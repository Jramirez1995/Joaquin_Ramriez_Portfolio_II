<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Joaquin Ramirez">

<title>Joaquin Ramirez - Predictive Modeling</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Joaquin Ramirez</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../aboutme.html" rel="" target="">
 <span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Projects</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="../starter-analysis-exercise/products/report/starter-analysis-report.html" rel="" target="">
 <span class="dropdown-text">Starter Analysis Exercise</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../coding-exercise/coding-exercise.html" rel="" target="">
 <span class="dropdown-text">R Coding Exercise</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../presentation-exercise/presentation-exercise.html" rel="" target="">
 <span class="dropdown-text">Presentation Exercise</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tidytuesday-exercise/tidytuesday-exercise.html" rel="" target="">
 <span class="dropdown-text">Tidy Tuesday Exercise</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../data-exercise/data-exercise.html" rel="" target="">
 <span class="dropdown-text">Data Exercise</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../cdcdata-exercise/cdcdata-exercise.html" rel="" target="">
 <span class="dropdown-text">CDC Data Exercise</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../time-series/practicum1.html" rel="" target="">
 <span class="dropdown-text">Time Series</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../market-segmentation/market-segmentation.html" rel="" target="">
 <span class="dropdown-text">Market Segmentation: Dr Pepper</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../predictive-modeling/predictive-modeling.html" rel="" target="">
 <span class="dropdown-text">Predictive Modeling</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Jramirez1995/Joaquin_Ramriez_Portfolio_II.git" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Predictive Modeling</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Joaquin Ramirez </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<p>Below is an overview of the key concepts I learned, focusing on predictive modeling techniques and analytics tools with a practical approach using R programming. The topics I explored include data preprocessing, overfitting, model tuning, and both supervised methods (such as linear and nonlinear regression, classification) and unsupervised methods (like clustering, PCA, and outlier detection). Additionally, I delved into advanced techniques such as support vector machines and tree-based models. Through this, I gained the ability to choose, implement, and interpret predictive models for a variety of applications and developed the skills to create comprehensive data analysis reports.</p>
<section id="student-dataset-case-study" class="level1">
<h1>Student Dataset Case Study</h1>
<p>R offers a wide range of functions for data preprocessing, calculation, manipulation, and graphical display, and can be easily extended with new functions through downloadable packages from the Comprehensive R Archive Network (CRAN).</p>
<p>As an example, the studentdata dataset from the LearnBayes package is used, containing 657 observations across 11 variables:</p>
<p><strong>Student</strong> student number <strong>Height</strong> height in inches <strong>Gender</strong> gender <strong>Shoes</strong> number of pairs of shoes owned <strong>Number</strong> number chosen between 1 and 10 <strong>Dvds</strong> name of movie dvds owned <strong>ToSleep</strong> time the person went to sleep the previous night (hours past midnight) <strong>WakeUp</strong> time the person woke up the next morning <strong>Haircut</strong> cost of last haircut including tip <strong>Job</strong> number of hours working on a job per week <strong>Drink</strong> usual drink at suppertime among milk, water, and pop</p>
<p>Install LearnBayes package in R/Rstudio and then access studentdata</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Install the LearnBayes package</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">#Keep in mind that R is case-sensitive</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages('LearnBayes')</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">#You just need to install once and then you can directly use</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">#so long as you access the LearnBayes package</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(LearnBayes)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Access studentdata from the LearnBayes package</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(studentdata)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(studentdata)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">#show part of data</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(studentdata)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Student Height Gender Shoes Number Dvds ToSleep WakeUp Haircut  Job Drink
1       1     67 female    10      5   10    -2.5    5.5      60 30.0 water
2       2     64 female    20      7    5     1.5    8.0       0 20.0   pop
3       3     61 female    12      2    6    -1.5    7.5      48  0.0  milk
4       4     61 female     3      6   40     2.0    8.5      10  0.0 water
5       5     70   male     4      5    6     0.0    9.0      15 17.5   pop
6       6     63 female    NA      3    5     1.0    8.5      25  0.0 water</code></pre>
</div>
</div>
<p>After accessing the studentdata, we can now use R to answer the following questions:</p>
<ol type="1">
<li>The variable Dvds in the student dataset contains the number of movie DVDs owned by students in the class.</li>
</ol>
<ol type="a">
<li>Construct a histogram of this variable using the hist command in R.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#?hist</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct a histogram of the Dvds variable</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(Dvds,<span class="at">main =</span> <span class="st">"DVDs Owned"</span>, <span class="at">xlab =</span> <span class="st">"Number of DVDs"</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ol start="2" type="a">
<li>Summarize this variable using the summary command in R.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Dvds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
   0.00   10.00   20.00   30.93   30.00 1000.00      16 </code></pre>
</div>
</div>
<ol start="3" type="a">
<li>Use the table command in R to construct a frequency table of the individual values of Dvds that were observed. If one constructs a barplot of these tabled values using the command barplot(table(Dvds),col=‘red’) one will see that particular response values are very popular. Is there any explanation for these popular values for the number of DVDs owned?</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>table <span class="ot">=</span> <span class="fu">table</span>(Dvds)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(table)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dvds
   0    1    2  2.5    3    4    5    6    7    8    9   10   11   12   13   14 
  26   10   13    1   18    9   27   14   12   12    7   78    3   20    7    4 
  15   16   17 17.5   18   20   21   22 22.5   23   24   25 27.5   28   29   30 
  46    1    3    1    4   83    3    3    1    3    2   31    3    1    1   45 
  31   33   35   36   37   40   41   42   45   46   48   50   52   53   55   60 
   1    1   12    4    1   26    1    1    5    1    2   26    1    2    1    7 
  62   65   67   70   73   75   80   83   85   90   97  100  120  122  130  137 
   1    2    1    4    1    3    4    1    1    1    1   10    2    1    2    1 
 150  152  157  175  200  250  500  900 1000 
   6    1    1    1    8    1    1    1    1 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">barplot</span>(table,<span class="at">col=</span><span class="st">'red'</span>, <span class="at">main =</span> <span class="st">"DVDs Owned"</span>, <span class="at">xlab =</span> <span class="st">"Number of DVDs"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Based on the limited information provided, we can assume there are many reasons for the number of DVDs owned. Some of these reasons include, but are not limited to: sales of DVDs, the release of new or classic DVDs, are students collecting DVDs and DVDs received as gifts. In order to dive deeper into the analysis, it would be crucial to know the name of the movies. This information could provide important details about the reasons why certain DVDs are appearing more often.</p>
<ol start="2" type="1">
<li>The variable Height contains the height (in inches) of each student in the class.</li>
</ol>
<ol type="a">
<li>Construct parallel boxplots of the heights using the Gender variable. Hint: boxplot(Height~Gender)</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(Height<span class="sc">~</span>Gender, <span class="at">main =</span> <span class="st">"Height by Gender"</span>, <span class="at">ylab =</span> <span class="st">"Height (inches)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ol start="2" type="a">
<li>If one assigns the boxplot output to a variable output=boxplot(Height~Gender) then output is a list that contains statistics used in constructing the boxplots. Print output to see the statistics that are stored.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>output<span class="ot">=</span><span class="fu">boxplot</span>(Height<span class="sc">~</span>Gender, <span class="at">main =</span> <span class="st">"Height by Gender"</span>, <span class="at">ylab =</span> <span class="st">"Height (inches)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(output)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$stats
      [,1] [,2]
[1,] 57.75   65
[2,] 63.00   69
[3,] 64.50   71
[4,] 67.00   72
[5,] 73.00   76

$n
[1] 428 219

$conf
         [,1]    [,2]
[1,] 64.19451 70.6797
[2,] 64.80549 71.3203

$out
 [1] 56 76 55 56 76 54 54 84 78 77 56 63 77 79 62 62 61 79 59 61 78 62

$group
 [1] 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2

$names
[1] "female" "male"  </code></pre>
</div>
</div>
<ol start="3" type="a">
<li>On average, how much taller are male students than female students? 3</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>average <span class="ot">=</span> <span class="fu">tapply</span>(Height, Gender, mean, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(average)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  female     male 
64.75701 70.50767 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>avg_female_height <span class="ot">=</span> <span class="fl">64.75701</span> </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>avg_male_height <span class="ot">=</span> <span class="fl">70.50767</span> </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span>  avg_male_height <span class="sc">-</span> avg_female_height</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(c)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.75066</code></pre>
</div>
</div>
<p>Male: 70.50767 Female: 64.75701</p>
<p>On average males students are 5.75066 inches taller than female students.</p>
<ol start="3" type="1">
<li>The variables ToSleep and WakeUp contain, respectively, the time to bed and wake-up time for each student the previous evening. (The data are recorded as hours past midnight, so a value of −2 indicates 10 p.m.)</li>
</ol>
<ol type="a">
<li>Construct a scatterplot of ToSleep and WakeUp.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ToSleep, WakeUp, <span class="at">main =</span> <span class="st">"Scatterplot: ToSleep and WakeUp"</span>, <span class="at">xlab =</span> <span class="st">"Sleep-Time"</span>, <span class="at">ylab =</span> <span class="st">"Wake-up Time"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ol start="2" type="a">
<li>Find a least-squares fit to these data using the lm command and then place the least-squares fit on the scatterplot using the abline command.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ToSleep, WakeUp, <span class="at">main =</span> <span class="st">"Scatterplot: ToSleep and WakeUp"</span>, <span class="at">xlab =</span> <span class="st">"Sleep-Time"</span>, <span class="at">ylab =</span> <span class="st">"Wake-up Time"</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(WakeUp<span class="sc">~</span>ToSleep)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = WakeUp ~ ToSleep)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.4010 -0.9628 -0.0998  0.8249  4.6125 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  7.96276    0.06180  128.85   &lt;2e-16 ***
ToSleep      0.42472    0.03595   11.81   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.282 on 651 degrees of freedom
  (4 observations deleted due to missingness)
Multiple R-squared:  0.1765,    Adjusted R-squared:  0.1753 
F-statistic: 139.5 on 1 and 651 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(fit, <span class="at">col=</span><span class="st">'blue'</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="analysis-of-glass-identification-data-exploratory-data-analysis-and-model-development" class="level1">
<h1>Analysis of Glass Identification Data: Exploratory Data Analysis and Model Development</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages('mlbench')</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages('ggplot2')</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages('GGally')</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages('corrplot')</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages('gridExtra')</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages('kernlab')</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kernlab) </span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'mlbench' was built under R version 4.3.3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'ggplot2' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'ggplot2'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:kernlab':

    alpha</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'GGally' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Registered S3 method overwritten by 'GGally':
  method from   
  +.gg   ggplot2</code></pre>
</div>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(corrplot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'corrplot' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>corrplot 0.92 loaded</code></pre>
</div>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'gridExtra' was built under R version 4.3.3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AppliedPredictiveModeling)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'AppliedPredictiveModeling' was built under R version 4.3.3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'caret' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: lattice</code></pre>
</div>
</div>
<p>The UC Irvine Machine Learning Repository contains a data set related to glass identification. The data consists of 214 glass samples labeled as one of seven class categories. There are nine predictors, including the refractive index and percentages of eight elements: Na, Mg, Al, Si, K, Ca, Ba, and Fe.</p>
<p>The data can be accessed via</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Glass)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(Glass)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   214 obs. of  10 variables:
 $ RI  : num  1.52 1.52 1.52 1.52 1.52 ...
 $ Na  : num  13.6 13.9 13.5 13.2 13.3 ...
 $ Mg  : num  4.49 3.6 3.55 3.69 3.62 3.61 3.6 3.61 3.58 3.6 ...
 $ Al  : num  1.1 1.36 1.54 1.29 1.24 1.62 1.14 1.05 1.37 1.36 ...
 $ Si  : num  71.8 72.7 73 72.6 73.1 ...
 $ K   : num  0.06 0.48 0.39 0.57 0.55 0.64 0.58 0.57 0.56 0.57 ...
 $ Ca  : num  8.75 7.83 7.78 8.22 8.07 8.07 8.17 8.24 8.3 8.4 ...
 $ Ba  : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Fe  : num  0 0 0 0 0 0.26 0 0 0 0.11 ...
 $ Type: Factor w/ 6 levels "1","2","3","5",..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
</div>
</div>
<p><strong>a) Utilize suitable visualizations (employ any types of data visualization you deem appropriate) to explore the predictor variables, aiming to understand their distributions and relationships among them.</strong></p>
<p><strong>Boxplots:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Glass)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>Glass<span class="sc">$</span>Type <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(Glass<span class="sc">$</span>Type)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>boxplots <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="fu">names</span>(Glass)[<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>], <span class="cf">function</span>(var) {<span class="fu">ggplot</span>(Glass, <span class="fu">aes_string</span>(<span class="at">x =</span> <span class="st">"Type"</span>, <span class="at">y =</span> var)) <span class="sc">+</span> </span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_boxplot</span>() <span class="sc">+</span> </span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="fu">paste</span>(<span class="st">"Boxplot of"</span>, var)) <span class="sc">+</span> </span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_dark</span>()})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: `aes_string()` was deprecated in ggplot2 3.0.0.
ℹ Please use tidy evaluation idioms with `aes()`.
ℹ See also `vignette("ggplot2-in-packages")` for more information.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>boxplots_combined <span class="ot">&lt;-</span> <span class="fu">do.call</span>(grid.arrange, <span class="fu">c</span>(boxplots, <span class="at">ncol =</span> <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><strong>Histograms:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>histograms <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="fu">names</span>(Glass)[<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>], <span class="cf">function</span>(var) {<span class="fu">ggplot</span>(Glass, <span class="fu">aes_string</span>(<span class="at">x =</span> var)) <span class="sc">+</span> </span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">30</span>) <span class="sc">+</span> </span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="fu">paste</span>(<span class="st">"Histogram of"</span>, var)) <span class="sc">+</span> </span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_classic</span>()})</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>histogram_combined <span class="ot">&lt;-</span> <span class="fu">do.call</span>(grid.arrange, <span class="fu">c</span>(histograms, <span class="at">ncol =</span> <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>I utilized both Histograms and Boxplots, you can definitely see a lot of outliers in the plots displayed. Na and Al, seem to be normally distributed but all other seem to be either skewed to the left or to the right.</p>
<p><strong>b) Do there appear to be any outliers in the data? Are any predictors skewed? Show all the work! </strong></p>
<ul>
<li>Function to create boxplots for each predictor:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>create_boxplot <span class="ot">&lt;-</span> <span class="cf">function</span>(data, var) {</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(data, <span class="fu">aes_string</span>(<span class="at">y =</span> var)) <span class="sc">+</span> </span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_boxplot</span>() <span class="sc">+</span> </span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="fu">paste</span>(<span class="st">"Boxplot of"</span>, var)) <span class="sc">+</span> </span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_classic</span>()}</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>boxplots <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="fu">names</span>(Glass)[<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>], <span class="cf">function</span>(var) <span class="fu">create_boxplot</span>(Glass, var))</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="fu">do.call</span>(grid.arrange, <span class="fu">c</span>(boxplots, <span class="at">ncol =</span> <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Predictors Outliers from Boxplots:</p>
<ul>
<li><p>RI (Refractive Index): Significant outliers exist</p></li>
<li><p>Na (Sodium): Fewer outliers exist, with some extreme values</p></li>
<li><p>Mg (Magnesium): No outliers</p></li>
<li><p>Al (Aluminum): Significant Outliers exist, with extreme values</p></li>
<li><p>Si (Silicon): Significant outliers exist, with extreme values</p></li>
<li><p>K (Potassium): Outliers exist, fewer extreme values</p></li>
<li><p>Ca (Calcium): Significant outliers are existing.</p></li>
<li><p>Ba (Barium): Significant outliers observed, with many extreme value</p></li>
<li><p>Fe (Iron): Outliers observed with few extreme values</p></li>
<li><p>Function to create histograms for each predictor</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>create_histogram <span class="ot">&lt;-</span> <span class="cf">function</span>(data, var) {</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(data, <span class="fu">aes_string</span>(<span class="at">x =</span> var)) <span class="sc">+</span> </span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">30</span>) <span class="sc">+</span> </span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="fu">paste</span>(<span class="st">"Histogram of"</span>, var)) <span class="sc">+</span> </span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_classic</span>()}</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>histograms <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="fu">names</span>(Glass)[<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>], <span class="cf">function</span>(var) <span class="fu">create_histogram</span>(Glass, var))</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>histo <span class="ot">&lt;-</span> <span class="fu">do.call</span>(grid.arrange, <span class="fu">c</span>(histograms, <span class="at">ncol =</span> <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Predictors Skewness from Histogram:</p>
<ul>
<li>RI (Refractive Index): Right - Postive skewed</li>
<li>Na (Sodium): Right - Postive skewed</li>
<li>Mg (Magnesium):Left - Negative skewed</li>
<li>Al (Aluminum): Symmetrical, balanced</li>
<li>Si (Silicon): Left - Negatively skewed</li>
<li>K (Potassium): Left - Negative skewed</li>
<li>Ca (Calcium): Symmetrical, balanced</li>
<li>Ba (Barium): Non symmetrical</li>
<li>Fe (Iron): Non symmetrical</li>
</ul>
<p><strong>Conclusion (Predictors):</strong></p>
<p>We can determine from the observations (Boxplot and Histograms), all but one showed outliers with extreme values. Most of these predictors where either skewed to the left (negative) or to the right (positive). All this to say that we need to consider the outliers and the distribution charactertics going forward.</p>
<ol start="3" type="a">
<li>Are there any relevant transformations of one or more predictors that might improve the classification model? Show all the work!</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>Glass_transformed <span class="ot">&lt;-</span> Glass</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>Glass_transformed[] <span class="ot">&lt;-</span> <span class="fu">lapply</span>(Glass_transformed, <span class="cf">function</span>(x) <span class="cf">if</span> (<span class="fu">is.numeric</span>(x)) <span class="fu">log</span>(x <span class="sc">+</span> <span class="dv">1</span>) <span class="cf">else</span> x)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(Glass_transformed)[<span class="fu">names</span>(Glass_transformed) <span class="sc">!=</span> <span class="st">"Type"</span>] <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"log_"</span>, <span class="fu">names</span>(Glass_transformed)[<span class="fu">names</span>(Glass_transformed) <span class="sc">!=</span> <span class="st">"Type"</span>])</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>Glass_sqrt_transformed <span class="ot">&lt;-</span> Glass</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>Glass_sqrt_transformed[] <span class="ot">&lt;-</span> <span class="fu">lapply</span>(Glass_sqrt_transformed, <span class="cf">function</span>(x) <span class="cf">if</span> (<span class="fu">is.numeric</span>(x)) <span class="fu">sqrt</span>(x) <span class="cf">else</span> x)</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(Glass_sqrt_transformed)[<span class="fu">names</span>(Glass_sqrt_transformed) <span class="sc">!=</span> <span class="st">"Type"</span>] <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"sqrt_"</span>, <span class="fu">names</span>(Glass_sqrt_transformed)[<span class="fu">names</span>(Glass_sqrt_transformed) <span class="sc">!=</span> <span class="st">"Type"</span>])</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>Glass_all_transformed <span class="ot">&lt;-</span> <span class="fu">cbind</span>(Glass_transformed, Glass_sqrt_transformed[,<span class="sc">-</span><span class="fu">which</span>(<span class="fu">names</span>(Glass_sqrt_transformed) <span class="sc">==</span> <span class="st">"Type"</span>)])</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>log_histograms <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="fu">names</span>(Glass_transformed)[<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>], <span class="cf">function</span>(var) {</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(Glass_transformed, <span class="fu">aes_string</span>(<span class="at">x =</span> var)) <span class="sc">+</span> </span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">30</span>) <span class="sc">+</span> </span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="fu">paste</span>(<span class="st">"Histogram of"</span>, var)) <span class="sc">+</span> </span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_classic</span>()})</span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a>sqrt_histograms <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="fu">names</span>(Glass_sqrt_transformed)[<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>], <span class="cf">function</span>(var) {</span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(Glass_sqrt_transformed, <span class="fu">aes_string</span>(<span class="at">x =</span> var)) <span class="sc">+</span> </span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">30</span>) <span class="sc">+</span> </span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="fu">paste</span>(<span class="st">"Histogram of"</span>, var)) <span class="sc">+</span> </span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_classic</span>()})</span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a>histogram_combined <span class="ot">&lt;-</span> <span class="fu">do.call</span>(grid.arrange, <span class="fu">c</span>(histograms, <span class="at">ncol =</span> <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>log_histogram_combined <span class="ot">&lt;-</span> <span class="fu">do.call</span>(grid.arrange, <span class="fu">c</span>(log_histograms, <span class="at">ncol =</span> <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-17-2.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>sqrt_histogram_combined <span class="ot">&lt;-</span> <span class="fu">do.call</span>(grid.arrange, <span class="fu">c</span>(sqrt_histograms, <span class="at">ncol =</span> <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-17-3.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>trainIndex <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(Glass<span class="sc">$</span>Type, <span class="at">p =</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>GlassTrain <span class="ot">&lt;-</span> Glass_all_transformed[trainIndex, ]</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>GlassTest <span class="ot">&lt;-</span> Glass_all_transformed[<span class="sc">-</span>trainIndex, ]</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>model_transformed <span class="ot">&lt;-</span> <span class="fu">train</span>(Type <span class="sc">~</span> ., <span class="at">data =</span> GlassTrain, <span class="at">method =</span> <span class="st">'rpart'</span>)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>pred_transformed <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_transformed, <span class="at">newdata =</span> GlassTest)</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>cm_transformed <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred_transformed, GlassTest<span class="sc">$</span>Type)</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Transformed Model Performance:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Transformed Model Performance:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(cm_transformed)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  1  2  3  5  6  7
         1 11  8  2  0  0  0
         2  3  7  1  1  1  0
         3  0  0  0  0  0  0
         5  0  0  0  0  0  0
         6  0  0  0  0  0  0
         7  0  0  0  1  0  5

Overall Statistics
                                          
               Accuracy : 0.575           
                 95% CI : (0.4089, 0.7296)
    No Information Rate : 0.375           
    P-Value [Acc &gt; NIR] : 0.008001        
                                          
                  Kappa : 0.371           
                                          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: 1 Class: 2 Class: 3 Class: 5 Class: 6 Class: 7
Sensitivity            0.7857   0.4667    0.000     0.00    0.000   1.0000
Specificity            0.6154   0.7600    1.000     1.00    1.000   0.9714
Pos Pred Value         0.5238   0.5385      NaN      NaN      NaN   0.8333
Neg Pred Value         0.8421   0.7037    0.925     0.95    0.975   1.0000
Prevalence             0.3500   0.3750    0.075     0.05    0.025   0.1250
Detection Rate         0.2750   0.1750    0.000     0.00    0.000   0.1250
Detection Prevalence   0.5250   0.3250    0.000     0.00    0.000   0.1500
Balanced Accuracy      0.7005   0.6133    0.500     0.50    0.500   0.9857</code></pre>
</div>
</div>
<p>After I applied the transformation and achieved accuracy of 57.5%, and the Kappa is 0.371. We can say there is a level of agreement between the variables. Now looking at the classes that were observed we can see that class 1 and 2 are strong in their classification while the rest need improvement. Maybe if we refine our focus on the variblae we observe we can improve out accurancy.</p>
<ol start="4" type="a">
<li>Fit SVM model (You may refer to Chapter 4 material for details) using the following R codes: (This code will be discussed in detail in the following chapters)</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">231</span>) </span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>sigDist <span class="ot">&lt;-</span> <span class="fu">sigest</span>(Type<span class="sc">~</span> ., <span class="at">data =</span> Glass, <span class="at">frac =</span> <span class="dv">1</span>)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>sigDist </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       90%        50%        10% 
0.03407935 0.11297847 0.62767315 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>svmTuneGrid <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">sigma =</span> <span class="fu">as.vector</span>(sigDist)[<span class="dv">1</span>], <span class="at">C =</span> <span class="dv">2</span><span class="sc">^</span>(<span class="sc">-</span><span class="dv">2</span><span class="sc">:</span><span class="dv">10</span>)) </span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>svmTuneGrid </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        sigma       C
1  0.03407935    0.25
2  0.03407935    0.50
3  0.03407935    1.00
4  0.03407935    2.00
5  0.03407935    4.00
6  0.03407935    8.00
7  0.03407935   16.00
8  0.03407935   32.00
9  0.03407935   64.00
10 0.03407935  128.00
11 0.03407935  256.00
12 0.03407935  512.00
13 0.03407935 1024.00</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">231</span>)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>sigDist <span class="ot">&lt;-</span> <span class="fu">sigest</span>(Type <span class="sc">~</span> ., <span class="at">data =</span> Glass, <span class="at">frac =</span> <span class="dv">1</span>)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>svmTuneGrid <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">sigma =</span> <span class="fu">as.vector</span>(sigDist)[<span class="dv">1</span>], <span class="at">C =</span> <span class="dv">2</span><span class="sc">^</span>(<span class="sc">-</span><span class="dv">2</span><span class="sc">:</span><span class="dv">10</span>))</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>svmModel <span class="ot">&lt;-</span> <span class="fu">ksvm</span>(Type <span class="sc">~</span> ., <span class="at">data =</span> Glass, <span class="at">type =</span> <span class="st">"C-svc"</span>, <span class="at">kernel =</span> <span class="st">"rbfdot"</span>, <span class="at">kpar =</span> <span class="fu">list</span>(<span class="at">sigma =</span> <span class="fu">as.vector</span>(sigDist)[<span class="dv">1</span>]), <span class="at">C =</span> <span class="dv">2</span><span class="sc">^</span>(<span class="sc">-</span><span class="dv">2</span><span class="sc">:</span><span class="dv">10</span>))</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(svmModel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Support Vector Machine object of class "ksvm" 

SV type: C-svc  (classification) 
 parameter : cost C = 0.25 
  parameter : cost C = 0.5 
  parameter : cost C = 1 
  parameter : cost C = 2 
  parameter : cost C = 4 
  parameter : cost C = 8 
  parameter : cost C = 16 
  parameter : cost C = 32 
  parameter : cost C = 64 
  parameter : cost C = 128 
  parameter : cost C = 256 
  parameter : cost C = 512 
  parameter : cost C = 1024 

Gaussian Radial Basis kernel function. 
 Hyperparameter : sigma =  0.0340793487610772 

Number of Support Vectors : 205 

Objective Function Value : -30.8971 -8.4786 -4.7642 -3.9839 -4.8778 -8.4545 -6.0399 -4.2908 -6.4624 -4.3643 -3.8975 -4.5021 -3.8506 -4.9211 -4.0869 
Training error : 0.439252 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1056</span>)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit SVM model using 10-fold cross-validation</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>svmFit <span class="ot">&lt;-</span> <span class="fu">train</span>(Type <span class="sc">~</span> .,</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">data =</span> Glass, <span class="at">method =</span> <span class="st">"svmRadial"</span>,</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>                <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">"center"</span>, <span class="st">"scale"</span>),</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>                <span class="at">tuneGrid =</span> svmTuneGrid,</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>                <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"repeatedcv"</span>, <span class="at">repeats =</span> <span class="dv">5</span>))</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(svmFit, <span class="at">scales =</span> <span class="fu">list</span>(<span class="at">x =</span> <span class="fu">list</span>(<span class="at">log =</span> <span class="dv">2</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/train-svm-model-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="predicting-meat-moisture-content-using-infrared-spectroscopy-model-comparison-and-evaluation" class="level1">
<h1>Predicting Meat Moisture Content Using Infrared Spectroscopy: Model Comparison and Evaluation</h1>
<p>Infrared (IR) spectroscopy technology is used to determine the chemical makeup of a substance. The theory of IR spectroscopy holds that unique molecular structures absorb IR frequencies differently. In practice a spectrometer fires a series of IR frequencies into a sample material, and the device measures the absorbance of the sample at each individual frequency. This series of measurements creates a spectrum profile which can then be used to determine the chemical makeup of the sample material.</p>
<p>A Tecator Infratec Food and Feed Analyzer instrument was used to analyze 215 samples of meat across 100 frequencies. A sample of these frequency profiles is displayed in Fig. 6.20. In addition to an IR profile, analytical chemistry determined the percent content of water, fat, and protein for each sample. If we can establish a predictive relationship between IR spectrum and fat content, then food scientists could predict a sample’s fat content with IR instead of using analytical chemistry. This would provide costs savings, since analytical chemistry is a more expensive, time-consuming process</p>
<p><strong>a) Start R and use these commands to load the data:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(tecator)</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="co"># use ?tecator to see more details</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>?tecator</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>starting httpd help server ... done</code></pre>
</div>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the structure of the data</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(absorp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:215, 1:100] 2.62 2.83 2.58 2.82 2.79 ...</code></pre>
</div>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(endpoints)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:215, 1:3] 60.5 46 71 72.8 58.3 44 44 69.3 61.4 61.4 ...</code></pre>
</div>
</div>
<p>The matrix absorp contains the 100 absorbance values for the 215 samples, while matrix endpoints contain the percent of moisture, fat, and protein in columns 1–3, respectively. To be more specific</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign the percent content to variables</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>moisture <span class="ot">&lt;-</span> endpoints[,<span class="dv">1</span>]</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>fat <span class="ot">&lt;-</span> endpoints[,<span class="dv">2</span>]</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>protein <span class="ot">&lt;-</span> endpoints[,<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(moisture)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  39.30   55.55   65.70   63.20   71.80   76.60 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co">#print(moisture)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   0.90    7.30   14.00   18.14   28.00   49.10 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co">#print(fat)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(protein)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  11.00   15.35   18.70   17.68   20.10   21.80 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co">#print(protein)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for missing values</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">is.na</span>(absorp))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">is.na</span>(moisture))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">is.na</span>(fat))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">is.na</span>(protein))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
</div>
<p><strong>b) In this example the predictors are the measurements at the individual frequencies. Because the frequencies lie in a systematic order (850–1,050nm), the predictors have a high degree of correlation. Hence, the data lie in a smaller dimension than the total number of predictors (215). Use PCA to determine the effective dimension of these data. What is the effective dimension?</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co">#  PCA on the absorp data</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>pca_model <span class="ot">&lt;-</span> <span class="fu">prcomp</span>(absorp, <span class="at">center =</span> <span class="cn">TRUE</span>, <span class="at">scale. =</span> <span class="cn">TRUE</span>)</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary of PCA </span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pca_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Importance of components:
                          PC1    PC2     PC3     PC4     PC5     PC6     PC7
Standard deviation     9.9311 0.9847 0.52851 0.33827 0.08038 0.05123 0.02681
Proportion of Variance 0.9863 0.0097 0.00279 0.00114 0.00006 0.00003 0.00001
Cumulative Proportion  0.9863 0.9960 0.99875 0.99990 0.99996 0.99999 0.99999
                           PC8      PC9     PC10     PC11     PC12     PC13
Standard deviation     0.01961 0.008564 0.006739 0.004442 0.003361 0.001867
Proportion of Variance 0.00000 0.000000 0.000000 0.000000 0.000000 0.000000
Cumulative Proportion  1.00000 1.000000 1.000000 1.000000 1.000000 1.000000
                           PC14      PC15      PC16      PC17      PC18
Standard deviation     0.001377 0.0009449 0.0008641 0.0007558 0.0006977
Proportion of Variance 0.000000 0.0000000 0.0000000 0.0000000 0.0000000
Cumulative Proportion  1.000000 1.0000000 1.0000000 1.0000000 1.0000000
                            PC19      PC20      PC21      PC22      PC23
Standard deviation     0.0005884 0.0004628 0.0003897 0.0003341 0.0003123
Proportion of Variance 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
Cumulative Proportion  1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
                            PC24      PC25     PC26      PC27      PC28
Standard deviation     0.0002721 0.0002616 0.000211 0.0001954 0.0001857
Proportion of Variance 0.0000000 0.0000000 0.000000 0.0000000 0.0000000
Cumulative Proportion  1.0000000 1.0000000 1.000000 1.0000000 1.0000000
                            PC29      PC30      PC31      PC32      PC33
Standard deviation     0.0001729 0.0001656 0.0001539 0.0001473 0.0001392
Proportion of Variance 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
Cumulative Proportion  1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
                            PC34      PC35      PC36     PC37     PC38
Standard deviation     0.0001339 0.0001269 0.0001082 0.000104 9.98e-05
Proportion of Variance 0.0000000 0.0000000 0.0000000 0.000000 0.00e+00
Cumulative Proportion  1.0000000 1.0000000 1.0000000 1.000000 1.00e+00
                            PC39      PC40      PC41      PC42     PC43
Standard deviation     9.081e-05 8.668e-05 8.026e-05 7.762e-05 7.36e-05
Proportion of Variance 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.00e+00
Cumulative Proportion  1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.00e+00
                            PC44      PC45     PC46      PC47      PC48
Standard deviation     6.808e-05 6.541e-05 6.44e-05 5.897e-05 5.422e-05
Proportion of Variance 0.000e+00 0.000e+00 0.00e+00 0.000e+00 0.000e+00
Cumulative Proportion  1.000e+00 1.000e+00 1.00e+00 1.000e+00 1.000e+00
                            PC49      PC50      PC51      PC52      PC53
Standard deviation     5.027e-05 4.893e-05 4.608e-05 4.419e-05 4.037e-05
Proportion of Variance 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00
Cumulative Proportion  1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00
                            PC54    PC55     PC56      PC57      PC58      PC59
Standard deviation     3.854e-05 3.8e-05 3.64e-05 3.497e-05 3.443e-05 3.264e-05
Proportion of Variance 0.000e+00 0.0e+00 0.00e+00 0.000e+00 0.000e+00 0.000e+00
Cumulative Proportion  1.000e+00 1.0e+00 1.00e+00 1.000e+00 1.000e+00 1.000e+00
                            PC60     PC61      PC62      PC63      PC64
Standard deviation     3.104e-05 3.04e-05 2.959e-05 2.844e-05 2.699e-05
Proportion of Variance 0.000e+00 0.00e+00 0.000e+00 0.000e+00 0.000e+00
Cumulative Proportion  1.000e+00 1.00e+00 1.000e+00 1.000e+00 1.000e+00
                            PC65      PC66      PC67      PC68      PC69
Standard deviation     2.586e-05 2.388e-05 2.364e-05 2.284e-05 2.173e-05
Proportion of Variance 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00
Cumulative Proportion  1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00
                            PC70      PC71     PC72      PC73      PC74
Standard deviation     2.058e-05 1.997e-05 1.93e-05 1.854e-05 1.807e-05
Proportion of Variance 0.000e+00 0.000e+00 0.00e+00 0.000e+00 0.000e+00
Cumulative Proportion  1.000e+00 1.000e+00 1.00e+00 1.000e+00 1.000e+00
                            PC75      PC76      PC77      PC78      PC79
Standard deviation     1.728e-05 1.693e-05 1.612e-05 1.569e-05 1.516e-05
Proportion of Variance 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00
Cumulative Proportion  1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00
                            PC80      PC81      PC82      PC83      PC84
Standard deviation     1.445e-05 1.408e-05 1.356e-05 1.275e-05 1.224e-05
Proportion of Variance 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00
Cumulative Proportion  1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00
                            PC85     PC86      PC87      PC88      PC89
Standard deviation     1.178e-05 1.09e-05 1.045e-05 1.009e-05 9.396e-06
Proportion of Variance 0.000e+00 0.00e+00 0.000e+00 0.000e+00 0.000e+00
Cumulative Proportion  1.000e+00 1.00e+00 1.000e+00 1.000e+00 1.000e+00
                            PC90     PC91      PC92     PC93      PC94
Standard deviation     8.728e-06 8.27e-06 7.613e-06 6.83e-06 6.383e-06
Proportion of Variance 0.000e+00 0.00e+00 0.000e+00 0.00e+00 0.000e+00
Cumulative Proportion  1.000e+00 1.00e+00 1.000e+00 1.00e+00 1.000e+00
                            PC95      PC96      PC97      PC98      PC99
Standard deviation     5.946e-06 5.478e-06 4.826e-06 4.521e-06 4.164e-06
Proportion of Variance 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00
Cumulative Proportion  1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00
                           PC100
Standard deviation     4.122e-06
Proportion of Variance 0.000e+00
Cumulative Proportion  1.000e+00</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scree plot to visualize the variance explained by each component</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="fu">screeplot</span>(pca_model, <span class="at">type =</span> <span class="st">"lines"</span>, <span class="at">main =</span> <span class="st">"PCA Model"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-29-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Based on both the PCA results above, first the pca summary output, and then screeplot visualization, tells me how much of the total variance is explained as PC are added. The following observations come from the output above:</p>
<ul>
<li><p>PC1 explains 98.63% of the total variance.</p></li>
<li><p>PC2: 0.97% proportion variance, and 99.60% cumulative proportion.</p></li>
<li><p>PC3: 0.279% proportion variance, and 99.875% cumulative proportion.</p></li>
<li><p>PC4: 0.114% proportion variance, and 99.99% cumulative proportion.</p></li>
</ul>
<p>Decision:</p>
<p>As shown in the screeplot and the summary, PC1 explains a very high percentage (98.63%), majority of the variability is captured here. The rest of the pc’s explain additional variance, but they’re unlikely to provide meaningful information.</p>
<p><strong>c) Split the data into a training and a test set the response of the percentage of moisture, pre-process the data, and build at least three models described in this chapter (i.e., ordinary least squares, PCR, PLS, Ridge, and ENET). For those models with tuning parameters, what are the optimal values of the tuning parameter(s)?</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) </span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>trainIndex <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(moisture, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>trainData <span class="ot">&lt;-</span> absorp[trainIndex, ]</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>testData <span class="ot">&lt;-</span> absorp[<span class="sc">-</span>trainIndex, ]</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>trainMoisture <span class="ot">&lt;-</span> moisture[trainIndex]</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>testMoisture <span class="ot">&lt;-</span> moisture[<span class="sc">-</span>trainIndex]</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>trainData <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(trainData)</span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>testData <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(testData)</span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(trainData) <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"V"</span>, <span class="dv">1</span><span class="sc">:</span><span class="fu">ncol</span>(trainData))</span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(testData) <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"V"</span>, <span class="dv">1</span><span class="sc">:</span><span class="fu">ncol</span>(testData))</span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-14"><a href="#cb89-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-15"><a href="#cb89-15" aria-hidden="true" tabindex="-1"></a>preProcValues <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(trainData, <span class="at">method =</span> <span class="fu">c</span>(<span class="st">"center"</span>, <span class="st">"scale"</span>, <span class="st">"pca"</span>))</span>
<span id="cb89-16"><a href="#cb89-16" aria-hidden="true" tabindex="-1"></a>trainTransformed <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcValues, trainData)</span>
<span id="cb89-17"><a href="#cb89-17" aria-hidden="true" tabindex="-1"></a>testTransformed <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcValues, testData)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>ols_model <span class="ot">&lt;-</span> <span class="fu">train</span>(trainTransformed, trainMoisture, <span class="at">method =</span> <span class="st">"lm"</span>)</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>ols_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear Regression 

152 samples
  2 predictor

No pre-processing
Resampling: Bootstrapped (25 reps) 
Summary of sample sizes: 152, 152, 152, 152, 152, 152, ... 
Resampling results:

  RMSE      Rsquared   MAE     
  8.521083  0.3199381  6.646874

Tuning parameter 'intercept' was held constant at a value of TRUE</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>pcr_model <span class="ot">&lt;-</span> <span class="fu">train</span>(trainTransformed, trainMoisture, <span class="at">method =</span> <span class="st">"pcr"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>))</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>pcr_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Principal Component Analysis 

152 samples
  2 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 136, 136, 137, 138, 136, 138, ... 
Resampling results:

  RMSE      Rsquared   MAE     
  8.929481  0.2947719  7.356878

Tuning parameter 'ncomp' was held constant at a value of 1</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>pls_model <span class="ot">&lt;-</span> <span class="fu">train</span>(trainTransformed, trainMoisture, <span class="at">method =</span> <span class="st">"pls"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>))</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>pls_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Partial Least Squares 

152 samples
  2 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 136, 136, 137, 138, 136, 138, ... 
Resampling results:

  RMSE      Rsquared   MAE    
  8.918747  0.2967856  7.34553

Tuning parameter 'ncomp' was held constant at a value of 1</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>ridge_model <span class="ot">&lt;-</span> <span class="fu">train</span>(trainTransformed, trainMoisture, <span class="at">method =</span> <span class="st">"ridge"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>))</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>ridge_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ridge Regression 

152 samples
  2 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 136, 136, 137, 138, 136, 138, ... 
Resampling results across tuning parameters:

  lambda  RMSE      Rsquared   MAE     
  0e+00   8.543739  0.3903416  6.778162
  1e-04   8.543732  0.3903418  6.778158
  1e-01   8.536797  0.3904599  6.774300

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was lambda = 0.1.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>glmnet <span class="ot">&lt;-</span> <span class="fu">train</span>(trainTransformed, trainMoisture, <span class="at">method =</span> <span class="st">"glmnet"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>))</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>glmnet</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>glmnet 

152 samples
  2 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 136, 136, 137, 138, 136, 138, ... 
Resampling results across tuning parameters:

  alpha  lambda      RMSE      Rsquared   MAE     
  0.10   0.01016872  8.541750  0.3903215  6.783427
  0.10   0.10168717  8.540506  0.3903110  6.787156
  0.10   1.01687174  8.533382  0.3900054  6.864132
  0.55   0.01016872  8.542255  0.3902511  6.783899
  0.55   0.10168717  8.541134  0.3901088  6.794327
  0.55   1.01687174  8.569440  0.3871371  6.953858
  1.00   0.01016872  8.542709  0.3902184  6.784242
  1.00   0.10168717  8.541940  0.3898954  6.801561
  1.00   1.01687174  8.628888  0.3822190  7.096575

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were alpha = 0.1 and lambda = 1.016872.</code></pre>
</div>
</div>
<p>Summary:</p>
<p><strong>OLS:</strong></p>
<ul>
<li>RMSE: 8.521083<br>
</li>
<li>Rsquared: 0.3199381<br>
</li>
<li>MAE: 6.646874</li>
<li>Tuning parameter held constant at a value of TRUE. (No tuning parameter)</li>
</ul>
<p><strong>PCR:</strong></p>
<ul>
<li>RMSE: 8.929481<br>
</li>
<li>Rsquared: 0.2947719<br>
</li>
<li>MAE: 7.356878<br>
</li>
<li>Tuning parameter held constant at a value of 1.</li>
</ul>
<p><strong>PLS:</strong></p>
<ul>
<li>RMSE: 8.918747<br>
</li>
<li>Rsquared: 0.2967856<br>
</li>
<li>MAE: 7.34553<br>
</li>
<li>Tuning parameter held constant at a value of 1.</li>
</ul>
<p><strong>Ridge Regression:</strong></p>
<ul>
<li>RMSE: 8.536797<br>
</li>
<li>Rsquared: 0.3904599<br>
</li>
<li>MAE: 6.774300<br>
</li>
<li>Tuning parameter the final value used for the model was lambda = 0.1.</li>
</ul>
<p><strong>Glmnet:</strong></p>
<ul>
<li>RMSE: 8.541750<br>
</li>
<li>Rsquared: 0.3903215<br>
</li>
<li>MAE: 6.783427</li>
<li>Tuning parameters alpha = 0.1 and lambda = 0.1016872</li>
</ul>
<p>Based on the lowest RMSE, OLS and Ridge Regression are the better models. They also they have a high rquared explaining a higher variance proportion.</p>
<p><strong>d) Which model has the best predictive ability? Is any model significantly better or worse than the others?</strong></p>
<p>The models are ordered from best to worst in terms of RMSE (predictive performance), based on the results provided above:</p>
<p><strong>1) OLS:</strong></p>
<ul>
<li>RMSE: 8.521083<br>
</li>
<li>Rsquared: 0.3199381<br>
</li>
<li>MAE: 6.646874</li>
<li>Tuning parameter held constant at a value of TRUE. (No tuning parameter)</li>
</ul>
<p><strong>2) Ridge Regression:</strong></p>
<ul>
<li>RMSE: 8.536797<br>
</li>
<li>Rsquared: 0.3904599<br>
</li>
<li>MAE: 6.774300<br>
</li>
<li>Tuning parameter the final value used for the model was lambda = 0.1.</li>
</ul>
<p><strong>3) Glmnet:</strong></p>
<ul>
<li>RMSE: 8.541750<br>
</li>
<li>Rsquared: 0.3903215<br>
</li>
<li>MAE: 6.783427</li>
<li>Tuning parameters alpha = 0.1 and lambda = 0.1016872</li>
</ul>
<p><strong>4) PLS:</strong></p>
<ul>
<li>RMSE: 8.918747<br>
</li>
<li>Rsquared: 0.2967856<br>
</li>
<li>MAE: 7.34553<br>
</li>
<li>Tuning parameter held constant at a value of 1.</li>
</ul>
<p><strong>5) PCR:</strong></p>
<ul>
<li>RMSE: 8.929481<br>
</li>
<li>Rsquared: 0.2947719<br>
</li>
<li>MAE: 7.356878<br>
</li>
<li>Tuning parameter held constant at a value of 1.</li>
</ul>
<p>The models are ordered first by the lowest RMSE and then highest R-squared to determine their performance. Based on the criteria of lowest RMSE, the OLS model is the best, this tells me that the OLS model has the lowest prediction error. However, you can also get away with using the Ridge model because it has the second lowest RMSE, and highest rsquared, indicating minimal error and a large proportion of the variance is explained by this model.</p>
<p><strong>e) Explain which model you would use for predicting the percentage of moisture of a sample.</strong></p>
<p>The model I would use to predict the percentage of moisture in a sample would be the one with the lowest RMSE because it has the lowest predictive error and a model with a high rsquared which explains variance proportion. In the outputs above, the model that best fits this is the Ridge model.</p>
</section>
<section id="comparative-performance-of-machine-learning-models-on-friedmans-benchmark-data-analyzing-knn-mars-neural-networks-and-svm" class="level1">
<h1>Comparative Performance of Machine Learning Models on Friedman’s Benchmark Data: Analyzing kNN, MARS, Neural Networks, and SVM</h1>
<p>7.2. Friedman (1991) introduced several benchmark data sets create by simulation. One of these simulations used the following nonlinear equation to create data:</p>
<p>y = 10 sin(πx1x2) + 20(x3 − 0.5)2 + 10x4 + 5x5 + N(0, σ2)</p>
<p>where the x values are random variables uniformly distributed between [0, 1] (there are also 5 other non-informative variables also created in the simulation). The package mlbench contains a function called mlbench.friedman1 that simulates these data:</p>
<p>Note: For this exercise, you need to consider at least three of the following models: kNN, MARS, Neural Network, and Support vector machines with a specified kernel.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages("caret")</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Loading libraries</span></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(earth)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'earth' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: Formula</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: plotmo</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'plotmo' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: plotrix</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'plotrix' was built under R version 4.3.2</code></pre>
</div>
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nnet)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">200</span>)</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate training data</span></span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>trainingData <span class="ot">&lt;-</span> <span class="fu">mlbench.friedman1</span>(<span class="dv">200</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>trainingData<span class="sc">$</span>x <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(trainingData<span class="sc">$</span>x) <span class="co"># We convert the 'x' data from a matrix to a data frame. One reason is that this will give the columns names.</span></span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(trainingData<span class="sc">$</span>x, trainingData<span class="sc">$</span>y) <span class="co"># Visualize the data using featurePlot</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-37-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate Test Data</span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>testData <span class="ot">&lt;-</span> <span class="fu">mlbench.friedman1</span>(<span class="dv">5000</span>, <span class="at">sd =</span> <span class="dv">1</span>) <span class="co"># This creates a list with a vector 'y' and a matrix of predictors 'x'. Also simulate a large test set to estimate the true error rate with good precision</span></span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a>testData<span class="sc">$</span>x <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(testData<span class="sc">$</span>x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Scatterplot Observations:</p>
<ul>
<li>X1-X5: show a positive trend.</li>
<li>X6-X10: show no specific trend, no correlation</li>
</ul>
</section>
<section id="tuning-several-models-knn-mars-neural-network-and-svm." class="level1">
<h1>Tuning several models: kNN, MARS, Neural Network, and SVM.</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train k-Nearest Neighbors (kNN) model</span></span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>knnModel <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">x =</span> trainingData<span class="sc">$</span>x,</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">y =</span> trainingData<span class="sc">$</span>y,</span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">"knn"</span>,</span>
<span id="cb110-5"><a href="#cb110-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">preProc =</span> <span class="fu">c</span>(<span class="st">"center"</span>, <span class="st">"scale"</span>),</span>
<span id="cb110-6"><a href="#cb110-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">tuneLength =</span> <span class="dv">10</span>)</span>
<span id="cb110-7"><a href="#cb110-7" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(knnModel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>k-Nearest Neighbors 

200 samples
 10 predictor

Pre-processing: centered (10), scaled (10) 
Resampling: Bootstrapped (25 reps) 
Summary of sample sizes: 200, 200, 200, 200, 200, 200, ... 
Resampling results across tuning parameters:

  k   RMSE      Rsquared   MAE     
   5  3.466085  0.5121775  2.816838
   7  3.349428  0.5452823  2.727410
   9  3.264276  0.5785990  2.660026
  11  3.214216  0.6024244  2.603767
  13  3.196510  0.6176570  2.591935
  15  3.184173  0.6305506  2.577482
  17  3.183130  0.6425367  2.567787
  19  3.198752  0.6483184  2.592683
  21  3.188993  0.6611428  2.588787
  23  3.200458  0.6638353  2.604529

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was k = 17.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict and evaluate kNN model</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>knnPred <span class="ot">&lt;-</span> <span class="fu">predict</span>(knnModel, <span class="at">newdata =</span> testData<span class="sc">$</span>x)</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>knnResults <span class="ot">&lt;-</span> <span class="fu">postResample</span>(<span class="at">pred =</span> knnPred, <span class="at">obs =</span> testData<span class="sc">$</span>y)  <span class="co"># The function 'postResample' can be used to get the test set perforamnce values</span></span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(knnResults)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     RMSE  Rsquared       MAE 
3.2040595 0.6819919 2.5683461 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Multivariate Adaptive Regression Splines (MARS)</span></span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>marsModel <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">x =</span> trainingData<span class="sc">$</span>x,</span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">y =</span> trainingData<span class="sc">$</span>y,</span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a>                   <span class="at">method =</span> <span class="st">"earth"</span>,</span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a>                   <span class="at">preProc =</span> <span class="fu">c</span>(<span class="st">"center"</span>, <span class="st">"scale"</span>),</span>
<span id="cb115-6"><a href="#cb115-6" aria-hidden="true" tabindex="-1"></a>                   <span class="at">tuneLength =</span> <span class="dv">10</span>)</span>
<span id="cb115-7"><a href="#cb115-7" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(marsModel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Multivariate Adaptive Regression Spline 

200 samples
 10 predictor

Pre-processing: centered (10), scaled (10) 
Resampling: Bootstrapped (25 reps) 
Summary of sample sizes: 200, 200, 200, 200, 200, 200, ... 
Resampling results across tuning parameters:

  nprune  RMSE      Rsquared   MAE     
   2      4.383438  0.2405683  3.597961
   3      3.645469  0.4745962  2.930453
   4      2.727602  0.7035031  2.184240
   6      2.331605  0.7835496  1.833420
   7      1.976830  0.8421599  1.562591
   9      1.804342  0.8683110  1.410395
  10      1.787676  0.8711960  1.386944
  12      1.821005  0.8670619  1.419893
  13      1.858688  0.8617344  1.445459
  15      1.871033  0.8607099  1.457618

Tuning parameter 'degree' was held constant at a value of 1
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nprune = 10 and degree = 1.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>marsPred <span class="ot">&lt;-</span> <span class="fu">predict</span>(marsModel, <span class="at">newdata =</span> testData<span class="sc">$</span>x)</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>marsResults <span class="ot">&lt;-</span> <span class="fu">postResample</span>(<span class="at">pred =</span> marsPred, <span class="at">obs =</span> testData<span class="sc">$</span>y)</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(marsResults)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    RMSE Rsquared      MAE 
1.776575 0.872700 1.358367 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural Network</span></span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>nnetModel <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">x =</span> trainingData<span class="sc">$</span>x,</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">y =</span> trainingData<span class="sc">$</span>y,</span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a>                   <span class="at">method =</span> <span class="st">"nnet"</span>,</span>
<span id="cb120-5"><a href="#cb120-5" aria-hidden="true" tabindex="-1"></a>                   <span class="at">preProc =</span> <span class="fu">c</span>(<span class="st">"center"</span>, <span class="st">"scale"</span>),</span>
<span id="cb120-6"><a href="#cb120-6" aria-hidden="true" tabindex="-1"></a>                   <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb120-7"><a href="#cb120-7" aria-hidden="true" tabindex="-1"></a>                   <span class="at">trace =</span> <span class="cn">FALSE</span>,</span>
<span id="cb120-8"><a href="#cb120-8" aria-hidden="true" tabindex="-1"></a>                   <span class="at">maxit =</span> <span class="dv">500</span>,</span>
<span id="cb120-9"><a href="#cb120-9" aria-hidden="true" tabindex="-1"></a>                   <span class="at">linout =</span> <span class="cn">TRUE</span>) <span class="co"># linout = TRUE for regression</span></span>
<span id="cb120-10"><a href="#cb120-10" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(nnetModel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Neural Network 

200 samples
 10 predictor

Pre-processing: centered (10), scaled (10) 
Resampling: Bootstrapped (25 reps) 
Summary of sample sizes: 200, 200, 200, 200, 200, 200, ... 
Resampling results across tuning parameters:

  size  decay  RMSE      Rsquared   MAE     
  1     0e+00  2.519137  0.7353382  1.970543
  1     1e-04  2.500942  0.7429904  1.944561
  1     1e-03  2.475847  0.7489994  1.931115
  1     1e-02  2.470504  0.7504027  1.922111
  1     1e-01  2.439968  0.7557086  1.893173
  3     0e+00  3.146237  0.6867740  2.246639
  3     1e-04  3.123896  0.6514690  2.421103
  3     1e-03  2.894276  0.6755563  2.274582
  3     1e-02  2.766721  0.6975189  2.199090
  3     1e-01  2.663439  0.7218025  2.102306
  5     0e+00  6.450585  0.4720758  3.615483
  5     1e-04  3.761009  0.5566309  2.708163
  5     1e-03  3.651200  0.5926186  2.679819
  5     1e-02  3.370460  0.6252829  2.614183
  5     1e-01  3.052473  0.6601510  2.392260
  7     0e+00  6.442198  0.4155727  3.821268
  7     1e-04  4.787702  0.4624648  3.401147
  7     1e-03  4.256500  0.5103711  3.207193
  7     1e-02  3.819179  0.5480917  2.979782
  7     1e-01  3.439917  0.6011807  2.741039
  9     0e+00  5.131231  0.4728159  3.608050
  9     1e-04  4.261980  0.4957059  3.306610
  9     1e-03  4.014608  0.5250012  3.199011
  9     1e-02  4.088546  0.5033594  3.233481
  9     1e-01  3.436716  0.6038520  2.721582

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were size = 1 and decay = 0.1.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>nnetPred <span class="ot">&lt;-</span> <span class="fu">predict</span>(nnetModel, <span class="at">newdata =</span> testData<span class="sc">$</span>x)</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>nnetResults <span class="ot">&lt;-</span> <span class="fu">postResample</span>(<span class="at">pred =</span> nnetPred, <span class="at">obs =</span> testData<span class="sc">$</span>y)</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(nnetResults)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     RMSE  Rsquared       MAE 
2.6493149 0.7177213 2.0295230 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SVM</span></span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>svmModel <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">x =</span> trainingData<span class="sc">$</span>x,</span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">y =</span> trainingData<span class="sc">$</span>y,</span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">"svmRadial"</span>,</span>
<span id="cb125-5"><a href="#cb125-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">preProc =</span> <span class="fu">c</span>(<span class="st">"center"</span>, <span class="st">"scale"</span>),</span>
<span id="cb125-6"><a href="#cb125-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">tuneLength =</span> <span class="dv">10</span>)</span>
<span id="cb125-7"><a href="#cb125-7" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(svmModel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Support Vector Machines with Radial Basis Function Kernel 

200 samples
 10 predictor

Pre-processing: centered (10), scaled (10) 
Resampling: Bootstrapped (25 reps) 
Summary of sample sizes: 200, 200, 200, 200, 200, 200, ... 
Resampling results across tuning parameters:

  C       RMSE      Rsquared   MAE     
    0.25  2.564825  0.7797760  2.011238
    0.50  2.357718  0.7938560  1.837232
    1.00  2.223469  0.8096320  1.723875
    2.00  2.136798  0.8217596  1.659346
    4.00  2.084793  0.8287955  1.622207
    8.00  2.067316  0.8310680  1.611923
   16.00  2.065727  0.8311623  1.610359
   32.00  2.065727  0.8311623  1.610359
   64.00  2.065727  0.8311623  1.610359
  128.00  2.065727  0.8311623  1.610359

Tuning parameter 'sigma' was held constant at a value of 0.062404
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were sigma = 0.062404 and C = 16.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>svmPred <span class="ot">&lt;-</span> <span class="fu">predict</span>(svmModel, <span class="at">newdata =</span> testData<span class="sc">$</span>x)</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>svmResults <span class="ot">&lt;-</span> <span class="fu">postResample</span>(<span class="at">pred =</span> svmPred, <span class="at">obs =</span> testData<span class="sc">$</span>y)</span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(svmResults)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     RMSE  Rsquared       MAE 
2.0723657 0.8258694 1.5741453 </code></pre>
</div>
</div>
<p><strong>Which models appear to give the best performance? Does MARS select the informative predictors (those named X1–X5)?</strong></p>
<p>Performance Summary:</p>
<p>MARS:</p>
<ul>
<li>Optimal nprune: 10</li>
<li>RMSE: 1.776575</li>
<li>R-squared: 0.872700</li>
<li>MAE: 1.358367</li>
</ul>
<p>SVM:</p>
<ul>
<li>Optimal C: 16</li>
<li>Optimal sigma: 0.068874</li>
<li>RMSE: 2.0889248</li>
<li>R-squared: 0.8232974</li>
<li>MAE: 1.5874122</li>
</ul>
<p>Neural Network:</p>
<ul>
<li>Optimal size: 1</li>
<li>Optimal decay: 0.1</li>
<li>RMSE: 2.6493162</li>
<li>R-squared: 0.7177209</li>
<li>MAE: 2.0295251</li>
</ul>
<p>kNN:</p>
<ul>
<li>Optimal k: 19</li>
<li>RMSE: 3.2286834</li>
<li>R-squared: 0.6871735</li>
<li>MAE: 2.5939727</li>
</ul>
<p>I have order the models from best performance to least, based on the following metric, low RMSE, high rsquared, and low MAE. In conclusion the MARS model outperforms the other models, it displays lowest RMSE, highest rsquared, lowest MAE. Now, the SVM model is also a strong contender following after the MARS model, it performs well. The Nueral Network performs alright it does have much higher RMSE than the previous two, lower rsquared and higher MAE, while the kNN model unperformed.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable Importance for MARS Model</span></span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Variable for MARS Model:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Variable for MARS Model:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">varImp</span>(marsModel))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>earth variable importance

   Overall
X1  100.00
X4   82.78
X2   64.18
X5   40.21
X3   28.14
X6    0.00</code></pre>
</div>
</div>
<p>In regards to the variables that are most informative they are as follows:</p>
<ul>
<li>X1: 100%</li>
<li>X4: 83%</li>
<li>X2: 64%</li>
<li>X5: 40%</li>
<li>X3: 28%</li>
</ul>
</section>
<section id="evaluating-predictor-importance-in-simulated-data-a-comparative-study-of-random-forest-conditional-inference-trees-boosted-trees-and-cubist-models" class="level1">
<h1>Evaluating Predictor Importance in Simulated Data: A Comparative Study of Random Forest, Conditional Inference Trees, Boosted Trees, and Cubist Models</h1>
<p><strong>8.1. Recreate the simulated data from Exercise 4:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">200</span>)</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a>simulated <span class="ot">&lt;-</span> <span class="fu">mlbench.friedman1</span>(<span class="dv">200</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true" tabindex="-1"></a>simulated <span class="ot">&lt;-</span> <span class="fu">cbind</span>(simulated<span class="sc">$</span>x, simulated<span class="sc">$</span>y)</span>
<span id="cb134-6"><a href="#cb134-6" aria-hidden="true" tabindex="-1"></a>simulated <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(simulated)</span>
<span id="cb134-7"><a href="#cb134-7" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(simulated)[<span class="fu">ncol</span>(simulated)] <span class="ot">&lt;-</span> <span class="st">"y"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>(a) Fit a random forest model to all of the predictors, then estimate the variable importance scores:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'randomForest' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>randomForest 4.7-1.1</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Type rfNews() to see new features/changes/bug fixes.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'randomForest'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:gridExtra':

    combine</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:ggplot2':

    margin</code></pre>
</div>
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the random forest model</span></span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a>random_forest <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(y <span class="sc">~</span> ., <span class="at">data =</span> simulated, <span class="at">importance =</span> <span class="cn">TRUE</span>, <span class="at">ntree =</span> <span class="dv">1000</span>)</span>
<span id="cb142-5"><a href="#cb142-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-6"><a href="#cb142-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate variable importance</span></span>
<span id="cb142-7"><a href="#cb142-7" aria-hidden="true" tabindex="-1"></a>random_forest_var <span class="ot">&lt;-</span> <span class="fu">varImp</span>(random_forest, <span class="at">scale =</span> <span class="cn">FALSE</span>)</span>
<span id="cb142-8"><a href="#cb142-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(random_forest_var)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         Overall
V1   8.732235404
V2   6.415369387
V3   0.763591825
V4   7.615118809
V5   2.023524577
V6   0.165111172
V7  -0.005961659
V8  -0.166362581
V9  -0.095292651
V10 -0.074944788</code></pre>
</div>
</div>
<ul>
<li><p>Positive Scores: V1, V2, V4, and V5 have positive scores. These are categorized as important predictors.</p></li>
<li><p>Negative Scores: V6, V7, V8, V9, and V10 have negative scores. These are categorized as counterproductive predictions.</p></li>
<li><p>V1 has the highest score (8.732) it is the most influential predictor in the model.</p></li>
</ul>
<p><strong>Did the random forest model significantly use the uninformative predictors (V6 – V10)?</strong></p>
<ul>
<li>No, the variables of importance score for these predictors are either low or negative. As stated above these predictors are categorized as counterproductive, so the models performance is driven by the important predictors.</li>
</ul>
<p><strong>(b) Now add an additional predictor that is highly correlated with one of the informative predictors. For example:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>simulated<span class="sc">$</span>duplicate1 <span class="ot">&lt;-</span> simulated<span class="sc">$</span>V1 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">200</span>) <span class="sc">*</span> .<span class="dv">1</span></span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(simulated<span class="sc">$</span>duplicate1, simulated<span class="sc">$</span>V1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9460206</code></pre>
</div>
</div>
<p>duplicate1 = 0.9460206</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">200</span>)  </span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a>simulated<span class="sc">$</span>duplicate2 <span class="ot">&lt;-</span> simulated<span class="sc">$</span>V2 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">200</span>) <span class="sc">*</span> <span class="fl">0.1</span></span>
<span id="cb146-3"><a href="#cb146-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(simulated<span class="sc">$</span>duplicate2, simulated<span class="sc">$</span>V2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9506982</code></pre>
</div>
</div>
<p>duplicate2 = 0.9506982</p>
<p><strong>Fit another random forest model to these data. Did the importance score for V1 change? What happens when you add another predictor that is also highly correlated with V1?</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">200</span>)</span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a>model_of_duplicates <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(y <span class="sc">~</span> ., <span class="at">data =</span> simulated, <span class="at">importance =</span> <span class="cn">TRUE</span>, <span class="at">ntree =</span> <span class="dv">1000</span>)</span>
<span id="cb148-6"><a href="#cb148-6" aria-hidden="true" tabindex="-1"></a>Imp_duplicates <span class="ot">&lt;-</span> <span class="fu">varImp</span>(model_of_duplicates, <span class="at">scale =</span> <span class="cn">FALSE</span>)</span>
<span id="cb148-7"><a href="#cb148-7" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(Imp_duplicates)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>               Overall
V1          5.60280192
V2          5.68392894
V3          0.46241755
V4          7.27624754
V5          1.72904882
V6          0.15759142
V7         -0.04038007
V8         -0.08223050
V9          0.01374080
V10        -0.00844889
duplicate1  4.24124904
duplicate2  2.44934620</code></pre>
</div>
</div>
<ul>
<li>After adding another predictor V1 decreased to 5.60.</li>
<li>V1 and V2, ad V4 have the highest scores.</li>
<li>Duplicate1, has a score of 4.24.</li>
<li>Duplicate2, had a score of 2.45.</li>
<li>V4 has the highest score (7.28) it is the most influential predictor in the model.</li>
</ul>
<p>As we add more predictors that are highly correlated, it ends up balancing the distribution of the predictor and shifting the level of importance for the model.</p>
<p><strong>(c) Use the cforest function in the party package to fit a random forest model using conditional inference trees. The party package function varimp can calculate predictor importance. The conditional argument of that function toggles between the traditional importance measure and the modified version. Do these importances show the same pattern as the traditional random forest model?</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(party)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'party' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: grid</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: mvtnorm</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: modeltools</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: stats4</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'modeltools'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:kernlab':

    prior</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: strucchange</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'strucchange' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: zoo</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'zoo'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:base':

    as.Date, as.Date.numeric</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: sandwich</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'sandwich' was built under R version 4.3.3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">200</span>)  </span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a>cforest_model <span class="ot">&lt;-</span> <span class="fu">cforest</span>(y <span class="sc">~</span> ., <span class="at">data =</span> simulated, <span class="at">controls =</span> <span class="fu">cforest_unbiased</span>(<span class="at">ntree =</span> <span class="dv">1000</span>))</span>
<span id="cb165-3"><a href="#cb165-3" aria-hidden="true" tabindex="-1"></a>cforest_conditional <span class="ot">&lt;-</span> <span class="fu">varimp</span>(cforest_model, <span class="at">conditional =</span> <span class="cn">TRUE</span>)</span>
<span id="cb165-4"><a href="#cb165-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(cforest_conditional)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          V1           V2           V3           V4           V5           V6 
 1.889829629  3.264726775  0.004320600  5.551127933  0.914778235  0.007554850 
          V7           V8           V9          V10   duplicate1   duplicate2 
 0.014874927 -0.008556608  0.005090607 -0.003604917  2.074263861  0.555345761 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb167"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">200</span>)  </span>
<span id="cb167-2"><a href="#cb167-2" aria-hidden="true" tabindex="-1"></a>cforest_traditional <span class="ot">&lt;-</span> <span class="fu">varimp</span>(cforest_model, <span class="at">conditional =</span> <span class="cn">FALSE</span>)</span>
<span id="cb167-3"><a href="#cb167-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(cforest_traditional)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          V1           V2           V3           V4           V5           V6 
 4.446790682  5.209317057  0.011349761  7.518264422  1.440050685 -0.007794484 
          V7           V8           V9          V10   duplicate1   duplicate2 
 0.032232290 -0.017239934  0.012003443 -0.007523583  4.992002245  1.845200350 </code></pre>
</div>
</div>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>Traditional</th>
<th>Conditional</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>V1</td>
<td>4.446790682</td>
<td>1.889829629</td>
</tr>
<tr class="even">
<td>V2</td>
<td>5.209317057</td>
<td>3.264726775</td>
</tr>
<tr class="odd">
<td>V3</td>
<td>0.011349761</td>
<td>0.004320600</td>
</tr>
<tr class="even">
<td>V4</td>
<td>7.518264422</td>
<td>5.551127933</td>
</tr>
<tr class="odd">
<td>V5</td>
<td>1.440050685</td>
<td>0.914778235</td>
</tr>
<tr class="even">
<td>V6</td>
<td>-0.007794484</td>
<td>0.007554850</td>
</tr>
<tr class="odd">
<td>V7</td>
<td>0.032232290</td>
<td>0.014874927</td>
</tr>
<tr class="even">
<td>V8</td>
<td>-0.017239934</td>
<td>-0.008556608</td>
</tr>
<tr class="odd">
<td>V9</td>
<td>0.012003443</td>
<td>0.005090607</td>
</tr>
<tr class="even">
<td>V10</td>
<td>-0.007523583</td>
<td>-0.003604917</td>
</tr>
<tr class="odd">
<td>duplicate1</td>
<td>4.992002245</td>
<td>2.074263861</td>
</tr>
<tr class="even">
<td>duplicate2</td>
<td>1.845200350</td>
<td>0.555345761</td>
</tr>
</tbody>
</table>
<p>In summary, while the general pattern of importance is similar, where V4 has the highest score followed by V2. Additionally, V6 through V10 remain unimportant. The conditional model has a more balance dispenserment while the traditional highlights more the importance of some variables.</p>
<p><strong>(d) Repeat this process with different tree models, such as boosted trees and Cubist. Does the same pattern occur?</strong></p>
<ol type="1">
<li>Boosted Trees</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gbm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'gbm' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loaded gbm 2.2.2</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>This version of gbm is no longer under development. Consider transitioning to gbm3, https://github.com/gbm-developers/gbm3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb173"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">200</span>)</span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a>gbm_model <span class="ot">&lt;-</span> <span class="fu">gbm</span>(y <span class="sc">~</span> ., <span class="at">data =</span> simulated, <span class="at">distribution =</span> <span class="st">"gaussian"</span>, <span class="at">n.trees =</span> <span class="dv">1000</span>, <span class="at">interaction.depth =</span> <span class="dv">3</span>)</span>
<span id="cb173-3"><a href="#cb173-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(gbm_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-50-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                  var   rel.inf
V4                 V4 27.564962
V2                 V2 18.081613
V1                 V1 13.457616
duplicate1 duplicate1 11.043677
V5                 V5 10.647818
V3                 V3  7.468840
duplicate2 duplicate2  4.082592
V7                 V7  2.232902
V6                 V6  1.579418
V8                 V8  1.322100
V10               V10  1.312882
V9                 V9  1.205581</code></pre>
</div>
</div>
<p>In short the Boosted Model, still considers the level of importance from V6-V10 to be unimportant. The most important variable here is V4 which matches the previous models, followed by V2 and V1. This seem to be in alignment with the other approaches where the level of importance lies within either V4, V1 or V2.</p>
<ol start="2" type="1">
<li>Cubist Model</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Cubist)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'Cubist' was built under R version 4.3.3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb177-3"><a href="#cb177-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">200</span>)</span>
<span id="cb177-4"><a href="#cb177-4" aria-hidden="true" tabindex="-1"></a>cubist_model <span class="ot">&lt;-</span> <span class="fu">train</span>(y <span class="sc">~</span> ., <span class="at">data =</span> simulated, <span class="at">method =</span> <span class="st">"cubist"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>))</span>
<span id="cb177-5"><a href="#cb177-5" aria-hidden="true" tabindex="-1"></a>cubist_varimp <span class="ot">&lt;-</span> <span class="fu">varImp</span>(cubist_model, <span class="at">scale =</span> <span class="cn">FALSE</span>)</span>
<span id="cb177-6"><a href="#cb177-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(cubist_varimp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>cubist variable importance

           Overall
V2            55.0
V1            52.0
V4            49.0
duplicate1    39.0
V5            38.0
V3            32.5
V6            21.5
duplicate2     4.5
V8             0.0
V7             0.0
V9             0.0
V10            0.0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb179"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cubist_varimp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           Length Class      Mode     
importance 1      data.frame list     
model      1      -none-     character
calledFrom 1      -none-     character</code></pre>
</div>
</div>
<p>As for the Cubist Model, you have some similarities, where V7-V10 remain unimportant and gives a slightly higher score to V6. However, in comparison to the other scores, V2 has the highest score followed by V1 then V4. This also aligns with the other methods where the level of importance is given to the op three variables either V1, V2, or V4.</p>
<p>Overall the pattern remains almost unchanged you have the order of importance shift between variables, but most of the attention lies within V1, V2, V4. The counterproductive variables are pretty much the same besides in the last model, where it give V6 a higher score, but the pattern remains unchanges for the most part.</p>
</section>
<section id="exploring-predictive-modeling-and-data-analysis-an-investigation-into-housing-data-soybean-disease-prediction-oil-classification-and-statistical-concepts" class="level1">
<h1>Exploring Predictive Modeling and Data Analysis: An Investigation into Housing Data, Soybean Disease Prediction, Oil Classification, and Statistical Concepts</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This exercise involves the Boston housing data set.</p>
<p><strong>a) To begin, load in the Boston data set. Since the Boston data set is part of the MASS library, you need to install the MASS package into R/Rstudio and then access the package as follows:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Boston</span></span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb182-3"><a href="#cb182-3" aria-hidden="true" tabindex="-1"></a>?Boston <span class="co">#Read about the data set using </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>How many rows are in this Boston data set? How many columns? What do the rows and columns represent?</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"Boston"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Based on the information provided we have the following:</p>
<p>Rows:506-observations in the dataset for the Boston area.</p>
<p>Columns: 14-variables, each column represents different variables. They are as followed:</p>
<ul>
<li><strong>crim:</strong> per capita crime rate by town.</li>
<li><strong>zn:</strong> proportion of residential land zoned for lots over 25,000 sq. ft.</li>
<li><strong>indus:</strong> proportion of non-retail business acres per town.</li>
<li><strong>chas:</strong> Charles River dummy variable (1 if tract bounds river; 0 otherwise).</li>
<li><strong>nox:</strong> nitrogen oxides concentration (parts per 10 million).</li>
<li><strong>rm:</strong> average number of rooms per dwelling.</li>
<li><strong>age:</strong> proportion of owner-occupied units built prior to 1940.</li>
<li><strong>dis:</strong> weighted mean of distances to five Boston employment centers.</li>
<li><strong>rad:</strong> index of accessibility to radial highways.</li>
<li><strong>tax:</strong> full-value property tax rate per $10,000.</li>
<li><strong>ptratio:</strong> pupil-teacher ratio by town.</li>
<li><strong>black:</strong> 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.</li>
<li><strong>lstat:</strong> percentage of lower status of the population.</li>
<li><strong>medv:</strong> median value of owner-occupied homes in $1000s.</li>
</ul>
<p><strong>b) Make some pairwise scatterplots of the predictors (columns) in this data set. Describe your findings. </strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb184"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(Boston, <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">cex =</span> <span class="dv">1</span>, <span class="at">labels =</span> <span class="fu">colnames</span>(Boston))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-55-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>OR</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb185"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a>predictors <span class="ot">&lt;-</span> <span class="fu">colnames</span>(Boston)</span>
<span id="cb185-2"><a href="#cb185-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb185-3"><a href="#cb185-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">3</span>)) </span>
<span id="cb185-4"><a href="#cb185-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb185-5"><a href="#cb185-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(predictors)) </span>
<span id="cb185-6"><a href="#cb185-6" aria-hidden="true" tabindex="-1"></a>  {<span class="cf">for</span> (j <span class="cf">in</span> (i<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span><span class="fu">length</span>(predictors))</span>
<span id="cb185-7"><a href="#cb185-7" aria-hidden="true" tabindex="-1"></a>    {predictor_x <span class="ot">&lt;-</span> predictors[i]</span>
<span id="cb185-8"><a href="#cb185-8" aria-hidden="true" tabindex="-1"></a>    predictor_y <span class="ot">&lt;-</span> predictors[j]</span>
<span id="cb185-9"><a href="#cb185-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb185-10"><a href="#cb185-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="sc">!</span><span class="fu">is.na</span>(predictor_x) <span class="sc">&amp;&amp;</span> <span class="sc">!</span><span class="fu">is.na</span>(predictor_y)) </span>
<span id="cb185-11"><a href="#cb185-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb185-12"><a href="#cb185-12" aria-hidden="true" tabindex="-1"></a>      {<span class="fu">plot</span>(Boston[[predictor_x]], Boston[[predictor_y]],</span>
<span id="cb185-13"><a href="#cb185-13" aria-hidden="true" tabindex="-1"></a>           <span class="at">xlab =</span> predictor_x, <span class="at">ylab =</span> predictor_y,</span>
<span id="cb185-14"><a href="#cb185-14" aria-hidden="true" tabindex="-1"></a>           <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">"Scatterplot:"</span>, predictor_x, <span class="st">"and"</span>, predictor_y))</span>
<span id="cb185-15"><a href="#cb185-15" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb185-16"><a href="#cb185-16" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb185-17"><a href="#cb185-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">abline</span>(<span class="fu">lm</span>(Boston[[predictor_y]] <span class="sc">~</span> Boston[[predictor_x]]), <span class="at">col =</span> <span class="st">"red"</span>)}}}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-56-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-56-2.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-56-3.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-56-4.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-56-5.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-56-6.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-56-7.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-56-8.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-56-9.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-56-10.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-56-11.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>I have provided two displays. The first combines all pairwise plots in a single view, the second organizes them for a better visualization. After reviewing the pairwise plots, I observed both positive and negative correlations, as well as some no-correlation, and some outliers. Below are a few observations, and as I proceed with the homework I will call out other observations:</p>
<ul>
<li>rad and zn: Negative correlation. Areas in Boston with more accessible radial highways have less residential zoning.</li>
<li>age and lstat: Positive correlation. Older homes have higher proportions of lower status population.</li>
<li>nox and tax: Positive correlation. Higher nitrogen oxides concentration levels are found in areas with higher property taxes.</li>
<li>chas: No significant correlation. Most of the variables associated (chas) - proximity to the Charles River are not significantly.</li>
<li>indus and tax: Positive correlation. Industrialized areas tend to have higher property taxes.</li>
<li>crim and medv: Negative correlation. Higher crime rates are found in areas with median home values.</li>
</ul>
<p><strong>c) Are any of the predictors associated with per capita crime rate? If so, explain the relationship. </strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) </span>
<span id="cb186-2"><a href="#cb186-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb186-3"><a href="#cb186-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Repeating the same as in 'b'</span></span>
<span id="cb186-4"><a href="#cb186-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(predictors)) </span>
<span id="cb186-5"><a href="#cb186-5" aria-hidden="true" tabindex="-1"></a>  {<span class="cf">for</span> (j <span class="cf">in</span> (i<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span><span class="fu">length</span>(predictors))</span>
<span id="cb186-6"><a href="#cb186-6" aria-hidden="true" tabindex="-1"></a>    {predictor_x <span class="ot">&lt;-</span> predictors[i]</span>
<span id="cb186-7"><a href="#cb186-7" aria-hidden="true" tabindex="-1"></a>    predictor_y <span class="ot">&lt;-</span> predictors[j]</span>
<span id="cb186-8"><a href="#cb186-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb186-9"><a href="#cb186-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="sc">!</span><span class="fu">is.na</span>(predictor_x) <span class="sc">&amp;&amp;</span> <span class="sc">!</span><span class="fu">is.na</span>(predictor_y)) </span>
<span id="cb186-10"><a href="#cb186-10" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb186-11"><a href="#cb186-11" aria-hidden="true" tabindex="-1"></a>      {<span class="cf">if</span> (predictor_x <span class="sc">==</span> <span class="st">"crim"</span> <span class="sc">||</span> predictor_y <span class="sc">==</span> <span class="st">"crim"</span>)   <span class="co"># Checking for crim as a predictor</span></span>
<span id="cb186-12"><a href="#cb186-12" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb186-13"><a href="#cb186-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Repeating the same as in 'b'</span></span>
<span id="cb186-14"><a href="#cb186-14" aria-hidden="true" tabindex="-1"></a>        {<span class="fu">plot</span>(Boston[[predictor_x]], Boston[[predictor_y]],</span>
<span id="cb186-15"><a href="#cb186-15" aria-hidden="true" tabindex="-1"></a>             <span class="at">xlab =</span> predictor_x, <span class="at">ylab =</span> predictor_y,</span>
<span id="cb186-16"><a href="#cb186-16" aria-hidden="true" tabindex="-1"></a>             <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">"Scatterplot:"</span>, predictor_x, <span class="st">"and"</span>, predictor_y))</span>
<span id="cb186-17"><a href="#cb186-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb186-18"><a href="#cb186-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (predictor_x <span class="sc">==</span> <span class="st">"crim"</span>) </span>
<span id="cb186-19"><a href="#cb186-19" aria-hidden="true" tabindex="-1"></a>          {<span class="fu">abline</span>(<span class="fu">lm</span>(Boston[[predictor_y]] <span class="sc">~</span> Boston[[predictor_x]]), <span class="at">col =</span> <span class="st">"red"</span>)}}}}}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-57-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-57-2.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-57-3.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-57-4.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Yes, there are predictors associated with the per capita crime rate. The following observation where made from the plots above, I also used the linear regression line to help me.</p>
<p>Negative correlation: - crim and zn: There’s a slight negative correlation. - crim and dis: There’s a negative correlation. - crim and black: There’s a negative correlation. - crim and medv: There’s a negative correlation. - crim and indus: There’s a positive correlation.</p>
<p>Positive correlation: - crim and nox: There’s a positive correlation.<br>
- crim and rm: There’s a slight negative correlation. - crim and age: There’s a positive correlation.<br>
- crim and rad: There’s a positive correlation.<br>
- crim and tax: There’s a positive correlation.<br>
- crim and ptratio: There’s a slight positive correlation. - crim and lstat: There’s a positive correlation.</p>
<p>No correlation: - crim and chas: There’s no clear correlation.</p>
<p>In conclusion the plots suggest that areas with higher nitrogen oxide/pollution, industrial areas, older homes, accessibility to radial highways, taxes, and lower status of population are likely to have higher crime rates. On the other hand, areas with more residential land zoning, larger homes, greater distance to five employment centers, and black population tend to have lower crime rates.</p>
<p><strong>d) Do any of the census tracts of Boston appear to have particularly high crime rates? Tax rates? Comment on the range of each predictor. </strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(Boston<span class="sc">$</span>crim, <span class="at">main =</span> <span class="st">"Histogram: crim"</span>, <span class="at">xlab =</span> <span class="st">"Per Capita Crime Rate"</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-58-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb188"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(Boston<span class="sc">$</span>tax, <span class="at">main =</span> <span class="st">"Histogram: tax"</span>, <span class="at">xlab =</span> <span class="st">"Tax Rate"</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-58-2.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a><span class="co"># census tracts with high crime rates and tax rates</span></span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a>high_crime <span class="ot">=</span> <span class="fu">quantile</span>(Boston<span class="sc">$</span>crim, <span class="fl">0.95</span>)  </span>
<span id="cb189-3"><a href="#cb189-3" aria-hidden="true" tabindex="-1"></a>high_tax <span class="ot">=</span> <span class="fu">quantile</span>(Boston<span class="sc">$</span>tax, <span class="fl">0.95</span>)  </span>
<span id="cb189-4"><a href="#cb189-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb189-5"><a href="#cb189-5" aria-hidden="true" tabindex="-1"></a>high_crime_tracts <span class="ot">=</span> Boston[Boston<span class="sc">$</span>crim <span class="sc">&gt;</span> high_crime, ]</span>
<span id="cb189-6"><a href="#cb189-6" aria-hidden="true" tabindex="-1"></a>high_tax_tracts <span class="ot">=</span> Boston[Boston<span class="sc">$</span>tax <span class="sc">&gt;</span> high_tax, ]</span>
<span id="cb189-7"><a href="#cb189-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb189-8"><a href="#cb189-8" aria-hidden="true" tabindex="-1"></a>rangecrim <span class="ot">=</span> <span class="fu">range</span>(Boston<span class="sc">$</span>crim, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb189-9"><a href="#cb189-9" aria-hidden="true" tabindex="-1"></a>rangetax <span class="ot">=</span> <span class="fu">range</span>(Boston<span class="sc">$</span>tax, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>According to the output there exist census tracts with high crime rates and tax rates, especially in the top 5%. The per capita crime rate ranges from 0.00632 to 88.97620, and the property tax rate range from 187 to 711. This just tells me that there are significant variability for both predictors.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb190"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a><span class="co"># range of each predictor</span></span>
<span id="cb190-2"><a href="#cb190-2" aria-hidden="true" tabindex="-1"></a>predictor_ranges <span class="ot">&lt;-</span> <span class="fu">apply</span>(Boston, <span class="dv">2</span>, range)</span>
<span id="cb190-3"><a href="#cb190-3" aria-hidden="true" tabindex="-1"></a>predictor_ranges</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         crim  zn indus chas   nox    rm   age     dis rad tax ptratio  black
[1,]  0.00632   0  0.46    0 0.385 3.561   2.9  1.1296   1 187    12.6   0.32
[2,] 88.97620 100 27.74    1 0.871 8.780 100.0 12.1265  24 711    22.0 396.90
     lstat medv
[1,]  1.73    5
[2,] 37.97   50</code></pre>
</div>
</div>
<p>According to the output there exist census tracts with high crime rates and tax rates, especially in the top 5%. The per capita crime rate ranges from 0.00632 to 88.97620, and the property tax rate range from 187 to 711. This just tells me that there are significant variability for both predictors. In addition to the census tract associated with high crime rates and tax rates, we can also note the rest of the predictors.</p>
<ul>
<li>Zn-proportion of residential land zoned rate range: 0 to 100</li>
<li>indus-proportion of non-retail business acres per town rate range: 0.46 to 27.74</li>
<li>chas-Charles River rate range: 0 to 1</li>
<li>nox-nitrogen oxides concentration rate range: 0.385 to 0.871 (parts per 10 million)</li>
<li>rm-average number of rooms rate range: 3.561 to 8.780</li>
<li>age-older home rate range: 2.9 to 100</li>
<li>dis-distances to employment centres rate range: 1.1296 to 12.1265</li>
<li>rad-accessibility to radial highways: 1 to 24</li>
<li>ptratio-pupil-teacher ratio by town rate range: 12.6 to 22</li>
<li>black-proportion of black population: 0.32 to 396.90</li>
<li>lstat-lower status of the population rate range: 1.73 to 37.97</li>
<li>medv-median value of owner-occupied rate range: 5 to 50</li>
</ul>
<p>Just reiterating what was previously stated, these predictors demonstrate that there is significant variability.</p>
<p><strong>e) How many of the census tracts in this data set bound the Charles river? </strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb192"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb192-1"><a href="#cb192-1" aria-hidden="true" tabindex="-1"></a>tracts_chas <span class="ot">=</span> <span class="fu">sum</span>(Boston<span class="sc">$</span>chas <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb192-2"><a href="#cb192-2" aria-hidden="true" tabindex="-1"></a>tracts_chas</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 35</code></pre>
</div>
</div>
<p>Since, the predictor chas - Charles River, 1 is if tract bounds river. They’re 35 census tracts.</p>
<p><strong>(f) What is the median pupil-teacher ratio among the towns in this data set?</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb194"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a>median_ptratio <span class="ot">=</span> <span class="fu">median</span>(Boston<span class="sc">$</span>ptratio)</span>
<span id="cb194-2"><a href="#cb194-2" aria-hidden="true" tabindex="-1"></a>median_ptratio</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 19.05</code></pre>
</div>
</div>
<p>The median pupil-teacher ratio by town is 19.05.</p>
</section>
<section id="soybean-case-study" class="level1">
<h1>Soybean case study</h1>
<p>The soybean data can also be found at the UC Irvine Machine Learning Repository. Data were collected to predict disease in 683 soybeans. The 35 predictors are mostly categorical and include information on the environmental conditions (e.g., temperature, precipitation) and plant conditions (e.g., left spots, mold growth). The outcome labels consist of 19 distinct classes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb196"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb196-1"><a href="#cb196-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(VIM)    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'VIM' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: colorspace</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>VIM is ready to use.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Suggestions and bug-reports can be submitted at: https://github.com/statistikat/VIM/issues</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'VIM'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:datasets':

    sleep</code></pre>
</div>
<div class="sourceCode cell-code" id="cb203"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mice)   </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'mice' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'mice'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:kernlab':

    convergence</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:stats':

    filter</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:base':

    cbind, rbind</code></pre>
</div>
<div class="sourceCode cell-code" id="cb209"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlbench) </span>
<span id="cb209-2"><a href="#cb209-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Soybean) </span>
<span id="cb209-3"><a href="#cb209-3" aria-hidden="true" tabindex="-1"></a>?Soybean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>a) Investigate the frequency distributions for the categorical predictors. Are any of the distributions degenerate in the ways discussed earlier in this chapter?</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb210"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb210-1"><a href="#cb210-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(Soybean)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   683 obs. of  36 variables:
 $ Class          : Factor w/ 19 levels "2-4-d-injury",..: 11 11 11 11 11 11 11 11 11 11 ...
 $ date           : Factor w/ 7 levels "0","1","2","3",..: 7 5 4 4 7 6 6 5 7 5 ...
 $ plant.stand    : Ord.factor w/ 2 levels "0"&lt;"1": 1 1 1 1 1 1 1 1 1 1 ...
 $ precip         : Ord.factor w/ 3 levels "0"&lt;"1"&lt;"2": 3 3 3 3 3 3 3 3 3 3 ...
 $ temp           : Ord.factor w/ 3 levels "0"&lt;"1"&lt;"2": 2 2 2 2 2 2 2 2 2 2 ...
 $ hail           : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 2 1 1 ...
 $ crop.hist      : Factor w/ 4 levels "0","1","2","3": 2 3 2 2 3 4 3 2 4 3 ...
 $ area.dam       : Factor w/ 4 levels "0","1","2","3": 2 1 1 1 1 1 1 1 1 1 ...
 $ sever          : Factor w/ 3 levels "0","1","2": 2 3 3 3 2 2 2 2 2 3 ...
 $ seed.tmt       : Factor w/ 3 levels "0","1","2": 1 2 2 1 1 1 2 1 2 1 ...
 $ germ           : Ord.factor w/ 3 levels "0"&lt;"1"&lt;"2": 1 2 3 2 3 2 1 3 2 3 ...
 $ plant.growth   : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
 $ leaves         : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
 $ leaf.halo      : Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 1 1 ...
 $ leaf.marg      : Factor w/ 3 levels "0","1","2": 3 3 3 3 3 3 3 3 3 3 ...
 $ leaf.size      : Ord.factor w/ 3 levels "0"&lt;"1"&lt;"2": 3 3 3 3 3 3 3 3 3 3 ...
 $ leaf.shread    : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ leaf.malf      : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ leaf.mild      : Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 1 1 ...
 $ stem           : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
 $ lodging        : Factor w/ 2 levels "0","1": 2 1 1 1 1 1 2 1 1 1 ...
 $ stem.cankers   : Factor w/ 4 levels "0","1","2","3": 4 4 4 4 4 4 4 4 4 4 ...
 $ canker.lesion  : Factor w/ 4 levels "0","1","2","3": 2 2 1 1 2 1 2 2 2 2 ...
 $ fruiting.bodies: Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
 $ ext.decay      : Factor w/ 3 levels "0","1","2": 2 2 2 2 2 2 2 2 2 2 ...
 $ mycelium       : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ int.discolor   : Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 1 1 ...
 $ sclerotia      : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ fruit.pods     : Factor w/ 4 levels "0","1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
 $ fruit.spots    : Factor w/ 4 levels "0","1","2","4": 4 4 4 4 4 4 4 4 4 4 ...
 $ seed           : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ mold.growth    : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ seed.discolor  : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ seed.size      : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ shriveling     : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ roots          : Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb212"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb212-1"><a href="#cb212-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Soybean)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 Class          date     plant.stand  precip      temp    
 brown-spot         : 92   5      :149   0   :354    0   : 74   0   : 80  
 alternarialeaf-spot: 91   4      :131   1   :293    1   :112   1   :374  
 frog-eye-leaf-spot : 91   3      :118   NA's: 36    2   :459   2   :199  
 phytophthora-rot   : 88   2      : 93               NA's: 38   NA's: 30  
 anthracnose        : 44   6      : 90                                    
 brown-stem-rot     : 44   (Other):101                                    
 (Other)            :233   NA's   :  1                                    
   hail     crop.hist  area.dam    sever     seed.tmt     germ     plant.growth
 0   :435   0   : 65   0   :123   0   :195   0   :305   0   :165   0   :441    
 1   :127   1   :165   1   :227   1   :322   1   :222   1   :213   1   :226    
 NA's:121   2   :219   2   :145   2   : 45   2   : 35   2   :193   NA's: 16    
            3   :218   3   :187   NA's:121   NA's:121   NA's:112               
            NA's: 16   NA's:  1                                                
                                                                               
                                                                               
 leaves  leaf.halo  leaf.marg  leaf.size  leaf.shread leaf.malf  leaf.mild 
 0: 77   0   :221   0   :357   0   : 51   0   :487    0   :554   0   :535  
 1:606   1   : 36   1   : 21   1   :327   1   : 96    1   : 45   1   : 20  
         2   :342   2   :221   2   :221   NA's:100    NA's: 84   2   : 20  
         NA's: 84   NA's: 84   NA's: 84                          NA's:108  
                                                                           
                                                                           
                                                                           
   stem     lodging    stem.cankers canker.lesion fruiting.bodies ext.decay 
 0   :296   0   :520   0   :379     0   :320      0   :473        0   :497  
 1   :371   1   : 42   1   : 39     1   : 83      1   :104        1   :135  
 NA's: 16   NA's:121   2   : 36     2   :177      NA's:106        2   : 13  
                       3   :191     3   : 65                      NA's: 38  
                       NA's: 38     NA's: 38                                
                                                                            
                                                                            
 mycelium   int.discolor sclerotia  fruit.pods fruit.spots   seed    
 0   :639   0   :581     0   :625   0   :407   0   :345    0   :476  
 1   :  6   1   : 44     1   : 20   1   :130   1   : 75    1   :115  
 NA's: 38   2   : 20     NA's: 38   2   : 14   2   : 57    NA's: 92  
            NA's: 38                3   : 48   4   :100              
                                    NA's: 84   NA's:106              
                                                                     
                                                                     
 mold.growth seed.discolor seed.size  shriveling  roots    
 0   :524    0   :513      0   :532   0   :539   0   :551  
 1   : 67    1   : 64      1   : 59   1   : 38   1   : 86  
 NA's: 92    NA's:106      NA's: 92   NA's:106   2   : 15  
                                                 NA's: 31  
                                                           
                                                           
                                                           </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb214"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a>degenerate_predictors <span class="ot">=</span> <span class="fu">sapply</span>(Soybean, <span class="cf">function</span>(x) </span>
<span id="cb214-2"><a href="#cb214-2" aria-hidden="true" tabindex="-1"></a>  {<span class="cf">if</span> (<span class="fu">is.factor</span>(x)) </span>
<span id="cb214-3"><a href="#cb214-3" aria-hidden="true" tabindex="-1"></a>    {<span class="fu">length</span>(<span class="fu">unique</span>(x)) <span class="sc">==</span> <span class="dv">1</span>}</span>
<span id="cb214-4"><a href="#cb214-4" aria-hidden="true" tabindex="-1"></a>   <span class="cf">else</span> {<span class="cn">FALSE</span>}})</span>
<span id="cb214-5"><a href="#cb214-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb214-6"><a href="#cb214-6" aria-hidden="true" tabindex="-1"></a>degenerate_predictors</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Class            date     plant.stand          precip            temp 
          FALSE           FALSE           FALSE           FALSE           FALSE 
           hail       crop.hist        area.dam           sever        seed.tmt 
          FALSE           FALSE           FALSE           FALSE           FALSE 
           germ    plant.growth          leaves       leaf.halo       leaf.marg 
          FALSE           FALSE           FALSE           FALSE           FALSE 
      leaf.size     leaf.shread       leaf.malf       leaf.mild            stem 
          FALSE           FALSE           FALSE           FALSE           FALSE 
        lodging    stem.cankers   canker.lesion fruiting.bodies       ext.decay 
          FALSE           FALSE           FALSE           FALSE           FALSE 
       mycelium    int.discolor       sclerotia      fruit.pods     fruit.spots 
          FALSE           FALSE           FALSE           FALSE           FALSE 
           seed     mold.growth   seed.discolor       seed.size      shriveling 
          FALSE           FALSE           FALSE           FALSE           FALSE 
          roots 
          FALSE </code></pre>
</div>
</div>
<p>According to the result, the Soybean dataset has no predictors that are degenerate.</p>
<p><strong>b) Roughly 18 % of the data are missing. Are there particular predictors that are more likely to be missing? Is the pattern of missing data related to the classes?</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb216"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb216-1"><a href="#cb216-1" aria-hidden="true" tabindex="-1"></a>aggr_plot <span class="ot">&lt;-</span> <span class="fu">aggr</span>(Soybean, <span class="at">col=</span><span class="fu">c</span>(<span class="st">'blue'</span>, <span class="st">'red'</span>), <span class="at">numbers=</span><span class="cn">TRUE</span>, <span class="at">sortVars=</span><span class="cn">TRUE</span>, </span>
<span id="cb216-2"><a href="#cb216-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">labels=</span><span class="fu">names</span>(Soybean), <span class="at">cex.axis=</span>.<span class="dv">85</span>, <span class="at">gap=</span><span class="dv">3</span>, </span>
<span id="cb216-3"><a href="#cb216-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">ylab=</span><span class="fu">c</span>(<span class="st">"Missing data"</span>,<span class="st">"Pattern"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-66-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 Variables sorted by number of missings: 
        Variable       Count
            hail 0.177159590
           sever 0.177159590
        seed.tmt 0.177159590
         lodging 0.177159590
            germ 0.163982430
       leaf.mild 0.158125915
 fruiting.bodies 0.155197657
     fruit.spots 0.155197657
   seed.discolor 0.155197657
      shriveling 0.155197657
     leaf.shread 0.146412884
            seed 0.134699854
     mold.growth 0.134699854
       seed.size 0.134699854
       leaf.halo 0.122986823
       leaf.marg 0.122986823
       leaf.size 0.122986823
       leaf.malf 0.122986823
      fruit.pods 0.122986823
          precip 0.055636896
    stem.cankers 0.055636896
   canker.lesion 0.055636896
       ext.decay 0.055636896
        mycelium 0.055636896
    int.discolor 0.055636896
       sclerotia 0.055636896
     plant.stand 0.052708638
           roots 0.045387994
            temp 0.043923865
       crop.hist 0.023426061
    plant.growth 0.023426061
            stem 0.023426061
            date 0.001464129
        area.dam 0.001464129
           Class 0.000000000
          leaves 0.000000000</code></pre>
</div>
</div>
<p>The highest proportion of missing data are as follows:</p>
<p>Hail - 17.7% Server - 17.7% Seed.tmt - 17.7% Germ - 16.4% lodging - 17.7% There are other in the 15% range, and in the 14%, and so on.</p>
<p>Most of the variables seem to be missing data, you have some variables that are not missing (class, and leaves). After looking at the visualization, the missing data does not have a relationship to classes.</p>
<p><strong>c) Develop a strategy for handling missing data, either by eliminating predictors or imputation.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb218"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb218-1"><a href="#cb218-1" aria-hidden="true" tabindex="-1"></a>missing_na <span class="ot">&lt;-</span> <span class="fu">colSums</span>(<span class="fu">is.na</span>(Soybean))</span>
<span id="cb218-2"><a href="#cb218-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-3"><a href="#cb218-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify predictors with more than 99 missing values</span></span>
<span id="cb218-4"><a href="#cb218-4" aria-hidden="true" tabindex="-1"></a>predictors_removed <span class="ot">&lt;-</span> <span class="fu">names</span>(missing_na[missing_na <span class="sc">&gt;</span> <span class="dv">99</span>])</span>
<span id="cb218-5"><a href="#cb218-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-6"><a href="#cb218-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a new dataset, now without the predictors  that have more than 99 missing values</span></span>
<span id="cb218-7"><a href="#cb218-7" aria-hidden="true" tabindex="-1"></a>Soybean_new <span class="ot">&lt;-</span> Soybean[, <span class="sc">!</span>(<span class="fu">names</span>(Soybean) <span class="sc">%in%</span> predictors_removed)]</span>
<span id="cb218-8"><a href="#cb218-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-9"><a href="#cb218-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary of the cleaned dataset</span></span>
<span id="cb218-10"><a href="#cb218-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Soybean_new)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 Class          date     plant.stand  precip      temp    
 brown-spot         : 92   5      :149   0   :354    0   : 74   0   : 80  
 alternarialeaf-spot: 91   4      :131   1   :293    1   :112   1   :374  
 frog-eye-leaf-spot : 91   3      :118   NA's: 36    2   :459   2   :199  
 phytophthora-rot   : 88   2      : 93               NA's: 38   NA's: 30  
 anthracnose        : 44   6      : 90                                    
 brown-stem-rot     : 44   (Other):101                                    
 (Other)            :233   NA's   :  1                                    
 crop.hist  area.dam   plant.growth leaves  leaf.halo  leaf.marg  leaf.size 
 0   : 65   0   :123   0   :441     0: 77   0   :221   0   :357   0   : 51  
 1   :165   1   :227   1   :226     1:606   1   : 36   1   : 21   1   :327  
 2   :219   2   :145   NA's: 16             2   :342   2   :221   2   :221  
 3   :218   3   :187                        NA's: 84   NA's: 84   NA's: 84  
 NA's: 16   NA's:  1                                                        
                                                                            
                                                                            
 leaf.malf    stem     stem.cankers canker.lesion ext.decay  mycelium  
 0   :554   0   :296   0   :379     0   :320      0   :497   0   :639  
 1   : 45   1   :371   1   : 39     1   : 83      1   :135   1   :  6  
 NA's: 84   NA's: 16   2   : 36     2   :177      2   : 13   NA's: 38  
                       3   :191     3   : 65      NA's: 38             
                       NA's: 38     NA's: 38                           
                                                                       
                                                                       
 int.discolor sclerotia  fruit.pods   seed     mold.growth seed.size 
 0   :581     0   :625   0   :407   0   :476   0   :524    0   :532  
 1   : 44     1   : 20   1   :130   1   :115   1   : 67    1   : 59  
 2   : 20     NA's: 38   2   : 14   NA's: 92   NA's: 92    NA's: 92  
 NA's: 38                3   : 48                                    
                         NA's: 84                                    
                                                                     
                                                                     
  roots    
 0   :551  
 1   : 86  
 2   : 15  
 NA's: 31  
           
           
           </code></pre>
</div>
</div>
<p>Explanation: Initially during part a, when I ran this model, I noticed variables that higher amounts of missing data. I decided to remove predictors that had more than 100 missing values and removing them accordingly. This way I can remove any variables that exceeds a specific number of missing values. Finally I create a new dataset that can be used for future analysis.</p>
<p>Brodnjak-Vonina et al.&nbsp;(2005) develop a methodology for food laboratories to determine the type of oil from a sample. In their procedure, they used a gas chromatograph (an instrument that separates chemicals in a sample) to measure seven different fatty acids in an oil. These measurements would then be used to predict the type of oil in food samples. To create their model, they used 96 samples2 of seven types of oils.</p>
<p>These data can be found in the caret package using data(oil). The oil types are contained in a factor variable called oilType. The types are pumpkin (coded as A), sunflower (B), peanut (C), olive (D), soybean (E), rapeseed (F) and corn (G). In R,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb220"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages("caret")</span></span>
<span id="cb220-2"><a href="#cb220-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb220-3"><a href="#cb220-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(oil)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb221"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb221-1"><a href="#cb221-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(oilType)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Factor w/ 7 levels "A","B","C","D",..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
</div>
<div class="sourceCode cell-code" id="cb223"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb223-1"><a href="#cb223-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb224"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb224-1"><a href="#cb224-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(oilType)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>oilType
 A  B  C  D  E  F  G 
37 26  3  7 11 10  2 </code></pre>
</div>
</div>
<p><strong>a) Use the sample function in base R to create a completely random sample of 60 oils. How closely do the frequencies of the random sample match the original samples? Repeat this procedure several times of understand the variation in the sampling process. </strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb226"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb226-1"><a href="#cb226-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb226-2"><a href="#cb226-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb226-3"><a href="#cb226-3" aria-hidden="true" tabindex="-1"></a>random_sample <span class="ot">&lt;-</span> <span class="fu">sample</span>(oilType, <span class="dv">60</span>, <span class="at">replace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb226-4"><a href="#cb226-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb226-5"><a href="#cb226-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparing frequencies for the random sample to the original data</span></span>
<span id="cb226-6"><a href="#cb226-6" aria-hidden="true" tabindex="-1"></a>random <span class="ot">&lt;-</span> <span class="fu">table</span>(random_sample)</span>
<span id="cb226-7"><a href="#cb226-7" aria-hidden="true" tabindex="-1"></a>original <span class="ot">&lt;-</span> <span class="fu">table</span>(oilType)</span>
<span id="cb226-8"><a href="#cb226-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb226-9"><a href="#cb226-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"Original Frequencies:"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Original Frequencies:"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb228"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb228-1"><a href="#cb228-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(original)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>oilType
 A  B  C  D  E  F  G 
37 26  3  7 11 10  2 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb230"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb230-1"><a href="#cb230-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb231"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb231-1"><a href="#cb231-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"Random Sample Frequencies:"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Random Sample Frequencies:"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb233"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(random)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>random_sample
 A  B  C  D  E  F  G 
24 17  3  3  6  5  2 </code></pre>
</div>
</div>
<ul>
<li>The random sample has the same frequencies for: C and G.</li>
<li>The random sample has lower frequencies for: A,B, D, E and F.</li>
</ul>
<p><strong>b) Use the caret package function createDataPartition to create a stratified random sample. How does this compare to completely random samples? </strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb235"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb235-1"><a href="#cb235-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Following same process as "a"</span></span>
<span id="cb235-2"><a href="#cb235-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb235-3"><a href="#cb235-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-4"><a href="#cb235-4" aria-hidden="true" tabindex="-1"></a><span class="co"># creating stratified random sample</span></span>
<span id="cb235-5"><a href="#cb235-5" aria-hidden="true" tabindex="-1"></a>stratified_sample <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> oilType, <span class="at">p =</span> <span class="fl">0.1</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb235-6"><a href="#cb235-6" aria-hidden="true" tabindex="-1"></a>stratified_data <span class="ot">&lt;-</span> oilType[stratified_sample]  </span>
<span id="cb235-7"><a href="#cb235-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-8"><a href="#cb235-8" aria-hidden="true" tabindex="-1"></a>stratified_data_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(stratified_data)</span>
<span id="cb235-9"><a href="#cb235-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-10"><a href="#cb235-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-11"><a href="#cb235-11" aria-hidden="true" tabindex="-1"></a>table_stratified <span class="ot">&lt;-</span> <span class="fu">table</span>(stratified_data_df)</span>
<span id="cb235-12"><a href="#cb235-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-13"><a href="#cb235-13" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Original Frequencies:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original Frequencies:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb237"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb237-1"><a href="#cb237-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(random)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>random_sample
 A  B  C  D  E  F  G 
24 17  3  3  6  5  2 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb239"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb239-1"><a href="#cb239-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print some space</span></span>
<span id="cb239-2"><a href="#cb239-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb240"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb240-1"><a href="#cb240-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print stratified sample frequencies</span></span>
<span id="cb240-2"><a href="#cb240-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Stratified Sample Frequencies:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Stratified Sample Frequencies:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb242"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb242-1"><a href="#cb242-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(table_stratified)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>stratified_data
A B C D E F G 
4 3 1 1 2 1 1 </code></pre>
</div>
</div>
<p>The values in the statified sample are much lower than the random sample. This is in part due to the stratified refined method, while the random sample looks at all variables within the dataset at random.</p>
<p><strong>c) With such a small samples size, what are the options for determining performance of the model? Should a test set be used? </strong></p>
<p>Methods such as K-fold, along with the train-test split method, could be an option for determining performance of the refined model.</p>
<p><strong>d) One method for understanding the uncertainty of a test set is to use a confidence interval. To obtain a confidence interval for the overall accuracy, the based R function binom.test can be used. It requires the user to input the number of samples and the number correctly classified to calculate the interval. For example, suppose a test set sample of 20 oil samples was set aside and 76 were used for model training. For this test set size and a model that is about 80 % accurate (16 out of 20 correct), the confidence interval would be computed using</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb244"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb244-1"><a href="#cb244-1" aria-hidden="true" tabindex="-1"></a>binomial_result1 <span class="ot">=</span> <span class="fu">binom.test</span>(<span class="dv">16</span>, <span class="dv">20</span>)</span>
<span id="cb244-2"><a href="#cb244-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(binomial_result1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Exact binomial test

data:  16 and 20
number of successes = 16, number of trials = 20, p-value = 0.01182
alternative hypothesis: true probability of success is not equal to 0.5
95 percent confidence interval:
 0.563386 0.942666
sample estimates:
probability of success 
                   0.8 </code></pre>
</div>
</div>
<p>In this case, the width of the 95% confidence interval is 37.9 %, and accuracy 80%.</p>
<p><strong>Try different samples sizes and accuracy rates to understand the trade-off between the uncertainty in the results, the model performance, and the test set size.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb246"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb246-1"><a href="#cb246-1" aria-hidden="true" tabindex="-1"></a>binom_result2 <span class="ot">&lt;-</span> <span class="fu">binom.test</span>(<span class="dv">41</span>, <span class="dv">50</span>)</span>
<span id="cb246-2"><a href="#cb246-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb246-3"><a href="#cb246-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(binom_result2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Exact binomial test

data:  41 and 50
number of successes = 41, number of trials = 50, p-value = 5.614e-06
alternative hypothesis: true probability of success is not equal to 0.5
95 percent confidence interval:
 0.6856306 0.9142379
sample estimates:
probability of success 
                  0.82 </code></pre>
</div>
</div>
<p>In this case, the width of the 95% confidence interval is 22.9% and accuracy 82%</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb248"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb248-1"><a href="#cb248-1" aria-hidden="true" tabindex="-1"></a>binom_result3 <span class="ot">&lt;-</span> <span class="fu">binom.test</span>(<span class="dv">90</span>, <span class="dv">100</span>)</span>
<span id="cb248-2"><a href="#cb248-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb248-3"><a href="#cb248-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(binom_result3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Exact binomial test

data:  90 and 100
number of successes = 90, number of trials = 100, p-value &lt; 2.2e-16
alternative hypothesis: true probability of success is not equal to 0.5
95 percent confidence interval:
 0.8237774 0.9509953
sample estimates:
probability of success 
                   0.9 </code></pre>
</div>
</div>
<p>In this case, the width of the 95% confidence interval is 12.7%, and accuracy 90%</p>
<p>In conclusion, I noticed that as the sample size increases it reduces the confidence level. However, as the accuracy rate increases it tends to reduce the interval width.</p>
<p>Briefly discuss what is the bias-variance tradeoff in statistics and predictive modeling.</p>
<p>The bias-variance tradeoff is when we chose lower bias which increases variance or lower variance increases bias. The objective is to find a good balance meaning that both bias and variance are at minimal.</p>
</section>
<section id="predicting-fat-content-in-meat-using-ir-spectroscopy-and-machine-learning-a-comparative-study-of-predictive-models" class="level1">
<h1>Predicting Fat Content in Meat Using IR Spectroscopy and Machine Learning: A Comparative Study of Predictive Models</h1>
<p>Infrared (IR) spectroscopy technology is used to determine the chemical makeup of a substance. The theory of IR spectroscopy holds that unique molecular structures absorb IR frequencies differently. In practice a spectrometer fires a series of IR frequencies into a sample material, and the device measures the absorbance of the sample at each individual frequency. This series of measurements creates a spectrum profile which can then be used to determine the chemical makeup of the sample material.</p>
<p>A Tecator Infratec Food and Feed Analyzer instrument was used to analyze 215 samples of meat across 100 frequencies. A sample of these frequency profiles is displayed in Fig. 6.20. In addition to an IR profile, analytical chemistry determined the percent content of water, fat, and protein for each sample. If we can establish a predictive relationship between IR spectrum and fat content, then food scientists could predict a sample’s fat content with IR instead of using analytical chemistry. This would provide costs savings, since analytical chemistry is a more expensive, time-consuming process.</p>
<p><strong>a) Start R and use these commands to load the data:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb250"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb250-1"><a href="#cb250-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb250-2"><a href="#cb250-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb250-3"><a href="#cb250-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nnet)</span>
<span id="cb250-4"><a href="#cb250-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(earth)</span>
<span id="cb250-5"><a href="#cb250-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kernlab)</span>
<span id="cb250-6"><a href="#cb250-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pls)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'pls'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:caret':

    R2</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:corrplot':

    corrplot</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:LearnBayes':

    predplot</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:stats':

    loadings</code></pre>
</div>
<div class="sourceCode cell-code" id="cb256"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb256-1"><a href="#cb256-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kknn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'kknn' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'kknn'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:caret':

    contr.dummy</code></pre>
</div>
<div class="sourceCode cell-code" id="cb260"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb260-1"><a href="#cb260-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(tecator)</span>
<span id="cb260-2"><a href="#cb260-2" aria-hidden="true" tabindex="-1"></a>?tecator </span>
<span id="cb260-3"><a href="#cb260-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(absorp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:215, 1:100] 2.62 2.83 2.58 2.82 2.79 ...</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb262"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb262-1"><a href="#cb262-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(endpoints)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:215, 1:3] 60.5 46 71 72.8 58.3 44 44 69.3 61.4 61.4 ...</code></pre>
</div>
</div>
<p><strong>The matrix absorp contains the 100 absorbance values for the 215 samples, while matrix endpoints contain the percent of moisture, fat, and protein in columns 1–3, respectively. To be more specific</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb264"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb264-1"><a href="#cb264-1" aria-hidden="true" tabindex="-1"></a>moisture <span class="ot">=</span> endpoints[,<span class="dv">1</span>]</span>
<span id="cb264-2"><a href="#cb264-2" aria-hidden="true" tabindex="-1"></a>fat <span class="ot">=</span> endpoints[,<span class="dv">2</span>]</span>
<span id="cb264-3"><a href="#cb264-3" aria-hidden="true" tabindex="-1"></a>protein <span class="ot">=</span> endpoints[,<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>b) Split the data into a training and a test set the response of the percentage of protein, pre-process the data as appropriate.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb265"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb265-1"><a href="#cb265-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb265-2"><a href="#cb265-2" aria-hidden="true" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(protein, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb265-3"><a href="#cb265-3" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(absorp[index, ], <span class="at">protein =</span> protein[index])</span>
<span id="cb265-4"><a href="#cb265-4" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(absorp[<span class="sc">-</span>index, ], <span class="at">protein =</span> protein[<span class="sc">-</span>index])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb266"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb266-1"><a href="#cb266-1" aria-hidden="true" tabindex="-1"></a>combined_data <span class="ot">&lt;-</span> <span class="fu">rbind</span>(train_data, test_data)</span>
<span id="cb266-2"><a href="#cb266-2" aria-hidden="true" tabindex="-1"></a>preProcess <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(combined_data[, <span class="sc">-</span><span class="fu">ncol</span>(combined_data)], <span class="at">method =</span> <span class="st">"pca"</span>, <span class="at">pcaComp =</span> <span class="dv">20</span>)</span>
<span id="cb266-3"><a href="#cb266-3" aria-hidden="true" tabindex="-1"></a>combined_pca <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcess, combined_data[, <span class="sc">-</span><span class="fu">ncol</span>(combined_data)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb267"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb267-1"><a href="#cb267-1" aria-hidden="true" tabindex="-1"></a>n_train <span class="ot">&lt;-</span> <span class="fu">nrow</span>(train_data)</span>
<span id="cb267-2"><a href="#cb267-2" aria-hidden="true" tabindex="-1"></a>train_pca <span class="ot">&lt;-</span> <span class="fu">cbind</span>(combined_pca[<span class="dv">1</span><span class="sc">:</span>n_train, ], <span class="at">protein =</span> train_data<span class="sc">$</span>protein)</span>
<span id="cb267-3"><a href="#cb267-3" aria-hidden="true" tabindex="-1"></a>test_pca <span class="ot">&lt;-</span> <span class="fu">cbind</span>(combined_pca[(n_train <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">:</span><span class="fu">nrow</span>(combined_data), ], <span class="at">protein =</span> test_data<span class="sc">$</span>protein)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>c) Build at least three models described Chapter 6: ordinary least squares, PCR, PLS, Ridge, and ENET. For those models with tuning parameters, what are the optimal values of the tuning parameter(s)?</strong></p>
<p><strong>Ordinary Least Squares (OLS):</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb268"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb268-1"><a href="#cb268-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb268-2"><a href="#cb268-2" aria-hidden="true" tabindex="-1"></a>ols_model <span class="ot">&lt;-</span> <span class="fu">train</span>(protein <span class="sc">~</span> ., <span class="at">data =</span> train_pca, <span class="at">method =</span> <span class="st">"lm"</span>)</span>
<span id="cb268-3"><a href="#cb268-3" aria-hidden="true" tabindex="-1"></a>ols_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear Regression 

152 samples
 20 predictor

No pre-processing
Resampling: Bootstrapped (25 reps) 
Summary of sample sizes: 152, 152, 152, 152, 152, 152, ... 
Resampling results:

  RMSE       Rsquared   MAE      
  0.7268192  0.9450398  0.5549019

Tuning parameter 'intercept' was held constant at a value of TRUE</code></pre>
</div>
</div>
<p><u><strong>OLS - Linear Regression:</strong></u></p>
<ul>
<li><p>RMSE: 0.7268192</p></li>
<li><p>R-squared: 0.9450398</p></li>
<li><p>MAE: 0.5549019</p></li>
</ul>
<p><strong>Principal Component Regression (PCR):</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb270"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb270-1"><a href="#cb270-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb270-2"><a href="#cb270-2" aria-hidden="true" tabindex="-1"></a>pcr_model <span class="ot">&lt;-</span> <span class="fu">train</span>(protein <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">"pcr"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>))</span>
<span id="cb270-3"><a href="#cb270-3" aria-hidden="true" tabindex="-1"></a>pcr_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Principal Component Analysis 

152 samples
100 predictors

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 136, 137, 137, 137, 136, 138, ... 
Resampling results across tuning parameters:

  ncomp  RMSE      Rsquared   MAE     
  1      2.966122  0.1570382  2.520911
  2      2.854048  0.1843866  2.337577
  3      2.316586  0.4545058  1.848556

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was ncomp = 3.</code></pre>
</div>
</div>
<p><u><strong>Principal Component Regression (PCR):</strong></u></p>
<ul>
<li><p>ncomp: 3</p></li>
<li><p>RMSE: 2.316586</p></li>
<li><p>R-squared: 0.4545058</p></li>
<li><p>MAE: 1.848556</p></li>
</ul>
<p><strong>Partial Least Squares (PLS):</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb272"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb272-1"><a href="#cb272-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb272-2"><a href="#cb272-2" aria-hidden="true" tabindex="-1"></a>pls_model <span class="ot">&lt;-</span> <span class="fu">train</span>(protein <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">"pls"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>))</span>
<span id="cb272-3"><a href="#cb272-3" aria-hidden="true" tabindex="-1"></a>pls_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Partial Least Squares 

152 samples
100 predictors

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 136, 137, 137, 137, 136, 138, ... 
Resampling results across tuning parameters:

  ncomp  RMSE      Rsquared   MAE     
  1      2.959109  0.1580897  2.511023
  2      2.256430  0.5094219  1.788162
  3      1.743833  0.6963113  1.291007

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was ncomp = 3.</code></pre>
</div>
</div>
<p><u><strong>Partial Least Squares (PLS):</strong></u></p>
<ul>
<li><p>ncomp: 3</p></li>
<li><p>RMSE: 1.743833</p></li>
<li><p>R-squared: 0.6963113</p></li>
<li><p>MAE: 1.291007</p></li>
</ul>
<p><strong>d) Build nonlinear models in Chapter 7: SVM, neural network, MARS, and KNN models. Since neural networks are especially sensitive to highly correlated predictors, does pre-processing using PCA help the model? For those models with tuning parameters, what are the optimal values of the tuning parameter(s)?</strong></p>
<p><strong>Support Vector Machine (SVM)</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb274"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb274-1"><a href="#cb274-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb274-2"><a href="#cb274-2" aria-hidden="true" tabindex="-1"></a>svm_model <span class="ot">&lt;-</span> <span class="fu">train</span>(protein <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">"svmRadial"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>), <span class="at">tuneLength =</span> <span class="dv">10</span>)</span>
<span id="cb274-3"><a href="#cb274-3" aria-hidden="true" tabindex="-1"></a>svm_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Support Vector Machines with Radial Basis Function Kernel 

152 samples
100 predictors

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 136, 137, 137, 137, 136, 138, ... 
Resampling results across tuning parameters:

  C       RMSE      Rsquared   MAE     
    0.25  2.683055  0.3123868  2.126981
    0.50  2.431071  0.4167549  1.921845
    1.00  2.135216  0.5501123  1.656360
    2.00  1.934330  0.6259364  1.506506
    4.00  1.812361  0.6698215  1.397221
    8.00  1.744285  0.6980792  1.333155
   16.00  1.717343  0.7085363  1.317764
   32.00  1.676734  0.7178974  1.272854
   64.00  1.805285  0.6829508  1.316395
  128.00  1.910920  0.6787767  1.327847

Tuning parameter 'sigma' was held constant at a value of 0.05200074
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were sigma = 0.05200074 and C = 32.</code></pre>
</div>
</div>
<p><u><strong>SVM:</strong></u></p>
<ul>
<li><p>C: 32</p></li>
<li><p>sigma: 0.05200074</p></li>
<li><p>RMSE: 1.676734</p></li>
<li><p>R-squared: 0.7178974</p></li>
<li><p>MAE: 1.272854</p></li>
</ul>
<p><strong>Neural Network (NN):</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb276"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb276-1"><a href="#cb276-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb276-2"><a href="#cb276-2" aria-hidden="true" tabindex="-1"></a>nn_model <span class="ot">&lt;-</span> <span class="fu">train</span>(protein <span class="sc">~</span> ., <span class="at">data =</span> train_pca, <span class="at">method =</span> <span class="st">"nnet"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>), <span class="at">tuneLength =</span> <span class="dv">10</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,
: There were missing values in resampled performance measures.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb278"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb278-1"><a href="#cb278-1" aria-hidden="true" tabindex="-1"></a>nn_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Neural Network 

152 samples
 20 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 136, 137, 137, 137, 136, 138, ... 
Resampling results across tuning parameters:

  size  decay         RMSE      Rsquared    MAE     
   1    0.0000000000  16.94374         NaN  16.66501
   1    0.0001000000  16.94374  0.14978364  16.66501
   1    0.0002371374  16.94374  0.12567105  16.66501
   1    0.0005623413  16.94374  0.23506957  16.66501
   1    0.0013335214  16.94374  0.22929835  16.66501
   1    0.0031622777  16.94375  0.36449463  16.66502
   1    0.0074989421  16.94376  0.28410002  16.66503
   1    0.0177827941  16.94378  0.37009598  16.66505
   1    0.0421696503  16.94383  0.43328160  16.66510
   1    0.1000000000  16.94394  0.43121217  16.66522
   3    0.0000000000  16.94374         NaN  16.66501
   3    0.0001000000  16.94374  0.05872841  16.66501
   3    0.0002371374  16.94374  0.06529164  16.66501
   3    0.0005623413  16.94374  0.13473509  16.66501
   3    0.0013335214  16.94374  0.08244673  16.66501
   3    0.0031622777  16.94374  0.28238535  16.66501
   3    0.0074989421  16.94375  0.41696389  16.66502
   3    0.0177827941  16.94376  0.42169655  16.66503
   3    0.0421696503  16.94380  0.36330231  16.66507
   3    0.1000000000  16.94387  0.39924295  16.66515
   5    0.0000000000  16.94374         NaN  16.66501
   5    0.0001000000  16.94374  0.04037119  16.66501
   5    0.0002371374  16.94374  0.09412361  16.66501
   5    0.0005623413  16.94374  0.12538589  16.66501
   5    0.0013335214  16.94374  0.10079018  16.66501
   5    0.0031622777  16.94374  0.22678453  16.66501
   5    0.0074989421  16.94375  0.40603294  16.66502
   5    0.0177827941  16.94376  0.39381393  16.66503
   5    0.0421696503  16.94379  0.39586586  16.66506
   5    0.1000000000  16.94385  0.38722123  16.66512
   7    0.0000000000  16.94374         NaN  16.66501
   7    0.0001000000  16.94374  0.05679502  16.66501
   7    0.0002371374  16.94374  0.10851811  16.66501
   7    0.0005623413  16.94374  0.06909546  16.66501
   7    0.0013335214  16.94374  0.13320589  16.66501
   7    0.0031622777  16.94374  0.23264217  16.66501
   7    0.0074989421  16.94375  0.29182176  16.66502
   7    0.0177827941  16.94376  0.35007398  16.66503
   7    0.0421696503  16.94378  0.28503256  16.66505
   7    0.1000000000  16.94384  0.32305081  16.66511
   9    0.0000000000  16.94374         NaN  16.66501
   9    0.0001000000  16.94374  0.07837021  16.66501
   9    0.0002371374  16.94374  0.08903918  16.66501
   9    0.0005623413  16.94374  0.08068229  16.66501
   9    0.0013335214  16.94374  0.08148662  16.66501
   9    0.0031622777  16.94374  0.22060992  16.66501
   9    0.0074989421  16.94374  0.24151517  16.66501
   9    0.0177827941  16.94375  0.36487565  16.66502
   9    0.0421696503  16.94378  0.39001464  16.66505
   9    0.1000000000  16.94382  0.40309815  16.66510
  11    0.0000000000  16.94374         NaN  16.66501
  11    0.0001000000  16.94374  0.08534898  16.66501
  11    0.0002371374  16.94374  0.05052102  16.66501
  11    0.0005623413  16.94374  0.05491134  16.66501
  11    0.0013335214  16.94374  0.07165259  16.66501
  11    0.0031622777  16.94374  0.10939340  16.66501
  11    0.0074989421  16.94374  0.28477069  16.66501
  11    0.0177827941  16.94375  0.27494690  16.66502
  11    0.0421696503  16.94377  0.35160466  16.66504
  11    0.1000000000  16.94382  0.32616988  16.66509
  13    0.0000000000  16.94374         NaN  16.66501
  13    0.0001000000  16.94374  0.07206534  16.66501
  13    0.0002371374  16.94374  0.03338102  16.66501
  13    0.0005623413  16.94374  0.10199462  16.66501
  13    0.0013335214  16.94374  0.07235802  16.66501
  13    0.0031622777  16.94374  0.07123641  16.66501
  13    0.0074989421  16.94374  0.16657309  16.66501
  13    0.0177827941  16.94375  0.30535658  16.66502
  13    0.0421696503  16.94377  0.27075772  16.66504
  13    0.1000000000  16.94381  0.29249124  16.66508
  15    0.0000000000  16.94374         NaN  16.66501
  15    0.0001000000  16.94374  0.16676854  16.66501
  15    0.0002371374  16.94374  0.12257102  16.66501
  15    0.0005623413  16.94374  0.09188033  16.66501
  15    0.0013335214  16.94374  0.10349543  16.66501
  15    0.0031622777  16.94374  0.04629168  16.66501
  15    0.0074989421  16.94374  0.12201012  16.66501
  15    0.0177827941  16.94375  0.24663325  16.66502
  15    0.0421696503  16.94377  0.29833891  16.66504
  15    0.1000000000  16.94381  0.32152626  16.66508
  17    0.0000000000  16.94374         NaN  16.66501
  17    0.0001000000  16.94374  0.11594246  16.66501
  17    0.0002371374  16.94374  0.07114745  16.66501
  17    0.0005623413  16.94374  0.09299386  16.66501
  17    0.0013335214  16.94374  0.06510852  16.66501
  17    0.0031622777  16.94374  0.06360193  16.66501
  17    0.0074989421  16.94375  0.11744827  16.66501
  17    0.0177827941  16.94375  0.24397690  16.66502
  17    0.0421696503  16.94377  0.16413717  16.66504
  17    0.1000000000  16.94380  0.28505783  16.66507
  19    0.0000000000  16.94374         NaN  16.66501
  19    0.0001000000  16.94374  0.08433063  16.66501
  19    0.0002371374  16.94374  0.09962678  16.66501
  19    0.0005623413  16.94374  0.09972566  16.66501
  19    0.0013335214  16.94374  0.19852311  16.66501
  19    0.0031622777  16.94374  0.04105236  16.66501
  19    0.0074989421  16.94374  0.14339708  16.66501
  19    0.0177827941  16.94375  0.19480536  16.66502
  19    0.0421696503  16.94377  0.29160005  16.66504
  19    0.1000000000  16.94380  0.25396402  16.66507

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were size = 1 and decay = 0.</code></pre>
</div>
</div>
<p><u><strong>Neural Network:</strong></u></p>
<ul>
<li><p>size: 1</p></li>
<li><p>decay: 0</p></li>
<li><p>RMSE: 16.94374</p></li>
<li><p>R-squared: NA</p></li>
<li><p>MAE: 16.66501</p></li>
</ul>
<p><strong>Multivariate Adaptive Regression Splines (MARS):</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb280"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb280-1"><a href="#cb280-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb280-2"><a href="#cb280-2" aria-hidden="true" tabindex="-1"></a>mars_model <span class="ot">&lt;-</span> <span class="fu">train</span>(protein <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">"earth"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>))</span>
<span id="cb280-3"><a href="#cb280-3" aria-hidden="true" tabindex="-1"></a>mars_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Multivariate Adaptive Regression Spline 

152 samples
100 predictors

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 136, 137, 137, 137, 136, 138, ... 
Resampling results across tuning parameters:

  nprune  RMSE      Rsquared   MAE      
   2      2.854067  0.1814645  2.3879962
  15      1.212796  0.8517258  0.9221938
  28      1.357497  0.8313863  0.9689615

Tuning parameter 'degree' was held constant at a value of 1
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nprune = 15 and degree = 1.</code></pre>
</div>
</div>
<p><u><strong>MARS:</strong></u></p>
<ul>
<li><p>nprune: 15</p></li>
<li><p>degree: 1</p></li>
<li><p>RMSE: 1.212796</p></li>
<li><p>R-squared: 0.8517258</p></li>
<li><p>MAE: 0.9221938</p></li>
</ul>
<p><strong>k-Nearest Neighbors (kNN):</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb282"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb282-1"><a href="#cb282-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb282-2"><a href="#cb282-2" aria-hidden="true" tabindex="-1"></a>knn_model <span class="ot">&lt;-</span> <span class="fu">train</span>(protein <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">"knn"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>), <span class="at">tuneLength =</span> <span class="dv">10</span>)</span>
<span id="cb282-3"><a href="#cb282-3" aria-hidden="true" tabindex="-1"></a>knn_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>k-Nearest Neighbors 

152 samples
100 predictors

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 136, 137, 137, 137, 136, 138, ... 
Resampling results across tuning parameters:

  k   RMSE      Rsquared   MAE     
   5  2.300655  0.4780876  1.909033
   7  2.453521  0.3946490  2.032608
   9  2.511651  0.3773289  2.075073
  11  2.550576  0.3616637  2.087163
  13  2.619400  0.3441352  2.145169
  15  2.654108  0.3080377  2.188281
  17  2.716741  0.2774054  2.239304
  19  2.716383  0.2760947  2.254749
  21  2.773202  0.2384392  2.297991
  23  2.789007  0.2262430  2.320930

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was k = 5.</code></pre>
</div>
</div>
<p><u><strong>kNN:</strong></u></p>
<ul>
<li><p>k: 5</p></li>
<li><p>RMSE: 2.300655</p></li>
<li><p>squared: 0.4780876</p></li>
<li><p>MAE: 1.909033</p></li>
</ul>
<p><strong>e) Which model from parts c) and d) has the best predictive ability? Is any model significantly better or worse than the others?</strong></p>
<table class="table">
<colgroup>
<col style="width: 34%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>RMSE</th>
<th>Rsquared</th>
<th>MAE</th>
<th>Rank</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>OLS - Linear Regression</td>
<td>0.7268192</td>
<td>0.9450398</td>
<td>0.5549019</td>
<td>1</td>
</tr>
<tr class="even">
<td>Principal Component Regression (PCR)</td>
<td>2.316586</td>
<td>0.4545058</td>
<td>1.848556</td>
<td>6</td>
</tr>
<tr class="odd">
<td>Partial Least Squares (PLS)</td>
<td>1.743833</td>
<td>0.6963113</td>
<td>1.291007</td>
<td>4</td>
</tr>
<tr class="even">
<td>SVM</td>
<td>1.676734</td>
<td>0.7178974</td>
<td>1.272854</td>
<td>3</td>
</tr>
<tr class="odd">
<td>Neural Network</td>
<td>16.94374</td>
<td>NA</td>
<td>16.66501</td>
<td>7</td>
</tr>
<tr class="even">
<td>MARS</td>
<td>1.212796</td>
<td>0.8517258</td>
<td>0.9221938</td>
<td>2</td>
</tr>
<tr class="odd">
<td>kNN</td>
<td>2.300655</td>
<td>0.478087</td>
<td>1.909033</td>
<td>5</td>
</tr>
</tbody>
</table>
<p>In conclusion, I have ranked the models according to the criteria of lowest RMSE, and lowest MAE, and high rsquared. The OLS - Linear Regression outperforms all other models, followed by the MARS. The Nueral Network model performs the worst out of all the other models as it has the highest RMSE and the rsquared is not available.</p>
<p><strong>Developing a model to predict permeability (see Sect. 1.4 of the textbook) could save significant resources for a pharmaceutical company, while at the same time more rapidly identifying molecules that have a sufficient permeability to become a drug:</strong></p>
<p><strong>a) Start R and use these commands to load the data:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb284"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb284-1"><a href="#cb284-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AppliedPredictiveModeling) </span>
<span id="cb284-2"><a href="#cb284-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(permeability)</span>
<span id="cb284-3"><a href="#cb284-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(fingerprints)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:165, 1:1107] 0 0 0 0 0 0 0 0 0 0 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:165] "1" "2" "3" "4" ...
  ..$ : chr [1:1107] "X1" "X2" "X3" "X4" ...</code></pre>
</div>
<div class="sourceCode cell-code" id="cb286"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb286-1"><a href="#cb286-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(permeability)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:165, 1] 12.52 1.12 19.41 1.73 1.68 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:165] "1" "2" "3" "4" ...
  ..$ : chr "permeability"</code></pre>
</div>
</div>
<p>The matrix fingerprints contains the 1,107 binary molecular predictors for the 165 compounds, while permeability contains permeability response:</p>
<p><strong>b) The fingerprint predictors indicate the presence or absence of substructures of a molecule and are often sparse meaning that relatively few of the molecules contain each substructure. Filter out the predictors that have low frequencies using the nearZeroVar function from the caret package. How many predictors are left for modeling?</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb288"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb288-1"><a href="#cb288-1" aria-hidden="true" tabindex="-1"></a>nzv <span class="ot">&lt;-</span> <span class="fu">nearZeroVar</span>(fingerprints, <span class="at">saveMetrics =</span> <span class="cn">TRUE</span>)</span>
<span id="cb288-2"><a href="#cb288-2" aria-hidden="true" tabindex="-1"></a>filtered_fingerprints <span class="ot">&lt;-</span> fingerprints[, <span class="sc">!</span>nzv<span class="sc">$</span>nzv]</span>
<span id="cb288-3"><a href="#cb288-3" aria-hidden="true" tabindex="-1"></a>predictors_left <span class="ot">&lt;-</span> <span class="fu">ncol</span>(filtered_fingerprints)</span>
<span id="cb288-4"><a href="#cb288-4" aria-hidden="true" tabindex="-1"></a>predictors_left</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 388</code></pre>
</div>
</div>
<p>There are 388 predictors left.</p>
<p><strong>c) Split the data into a training and a test set, pre-process the data, and tune a PLS model. How many latent variables are optimal and what is the corresponding resampled estimate of R2?</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb290"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb290-1"><a href="#cb290-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb290-2"><a href="#cb290-2" aria-hidden="true" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(permeability, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb290-3"><a href="#cb290-3" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> filtered_fingerprints[index, ]</span>
<span id="cb290-4"><a href="#cb290-4" aria-hidden="true" tabindex="-1"></a>train_permeability <span class="ot">&lt;-</span> permeability[index]</span>
<span id="cb290-5"><a href="#cb290-5" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> filtered_fingerprints[<span class="sc">-</span>index, ]</span>
<span id="cb290-6"><a href="#cb290-6" aria-hidden="true" tabindex="-1"></a>test_permeability <span class="ot">&lt;-</span> permeability[<span class="sc">-</span>index]</span>
<span id="cb290-7"><a href="#cb290-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb290-8"><a href="#cb290-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Preprocess the data (center and scale)</span></span>
<span id="cb290-9"><a href="#cb290-9" aria-hidden="true" tabindex="-1"></a>preProcValues <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(train_data, <span class="at">method =</span> <span class="fu">c</span>(<span class="st">"center"</span>, <span class="st">"scale"</span>))</span>
<span id="cb290-10"><a href="#cb290-10" aria-hidden="true" tabindex="-1"></a>train_data_transformed <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcValues, train_data)</span>
<span id="cb290-11"><a href="#cb290-11" aria-hidden="true" tabindex="-1"></a>test_data_transformed <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcValues, test_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>PLS</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb291"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb291-1"><a href="#cb291-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb291-2"><a href="#cb291-2" aria-hidden="true" tabindex="-1"></a>pls2_model <span class="ot">&lt;-</span> <span class="fu">train</span>(train_data_transformed, train_permeability, <span class="at">method =</span> <span class="st">"pls"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>), <span class="at">tuneLength =</span> <span class="dv">10</span>)</span>
<span id="cb291-3"><a href="#cb291-3" aria-hidden="true" tabindex="-1"></a>pls2_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Partial Least Squares 

117 samples
388 predictors

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 105, 105, 106, 105, 105, 105, ... 
Resampling results across tuning parameters:

  ncomp  RMSE      Rsquared   MAE      
   1     13.36436  0.3433889  10.474224
   2     12.30920  0.4595424   8.621998
   3     12.79841  0.4713902   9.518968
   4     13.01506  0.4586135   9.759753
   5     13.50115  0.4188773   9.868189
   6     13.28765  0.4391301   9.680872
   7     12.89540  0.4604643   9.314659
   8     12.82966  0.4653079   9.399587
   9     12.94528  0.4583512   9.434668
  10     13.30683  0.4341421   9.892463

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was ncomp = 2.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb293"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb293-1"><a href="#cb293-1" aria-hidden="true" tabindex="-1"></a>resampled_r2 <span class="ot">&lt;-</span> <span class="fu">max</span>(pls2_model<span class="sc">$</span>results<span class="sc">$</span>Rsquared)</span>
<span id="cb293-2"><a href="#cb293-2" aria-hidden="true" tabindex="-1"></a>resampled_r2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4713902</code></pre>
</div>
</div>
<p><u><strong>PLS Model:</strong></u></p>
<ul>
<li><p>ncomp: 2</p></li>
<li><p>RMSE: 12.30920</p></li>
<li><p>Rsquared: 0.4595424</p></li>
<li><p>MAE: 8.621998</p></li>
<li><p>resampled R2: 0.4713902</p></li>
</ul>
<p>There are 2 optimal latent variables and the resampled estimate rsquared is 0.4713902.</p>
<p><strong>d) Predict the response for the test set. What is the test set estimate of R2?</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb295"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb295-1"><a href="#cb295-1" aria-hidden="true" tabindex="-1"></a>pls2_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(pls2_model, test_data_transformed)</span>
<span id="cb295-2"><a href="#cb295-2" aria-hidden="true" tabindex="-1"></a>pls2_r2 <span class="ot">&lt;-</span> <span class="fu">cor</span>(pls2_pred, test_permeability)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb295-3"><a href="#cb295-3" aria-hidden="true" tabindex="-1"></a>pls2_r2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.3819407</code></pre>
</div>
</div>
<p>The test set of rsquared is 0.3819407.</p>
<p><strong>e) Try building other models discussed in this chapter. Do any have better predictive performance?</strong></p>
<p><strong>Support Vector Machine (SVM)</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb297"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb297-1"><a href="#cb297-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb297-2"><a href="#cb297-2" aria-hidden="true" tabindex="-1"></a>svm2_model <span class="ot">&lt;-</span> <span class="fu">train</span>(train_data, train_permeability, <span class="at">method =</span> <span class="st">"svmRadial"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>), <span class="at">tuneLength =</span> <span class="dv">10</span>)</span>
<span id="cb297-3"><a href="#cb297-3" aria-hidden="true" tabindex="-1"></a>svm2_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Support Vector Machines with Radial Basis Function Kernel 

117 samples
388 predictors

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 105, 105, 106, 105, 105, 105, ... 
Resampling results across tuning parameters:

  C       RMSE      Rsquared   MAE     
    0.25  13.31509  0.4937223  8.559747
    0.50  12.03042  0.5011860  7.954428
    1.00  11.71028  0.5103354  7.664866
    2.00  11.87293  0.4929464  7.786952
    4.00  12.17146  0.4658056  8.201456
    8.00  12.33716  0.4474256  8.447651
   16.00  12.33661  0.4453930  8.476095
   32.00  12.29978  0.4482620  8.468869
   64.00  12.27952  0.4499855  8.465674
  128.00  12.27952  0.4499855  8.465674

Tuning parameter 'sigma' was held constant at a value of 0.003241275
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were sigma = 0.003241275 and C = 1.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb299"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb299-1"><a href="#cb299-1" aria-hidden="true" tabindex="-1"></a>svm2_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(svm2_model, test_data)</span>
<span id="cb299-2"><a href="#cb299-2" aria-hidden="true" tabindex="-1"></a>svm2_r2 <span class="ot">&lt;-</span> <span class="fu">cor</span>(svm2_pred, test_permeability)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb299-3"><a href="#cb299-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb300"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb300-1"><a href="#cb300-1" aria-hidden="true" tabindex="-1"></a>svm2_r2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4394321</code></pre>
</div>
</div>
<p><u><strong>Support Vector Machine (SVM):</strong></u></p>
<ul>
<li>sigma: 0.003241275</li>
<li>C: 1</li>
<li>RMSE: 11.71028</li>
<li>rsquared: 0.5103354</li>
<li>MAE: 7.664866</li>
</ul>
<p>The Test Set of rsquared: 0.4394321</p>
<p><strong>Ridge Regression</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb302"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb302-1"><a href="#cb302-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb302-2"><a href="#cb302-2" aria-hidden="true" tabindex="-1"></a>ridge2_model <span class="ot">&lt;-</span> <span class="fu">train</span>(train_data, train_permeability, <span class="at">method =</span> <span class="st">"ridge"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>), <span class="at">tuneLength =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: lambda=0.0000000 Error in if (zmin &lt; gamhat) { : missing value where TRUE/FALSE needed</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,
: There were missing values in resampled performance measures.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb305"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb305-1"><a href="#cb305-1" aria-hidden="true" tabindex="-1"></a>ridge2_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ridge Regression 

117 samples
388 predictors

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 105, 105, 106, 105, 105, 105, ... 
Resampling results across tuning parameters:

  lambda        RMSE          Rsquared    MAE         
  0.0000000000      22.42497  0.27702987      15.70016
  0.0001000000    6615.25285  0.08396519    3563.99122
  0.0002371374   99671.84144  0.08457611   62604.59123
  0.0005623413  170244.42077  0.14306870  104949.49993
  0.0013335214   13949.49087  0.14095413    8819.60573
  0.0031622777    1338.29409  0.09027590     926.17683
  0.0074989421    4869.57307  0.19911169    3391.43119
  0.0177827941      17.66500  0.25592818      12.61336
  0.0421696503      15.69511  0.31773516      11.39005
  0.1000000000      14.70937  0.37493137      10.76181

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was lambda = 0.1.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb307"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb307-1"><a href="#cb307-1" aria-hidden="true" tabindex="-1"></a>ridge2_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(ridge2_model, test_data)</span>
<span id="cb307-2"><a href="#cb307-2" aria-hidden="true" tabindex="-1"></a>ridge2_r2 <span class="ot">&lt;-</span> <span class="fu">cor</span>(ridge2_pred, test_permeability)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb307-3"><a href="#cb307-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb308"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb308-1"><a href="#cb308-1" aria-hidden="true" tabindex="-1"></a>ridge2_r2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5311375</code></pre>
</div>
</div>
<p><u><strong>Ridge Rigression:</strong></u></p>
<ul>
<li>lambda = 0.1</li>
<li>RMSE: 14.70937</li>
<li>rsquared: 0.37493137</li>
<li>MAE: 10.76181</li>
</ul>
<p>The Test Set of rsquared: 0.5311375</p>
<p><strong>Lasso Regression</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb310"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb310-1"><a href="#cb310-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb310-2"><a href="#cb310-2" aria-hidden="true" tabindex="-1"></a>lasso2_model <span class="ot">&lt;-</span> <span class="fu">train</span>(train_data, train_permeability, <span class="at">method =</span> <span class="st">"lasso"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>), <span class="at">tuneLength =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: fraction=0.9 Error in if (zmin &lt; gamhat) { : missing value where TRUE/FALSE needed</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,
: There were missing values in resampled performance measures.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb313"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb313-1"><a href="#cb313-1" aria-hidden="true" tabindex="-1"></a>lasso2_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The lasso 

117 samples
388 predictors

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 105, 105, 106, 105, 105, 105, ... 
Resampling results across tuning parameters:

  fraction   RMSE      Rsquared   MAE      
  0.1000000  12.76949  0.4681541   9.532476
  0.1888889  13.75236  0.4031430   9.879639
  0.2777778  14.64878  0.3661843  10.403824
  0.3666667  15.57692  0.3421552  11.066913
  0.4555556  16.62051  0.3177241  11.791049
  0.5444444  17.77760  0.3013368  12.521844
  0.6333333  18.87893  0.2964326  13.284076
  0.7222222  20.07676  0.2902689  14.162004
  0.8111111  21.22992  0.2871456  14.928141
  0.9000000  21.91715  0.2806466  15.326569

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was fraction = 0.1.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb315"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb315-1"><a href="#cb315-1" aria-hidden="true" tabindex="-1"></a>lasso2_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(lasso2_model, test_data)</span>
<span id="cb315-2"><a href="#cb315-2" aria-hidden="true" tabindex="-1"></a>lasso2_r2 <span class="ot">&lt;-</span> <span class="fu">cor</span>(lasso2_pred, test_permeability)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb315-3"><a href="#cb315-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb316"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb316-1"><a href="#cb316-1" aria-hidden="true" tabindex="-1"></a>lasso2_r2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4573928</code></pre>
</div>
</div>
<p><u><strong>Lasso Regression:</strong></u></p>
<ul>
<li>fraction: 0.1</li>
<li>RMSE: 12.76949</li>
<li>rsquared: 0.4681541</li>
<li>MAE: 9.532476</li>
</ul>
<p>The Test Set of rsquared: 0.4573928</p>
<p><strong>Table Summary:</strong></p>
<table class="table">
<colgroup>
<col style="width: 26%">
<col style="width: 14%">
<col style="width: 16%">
<col style="width: 14%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>RMSE</th>
<th>Rsquared</th>
<th>MAE</th>
<th>Test_set_rsquared</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PLS Model</td>
<td>12.30920</td>
<td>0.4595424</td>
<td>8.621998</td>
<td>0.3819407</td>
</tr>
<tr class="even">
<td>SVM</td>
<td>11.71028</td>
<td>0.5103354</td>
<td>7.664866</td>
<td>0.4394321</td>
</tr>
<tr class="odd">
<td>Ridge Rigression</td>
<td>14.70937</td>
<td>0.3749313</td>
<td>10.76181</td>
<td>0.5311375</td>
</tr>
<tr class="even">
<td>Lasso Regression</td>
<td>12.76949</td>
<td>0.4681541</td>
<td>9.532476</td>
<td>0.4573928</td>
</tr>
</tbody>
</table>
<p><strong>f) Would you recommend any of your models to replace the permeability laboratory experiment?</strong></p>
<p>According to the table above, SVM has the lowest RMSE, and MAE, this model has less of a possibility to give us an error. However, the Ridge Regression model has the highest rquared, which simply means that this model can explain the highest variance out of the other models. Now, my recommendation, would be to use the SVM model for this laboratory experiment, the reason is because it has the lowest RMSE and MAE, and a decent amount of variance can be explained by this model.</p>
<p>Return to the permeability problem outlined in Problem 2. Train several nonlinear regression models and evaluate the resampling and test set performance.</p>
<p><strong>Support Vector Machines (SVM)</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb318"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb318-1"><a href="#cb318-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb318-2"><a href="#cb318-2" aria-hidden="true" tabindex="-1"></a>svm3_model <span class="ot">&lt;-</span> <span class="fu">train</span>(train_data_transformed, train_permeability, <span class="at">method =</span> <span class="st">"svmRadial"</span>,</span>
<span id="cb318-3"><a href="#cb318-3" aria-hidden="true" tabindex="-1"></a>                    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb318-4"><a href="#cb318-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">tuneLength =</span> <span class="dv">10</span>)</span>
<span id="cb318-5"><a href="#cb318-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb318-6"><a href="#cb318-6" aria-hidden="true" tabindex="-1"></a>svm3_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(svm3_model, <span class="at">newdata =</span> test_data_transformed)</span>
<span id="cb318-7"><a href="#cb318-7" aria-hidden="true" tabindex="-1"></a>svm3_result <span class="ot">&lt;-</span> <span class="fu">postResample</span>(svm3_pred, test_permeability)</span>
<span id="cb318-8"><a href="#cb318-8" aria-hidden="true" tabindex="-1"></a>svm3_result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      RMSE   Rsquared        MAE 
10.5483639  0.4394321  7.1154118 </code></pre>
</div>
</div>
<p><strong>Neural Network</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb320"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb320-1"><a href="#cb320-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb320-2"><a href="#cb320-2" aria-hidden="true" tabindex="-1"></a>nn3_model <span class="ot">&lt;-</span> <span class="fu">train</span>(train_data_transformed, train_permeability, <span class="at">method =</span> <span class="st">"nnet"</span>,</span>
<span id="cb320-3"><a href="#cb320-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb320-4"><a href="#cb320-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">tuneLength =</span> <span class="dv">10</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>, <span class="at">linout =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 3, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 5, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 7, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 9, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=11, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=13, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=15, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=17, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=19, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 3, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 5, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 7, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 9, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=11, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=13, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=15, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=17, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=19, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 3, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 5, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 7, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 9, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=11, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=13, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=15, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=17, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=19, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 3, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 5, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 7, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 9, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=11, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=13, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=15, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=17, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=19, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 3, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 5, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 7, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 9, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=11, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=13, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=15, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=17, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=19, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 3, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 5, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 7, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 9, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=11, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=13, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=15, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=17, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=19, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 3, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 5, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 7, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 9, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=11, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=13, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=15, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=17, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=19, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 3, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 5, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 7, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 9, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=11, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=13, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=15, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=17, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=19, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 3, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 5, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 7, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 9, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=11, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=13, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=15, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=17, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=19, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 3, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 5, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 7, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size= 9, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=11, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=13, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=15, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=17, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold01: size=19, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 3, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 5, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 7, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 9, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=11, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=13, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=15, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=17, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=19, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 3, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 5, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 7, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 9, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=11, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=13, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=15, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=17, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=19, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 3, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 5, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 7, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 9, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=11, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=13, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=15, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=17, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=19, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 3, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 5, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 7, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 9, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=11, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=13, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=15, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=17, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=19, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 3, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 5, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 7, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 9, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=11, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=13, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=15, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=17, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=19, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 3, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 5, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 7, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 9, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=11, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=13, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=15, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=17, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=19, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 3, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 5, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 7, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 9, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=11, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=13, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=15, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=17, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=19, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 3, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 5, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 7, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 9, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=11, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=13, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=15, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=17, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=19, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 3, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 5, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 7, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 9, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=11, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=13, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=15, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=17, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=19, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 3, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 5, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 7, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size= 9, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=11, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=13, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=15, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=17, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold02: size=19, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 3, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 5, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 7, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 9, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=11, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=13, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=15, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=17, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=19, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 3, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 5, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 7, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 9, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=11, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=13, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=15, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=17, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=19, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 3, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 5, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 7, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 9, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=11, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=13, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=15, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=17, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=19, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 3, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 5, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 7, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 9, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=11, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=13, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=15, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=17, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=19, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 3, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 5, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 7, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 9, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=11, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=13, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=15, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=17, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=19, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 3, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 5, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 7, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 9, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=11, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=13, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=15, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=17, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=19, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 3, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 5, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 7, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 9, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=11, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=13, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=15, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=17, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=19, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 3, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 5, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 7, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 9, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=11, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=13, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=15, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=17, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=19, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 3, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 5, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 7, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 9, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=11, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=13, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=15, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=17, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=19, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 3, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 5, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 7, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size= 9, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=11, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=13, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=15, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=17, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold03: size=19, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 3, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 5, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 7, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 9, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=11, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=13, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=15, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=17, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=19, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 3, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 5, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 7, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 9, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=11, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=13, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=15, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=17, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=19, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 3, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 5, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 7, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 9, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=11, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=13, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=15, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=17, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=19, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 3, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 5, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 7, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 9, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=11, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=13, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=15, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=17, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=19, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 3, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 5, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 7, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 9, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=11, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=13, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=15, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=17, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=19, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 3, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 5, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 7, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 9, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=11, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=13, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=15, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=17, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=19, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 3, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 5, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 7, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 9, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=11, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=13, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=15, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=17, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=19, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 3, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 5, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 7, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 9, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=11, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=13, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=15, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=17, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=19, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 3, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 5, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 7, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 9, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=11, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=13, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=15, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=17, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=19, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 3, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 5, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 7, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size= 9, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=11, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=13, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=15, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=17, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold04: size=19, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 3, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 5, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 7, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 9, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=11, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=13, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=15, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=17, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=19, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 3, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 5, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 7, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 9, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=11, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=13, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=15, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=17, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=19, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 3, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 5, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 7, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 9, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=11, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=13, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=15, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=17, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=19, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 3, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 5, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 7, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 9, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=11, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=13, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=15, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=17, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=19, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 3, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 5, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 7, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 9, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=11, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=13, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=15, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=17, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=19, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 3, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 5, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 7, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 9, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=11, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=13, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=15, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=17, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=19, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 3, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 5, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 7, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 9, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=11, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=13, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=15, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=17, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=19, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 3, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 5, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 7, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 9, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=11, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=13, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=15, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=17, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=19, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 3, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 5, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 7, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 9, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=11, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=13, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=15, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=17, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=19, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 3, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 5, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 7, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size= 9, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=11, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=13, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=15, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=17, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold05: size=19, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 3, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 5, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 7, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 9, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=11, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=13, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=15, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=17, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=19, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 3, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 5, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 7, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 9, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=11, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=13, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=15, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=17, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=19, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 3, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 5, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 7, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 9, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=11, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=13, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=15, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=17, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=19, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 3, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 5, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 7, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 9, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=11, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=13, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=15, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=17, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=19, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 3, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 5, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 7, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 9, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=11, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=13, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=15, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=17, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=19, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 3, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 5, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 7, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 9, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=11, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=13, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=15, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=17, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=19, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 3, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 5, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 7, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 9, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=11, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=13, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=15, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=17, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=19, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 3, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 5, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 7, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 9, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=11, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=13, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=15, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=17, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=19, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 3, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 5, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 7, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 9, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=11, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=13, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=15, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=17, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=19, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 3, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 5, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 7, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size= 9, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=11, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=13, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=15, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=17, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold06: size=19, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 3, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 5, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 7, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 9, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=11, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=13, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=15, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=17, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=19, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 3, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 5, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 7, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 9, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=11, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=13, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=15, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=17, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=19, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 3, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 5, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 7, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 9, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=11, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=13, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=15, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=17, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=19, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 3, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 5, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 7, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 9, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=11, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=13, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=15, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=17, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=19, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 3, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 5, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 7, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 9, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=11, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=13, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=15, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=17, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=19, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 3, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 5, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 7, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 9, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=11, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=13, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=15, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=17, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=19, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 3, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 5, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 7, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 9, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=11, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=13, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=15, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=17, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=19, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 3, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 5, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 7, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 9, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=11, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=13, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=15, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=17, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=19, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 3, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 5, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 7, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 9, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=11, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=13, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=15, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=17, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=19, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 3, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 5, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 7, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size= 9, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=11, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=13, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=15, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=17, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold07: size=19, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 3, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 5, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 7, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 9, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=11, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=13, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=15, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=17, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=19, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 3, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 5, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 7, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 9, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=11, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=13, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=15, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=17, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=19, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 3, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 5, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 7, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 9, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=11, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=13, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=15, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=17, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=19, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 3, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 5, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 7, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 9, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=11, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=13, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=15, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=17, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=19, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 3, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 5, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 7, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 9, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=11, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=13, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=15, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=17, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=19, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 3, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 5, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 7, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 9, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=11, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=13, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=15, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=17, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=19, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 3, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 5, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 7, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 9, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=11, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=13, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=15, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=17, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=19, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 3, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 5, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 7, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 9, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=11, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=13, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=15, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=17, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=19, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 3, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 5, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 7, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 9, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=11, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=13, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=15, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=17, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=19, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 3, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 5, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 7, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size= 9, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=11, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=13, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=15, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=17, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold08: size=19, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 3, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 5, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 7, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 9, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=11, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=13, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=15, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=17, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=19, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 3, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 5, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 7, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 9, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=11, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=13, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=15, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=17, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=19, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 3, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 5, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 7, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 9, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=11, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=13, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=15, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=17, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=19, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 3, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 5, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 7, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 9, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=11, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=13, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=15, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=17, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=19, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 3, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 5, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 7, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 9, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=11, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=13, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=15, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=17, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=19, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 3, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 5, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 7, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 9, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=11, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=13, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=15, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=17, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=19, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 3, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 5, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 7, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 9, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=11, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=13, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=15, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=17, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=19, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 3, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 5, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 7, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 9, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=11, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=13, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=15, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=17, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=19, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 3, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 5, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 7, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 9, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=11, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=13, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=15, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=17, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=19, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 3, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 5, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 7, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size= 9, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=11, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=13, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=15, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=17, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold09: size=19, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 3, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 5, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 7, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 9, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=11, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=13, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=15, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=17, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=19, decay=0.0000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 3, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 5, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 7, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 9, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=11, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=13, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=15, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=17, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=19, decay=0.1000000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 3, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 5, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 7, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 9, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=11, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=13, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=15, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=17, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=19, decay=0.0421697 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 3, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 5, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 7, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 9, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=11, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=13, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=15, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=17, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=19, decay=0.0177828 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 3, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 5, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 7, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 9, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=11, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=13, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=15, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=17, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=19, decay=0.0074989 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 3, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 5, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 7, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 9, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=11, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=13, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=15, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=17, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=19, decay=0.0031623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 3, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 5, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 7, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 9, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=11, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=13, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=15, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=17, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=19, decay=0.0013335 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 3, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 5, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 7, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 9, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=11, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=13, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=15, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=17, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=19, decay=0.0005623 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 3, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 5, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 7, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 9, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=11, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=13, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=15, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=17, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=19, decay=0.0002371 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 3, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1171) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 5, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (1951) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 7, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (2731) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size= 9, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (3511) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=11, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (4291) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=13, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5071) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=15, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (5851) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=17, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (6631) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: model fit failed for Fold10: size=19, decay=0.0001000 Error in nnet.default(x, y, w, ...) : too many (7411) weights</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,
: There were missing values in resampled performance measures.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in train.default(train_data_transformed, train_permeability, method =
"nnet", : missing values found in aggregated results</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1223"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1223-1"><a href="#cb1223-1" aria-hidden="true" tabindex="-1"></a>nn3_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(nn3_model, <span class="at">newdata =</span> test_data_transformed)</span>
<span id="cb1223-2"><a href="#cb1223-2" aria-hidden="true" tabindex="-1"></a>nn3_result <span class="ot">&lt;-</span> <span class="fu">postResample</span>(nn3_pred, test_permeability)</span>
<span id="cb1223-3"><a href="#cb1223-3" aria-hidden="true" tabindex="-1"></a>nn3_result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     RMSE  Rsquared       MAE 
12.731659  0.197259  9.597258 </code></pre>
</div>
</div>
<p><strong>MARS</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1225"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1225-1"><a href="#cb1225-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1225-2"><a href="#cb1225-2" aria-hidden="true" tabindex="-1"></a>mars3_model <span class="ot">&lt;-</span> <span class="fu">train</span>(train_data_transformed, train_permeability, <span class="at">method =</span> <span class="st">"earth"</span>,</span>
<span id="cb1225-3"><a href="#cb1225-3" aria-hidden="true" tabindex="-1"></a>                    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb1225-4"><a href="#cb1225-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">tuneLength =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,
: There were missing values in resampled performance measures.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1227"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1227-1"><a href="#cb1227-1" aria-hidden="true" tabindex="-1"></a>mars3_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(mars3_model, <span class="at">newdata =</span> test_data_transformed)</span>
<span id="cb1227-2"><a href="#cb1227-2" aria-hidden="true" tabindex="-1"></a>mars3_result <span class="ot">&lt;-</span> <span class="fu">postResample</span>(mars3_pred, test_permeability)</span>
<span id="cb1227-3"><a href="#cb1227-3" aria-hidden="true" tabindex="-1"></a>mars3_result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      RMSE   Rsquared        MAE 
11.8764033  0.3239788  7.5933958 </code></pre>
</div>
</div>
<p><strong>k-Nearest Neighbors (kNN)</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1229"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1229-1"><a href="#cb1229-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1229-2"><a href="#cb1229-2" aria-hidden="true" tabindex="-1"></a>knn3_model <span class="ot">&lt;-</span> <span class="fu">train</span>(train_data_transformed, train_permeability, <span class="at">method =</span> <span class="st">"kknn"</span>,</span>
<span id="cb1229-3"><a href="#cb1229-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb1229-4"><a href="#cb1229-4" aria-hidden="true" tabindex="-1"></a>                   <span class="at">tuneLength =</span> <span class="dv">10</span>)</span>
<span id="cb1229-5"><a href="#cb1229-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1229-6"><a href="#cb1229-6" aria-hidden="true" tabindex="-1"></a>knn3_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn3_model, <span class="at">newdata =</span> test_data_transformed)</span>
<span id="cb1229-7"><a href="#cb1229-7" aria-hidden="true" tabindex="-1"></a>knn3_result <span class="ot">&lt;-</span> <span class="fu">postResample</span>(knn3_pred, test_permeability)</span>
<span id="cb1229-8"><a href="#cb1229-8" aria-hidden="true" tabindex="-1"></a>knn3_result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      RMSE   Rsquared        MAE 
10.5121448  0.4547602  6.9931969 </code></pre>
</div>
</div>
<p><strong>a) Which nonlinear regression model that we learned in Chapter 7 gives the optimal resampling and test set performance?</strong></p>
<table class="table">
<thead>
<tr class="header">
<th>NONLINEAR</th>
<th>RMSE</th>
<th>Rsquared</th>
<th>MAE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>SVM</td>
<td>10.5483639</td>
<td>0.4394321</td>
<td>7.1154118</td>
</tr>
<tr class="even">
<td>Neural Network</td>
<td>12.731659</td>
<td>0.197259</td>
<td>9.597258</td>
</tr>
<tr class="odd">
<td>MARS</td>
<td>11.8764033</td>
<td>0.3239788</td>
<td>7.5933958</td>
</tr>
<tr class="even">
<td>kNN</td>
<td>10.5121448</td>
<td>0.4547602</td>
<td>6.9931969</td>
</tr>
</tbody>
</table>
<p>The kNN Model gives the optimal resampling and test set performance, because it has the lowest RMSE and the highest R-squared compared to the others.</p>
<p><strong>b) Do any of the nonlinear models outperform the optimal linear model you previously developed in Problem 2? If so, what might this tell you about the underlying relationship between the predictors and the response?</strong></p>
<table class="table">
<thead>
<tr class="header">
<th>NONLINEAR</th>
<th>RMSE</th>
<th>Rsquared</th>
<th>MAE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>SVM</td>
<td>10.5483639</td>
<td>0.4394321</td>
<td>7.1154118</td>
</tr>
<tr class="even">
<td>Neural Network</td>
<td>12.731659</td>
<td>0.197259</td>
<td>9.597258</td>
</tr>
<tr class="odd">
<td>MARS</td>
<td>11.8764033</td>
<td>0.3239788</td>
<td>7.5933958</td>
</tr>
<tr class="even">
<td>kNN</td>
<td>10.5121448</td>
<td>0.4547602</td>
<td>6.9931969</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 32%">
<col style="width: 13%">
<col style="width: 14%">
<col style="width: 13%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Other Models Ran in Q2</th>
<th>RMSE</th>
<th>Rsquared</th>
<th>MAE</th>
<th>Test_set_rsquared</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PLS Model</td>
<td>12.30920</td>
<td>0.4595424</td>
<td>8.621998</td>
<td>0.3819407</td>
</tr>
<tr class="even">
<td>Ridge Rigression</td>
<td>14.70937</td>
<td>0.3749313</td>
<td>10.76181</td>
<td>0.5311375</td>
</tr>
<tr class="odd">
<td>Lasso Regression</td>
<td>12.76949</td>
<td>0.4681541</td>
<td>9.532476</td>
<td>0.4573928</td>
</tr>
<tr class="even">
<td>SVM</td>
<td>11.71028</td>
<td>0.5103354</td>
<td>7.664866</td>
<td>0.4394321</td>
</tr>
</tbody>
</table>
<p>Yes, the best model so far is the kNN model, which seems to outperform all the other models, this model has the lowest RMSE and MAE, and its rsquared value is not the lowest. This highlights the relationship between predictors and the response variables are nonlinear.</p>
<p><strong>c) Would you recommend any of the models you have developed to replace the permeability laboratory experiment?</strong></p>
<p>Based on the results, I recommend using the kNN model. This model demonstrates the lowest RMSE and MAE, indicating it has the smallest error and provides the most accurate predictions. Additionally, it has one of the higher R-squared values, suggesting it effectively explains the variability in the data.</p>
</section>
<section id="analyzing-and-predicting-oil-types-and-customer-churn-using-machine-learning-techniques" class="level1">
<h1>Analyzing and Predicting Oil Types and Customer Churn Using Machine Learning Techniques</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb1231"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1231-1"><a href="#cb1231-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb1231-2"><a href="#cb1231-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb1231-3"><a href="#cb1231-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'tidyr' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'dplyr' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.4
✔ forcats   1.0.0     ✔ stringr   1.5.0
✔ lubridate 1.9.2     ✔ tibble    3.2.1
✔ purrr     1.0.2     ✔ tidyr     1.3.1
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ ggplot2::alpha()       masks kernlab::alpha()
✖ stringr::boundary()    masks strucchange::boundary()
✖ dplyr::combine()       masks randomForest::combine(), gridExtra::combine()
✖ purrr::cross()         masks kernlab::cross()
✖ dplyr::filter()        masks mice::filter(), stats::filter()
✖ dplyr::lag()           masks stats::lag()
✖ purrr::lift()          masks caret::lift()
✖ randomForest::margin() masks ggplot2::margin()
✖ dplyr::select()        masks MASS::select()
✖ dplyr::where()         masks party::where()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1235"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1235-1"><a href="#cb1235-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071) </span>
<span id="cb1235-2"><a href="#cb1235-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest) </span>
<span id="cb1235-3"><a href="#cb1235-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nnet) </span>
<span id="cb1235-4"><a href="#cb1235-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(modeldata)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'modeldata' was built under R version 4.3.3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1237"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1237-1"><a href="#cb1237-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1237-2"><a href="#cb1237-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb1237-3"><a href="#cb1237-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(corrplot)</span>
<span id="cb1237-4"><a href="#cb1237-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb1237-5"><a href="#cb1237-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rsample)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'rsample' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'rsample'

The following object is masked from 'package:e1071':

    permutations</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1240"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1240-1"><a href="#cb1240-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(recipes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'recipes' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'recipes'

The following object is masked from 'package:stringr':

    fixed

The following object is masked from 'package:VIM':

    prepare

The following object is masked from 'package:stats4':

    update

The following object is masked from 'package:stats':

    step</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1243"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1243-1"><a href="#cb1243-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb1243-2"><a href="#cb1243-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'ranger' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'ranger'

The following object is masked from 'package:randomForest':

    importance</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1246"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1246-1"><a href="#cb1246-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nnet)</span>
<span id="cb1246-2"><a href="#cb1246-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb1246-3"><a href="#cb1246-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(yardstick)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'yardstick' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'yardstick'

The following object is masked from 'package:readr':

    spec

The following objects are masked from 'package:caret':

    precision, recall, sensitivity, specificity</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1249"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1249-1"><a href="#cb1249-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(yardstick)</span>
<span id="cb1249-2"><a href="#cb1249-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1249-3"><a href="#cb1249-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb1249-4"><a href="#cb1249-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb1249-5"><a href="#cb1249-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'xgboost' was built under R version 4.3.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'xgboost'

The following object is masked from 'package:dplyr':

    slice</code></pre>
</div>
</div>
<p>In Homework 1, Problem 3, we described a data set which contained 96 oil samples each from one of seven types of oils (pumpkin, sunflower, peanut, olive, soybean, rapeseed, and corn). Gas chromatography was performed on each sample and the percentage of each type of 7 fatty acids was determined. We would like to use these data to build a model that predicts the type of oil based on a sample’s fatty acid percentages. These data can be found in the caret package using data(oil). The oil types are contained in a factor variable called oilType. The types are pumpkin (coded as A), sunflower (B), peanut (C), olive (D), soybean (E), rapeseed (F) and corn (G). In R</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1252"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1252-1"><a href="#cb1252-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data</span></span>
<span id="cb1252-2"><a href="#cb1252-2" aria-hidden="true" tabindex="-1"></a>?oil</span>
<span id="cb1252-3"><a href="#cb1252-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(oil)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1253"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1253-1"><a href="#cb1253-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(oilType)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Factor w/ 7 levels "A","B","C","D",..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1255"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1255-1"><a href="#cb1255-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(oilType)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>oilType
 A  B  C  D  E  F  G 
37 26  3  7 11 10  2 </code></pre>
</div>
</div>
<ol type="a">
<li>Given the classification imbalance in oil Type, describe how you would create a training and testing set.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb1257"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1257-1"><a href="#cb1257-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the fatty acid compositions into a data frame</span></span>
<span id="cb1257-2"><a href="#cb1257-2" aria-hidden="true" tabindex="-1"></a>oil_data <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(fattyAcids)</span>
<span id="cb1257-3"><a href="#cb1257-3" aria-hidden="true" tabindex="-1"></a>oil_data<span class="sc">$</span>oilType <span class="ot">&lt;-</span> oilType</span>
<span id="cb1257-4"><a href="#cb1257-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1257-5"><a href="#cb1257-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb1257-6"><a href="#cb1257-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1257-7"><a href="#cb1257-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1257-8"><a href="#cb1257-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data using stratified sampling</span></span>
<span id="cb1257-9"><a href="#cb1257-9" aria-hidden="true" tabindex="-1"></a>train_index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(oil_data<span class="sc">$</span>oilType, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb1257-10"><a href="#cb1257-10" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> oil_data[train_index, ]</span>
<span id="cb1257-11"><a href="#cb1257-11" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> oil_data[<span class="sc">-</span>train_index, ]</span>
<span id="cb1257-12"><a href="#cb1257-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1257-13"><a href="#cb1257-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Pre-process the data: Centering and Scaling</span></span>
<span id="cb1257-14"><a href="#cb1257-14" aria-hidden="true" tabindex="-1"></a>preProcValues <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(train_data[,<span class="sc">-</span><span class="fu">ncol</span>(train_data)], <span class="at">method =</span> <span class="fu">c</span>(<span class="st">"center"</span>, <span class="st">"scale"</span>))</span>
<span id="cb1257-15"><a href="#cb1257-15" aria-hidden="true" tabindex="-1"></a>train_data[,<span class="sc">-</span><span class="fu">ncol</span>(train_data)] <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcValues, train_data[,<span class="sc">-</span><span class="fu">ncol</span>(train_data)])</span>
<span id="cb1257-16"><a href="#cb1257-16" aria-hidden="true" tabindex="-1"></a>test_data[,<span class="sc">-</span><span class="fu">ncol</span>(test_data)] <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcValues, test_data[,<span class="sc">-</span><span class="fu">ncol</span>(test_data)])</span>
<span id="cb1257-17"><a href="#cb1257-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1257-18"><a href="#cb1257-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Control for cross-validation</span></span>
<span id="cb1257-19"><a href="#cb1257-19" aria-hidden="true" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, <span class="at">number =</span> <span class="dv">10</span>, <span class="at">classProbs =</span> <span class="cn">TRUE</span>, <span class="at">summaryFunction =</span> multiClassSummary)</span>
<span id="cb1257-20"><a href="#cb1257-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1257-21"><a href="#cb1257-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for missing values in the dataset</span></span>
<span id="cb1257-22"><a href="#cb1257-22" aria-hidden="true" tabindex="-1"></a><span class="fu">colSums</span>(<span class="fu">is.na</span>(train_data))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Palmitic    Stearic      Oleic   Linoleic  Linolenic Eicosanoic Eicosenoic 
         0          0          0          0          0          0          0 
   oilType 
         0 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1259"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1259-1"><a href="#cb1259-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove rows with missing values</span></span>
<span id="cb1259-2"><a href="#cb1259-2" aria-hidden="true" tabindex="-1"></a>train_data_clean <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(train_data)</span>
<span id="cb1259-3"><a href="#cb1259-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1259-4"><a href="#cb1259-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute missing values using the median</span></span>
<span id="cb1259-5"><a href="#cb1259-5" aria-hidden="true" tabindex="-1"></a>preProcess_missing <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(train_data, <span class="at">method =</span> <span class="st">'medianImpute'</span>)</span>
<span id="cb1259-6"><a href="#cb1259-6" aria-hidden="true" tabindex="-1"></a>train_data_clean <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcess_missing, train_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="2" type="a">
<li>Which classification statistic would you choose to optimize for this problem and why?</li>
</ol>
<ul>
<li><strong>I would choose the F1 score in cases where the classes are imbalanced. The objective is to achieve a balance between precision and recall.</strong></li>
</ul>
<ol start="3" type="a">
<li>Split the data into a training and a testing set, pre-process the data, and build models and tune them via resampling described in Chapter 12. Clearly list the models under consideration and the corresponding tuning parameters of the models.</li>
</ol>
<p><u><strong>k-Nearest Neighbors (k-NN):</strong></u></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1260"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1260-1"><a href="#cb1260-1" aria-hidden="true" tabindex="-1"></a><span class="co"># k-Nearest Neighbors (k-NN)</span></span>
<span id="cb1260-2"><a href="#cb1260-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1260-3"><a href="#cb1260-3" aria-hidden="true" tabindex="-1"></a>knn_model <span class="ot">&lt;-</span> <span class="fu">train</span>(oilType <span class="sc">~</span> ., <span class="at">data =</span> train_data_clean, <span class="at">method =</span> <span class="st">"knn"</span>, <span class="at">trControl =</span> ctrl, <span class="at">tuneLength =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,
: There were missing values in resampled performance measures.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1262"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1262-1"><a href="#cb1262-1" aria-hidden="true" tabindex="-1"></a>knn_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>k-Nearest Neighbors 

70 samples
 7 predictor
 7 classes: 'A', 'B', 'C', 'D', 'E', 'F', 'G' 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 62, 61, 62, 65, 63, 62, ... 
Resampling results across tuning parameters:

  k   logLoss    AUC        prAUC       Accuracy   Kappa      Mean_F1
   5  0.5583384  0.9919921  0.01388889  0.9375000  0.9195499  NaN    
   7  0.2130499  0.9974206  0.01708333  0.9138889  0.8913839  NaN    
   9  0.2846983  0.9926091  0.01504630  0.8902778  0.8606707  NaN    
  11  0.3528189  0.9904927  0.01430556  0.8500000  0.7986789  NaN    
  13  0.4069273  0.9866567  0.04625000  0.8333333  0.7649739  NaN    
  15  0.4571756  0.9891865  0.06750000  0.8208333  0.7493668  NaN    
  17  0.5034627  0.9847983  0.07888889  0.7629365  0.6623458  NaN    
  19  0.5718785  0.9844444  0.06222222  0.7629365  0.6633254  NaN    
  21  0.6450366  0.9800893  0.10847222  0.7179365  0.5943018  NaN    
  23  0.7030457  0.9753274  0.15388889  0.7054365  0.5779753  NaN    
  Mean_Sensitivity  Mean_Specificity  Mean_Pos_Pred_Value  Mean_Neg_Pred_Value
  NaN               0.9879592         NaN                  NaN                
  NaN               0.9852891         NaN                  NaN                
  NaN               0.9805272         NaN                  NaN                
  NaN               0.9712585         NaN                  NaN                
  NaN               0.9652041         NaN                  NaN                
  NaN               0.9632993         NaN                  NaN                
  NaN               0.9493878         NaN                  NaN                
  NaN               0.9497279         NaN                  NaN                
  NaN               0.9405612         NaN                  NaN                
  NaN               0.9381803         NaN                  NaN                
  Mean_Precision  Mean_Recall  Mean_Detection_Rate  Mean_Balanced_Accuracy
  NaN             NaN          0.1339286            NaN                   
  NaN             NaN          0.1305556            NaN                   
  NaN             NaN          0.1271825            NaN                   
  NaN             NaN          0.1214286            NaN                   
  NaN             NaN          0.1190476            NaN                   
  NaN             NaN          0.1172619            NaN                   
  NaN             NaN          0.1089909            NaN                   
  NaN             NaN          0.1089909            NaN                   
  NaN             NaN          0.1025624            NaN                   
  NaN             NaN          0.1007766            NaN                   

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was k = 5.</code></pre>
</div>
</div>
<p><u><strong>k-NN</strong></u></p>
<ul>
<li>k = 5</li>
<li>Log Loss: 0.5583384</li>
<li>AUC: 0.9919921</li>
<li>prAUC: 0.01388889</li>
<li>Accuracy: 0.9375000</li>
<li>Kappa: 0.9195499</li>
<li>Mean Specificity: 0.9879592</li>
<li>Mean_Detection_Rate: 0.1339286</li>
</ul>
<p><u><strong>Logistic Regression:</strong></u></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1264"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1264-1"><a href="#cb1264-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Multinomial Logistic Regression</span></span>
<span id="cb1264-2"><a href="#cb1264-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1264-3"><a href="#cb1264-3" aria-hidden="true" tabindex="-1"></a>log_reg_model <span class="ot">&lt;-</span> <span class="fu">train</span>(oilType <span class="sc">~</span> ., <span class="at">data =</span> train_data_clean, <span class="at">method =</span> <span class="st">"multinom"</span>, <span class="at">trControl =</span> ctrl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># weights:  63 (48 variable)
initial  value 120.646429 
iter  10 value 0.230492
iter  20 value 0.009305
iter  30 value 0.005935
iter  40 value 0.003696
iter  50 value 0.000954
iter  60 value 0.000826
iter  70 value 0.000260
iter  80 value 0.000245
final  value 0.000060 
converged
# weights:  63 (48 variable)
initial  value 120.646429 
iter  10 value 13.646415
iter  20 value 12.851693
final  value 12.849291 
converged
# weights:  63 (48 variable)
initial  value 120.646429 
iter  10 value 0.426250
iter  20 value 0.207953
iter  30 value 0.168443
iter  40 value 0.149413
iter  50 value 0.139491
iter  60 value 0.133972
iter  70 value 0.127703
iter  80 value 0.124725
iter  90 value 0.122750
iter 100 value 0.121841
final  value 0.121841 
stopped after 100 iterations
# weights:  63 (48 variable)
initial  value 118.700519 
iter  10 value 0.649572
iter  20 value 0.072909
iter  30 value 0.019004
iter  40 value 0.003326
iter  50 value 0.000645
iter  60 value 0.000422
iter  70 value 0.000364
final  value 0.000098 
converged
# weights:  63 (48 variable)
initial  value 118.700519 
iter  10 value 13.670469
iter  20 value 12.717571
final  value 12.717563 
converged
# weights:  63 (48 variable)
initial  value 118.700519 
iter  10 value 0.686614
iter  20 value 0.158090
iter  30 value 0.125404
iter  40 value 0.118784
iter  50 value 0.114113
iter  60 value 0.112865
iter  70 value 0.110695
iter  80 value 0.109572
iter  90 value 0.109285
iter 100 value 0.109183
final  value 0.109183 
stopped after 100 iterations
# weights:  63 (48 variable)
initial  value 120.646429 
iter  10 value 1.152097
iter  20 value 0.109926
iter  30 value 0.001534
iter  40 value 0.000261
final  value 0.000067 
converged
# weights:  63 (48 variable)
initial  value 120.646429 
iter  10 value 14.882114
iter  20 value 13.391351
final  value 13.391006 
converged
# weights:  63 (48 variable)
initial  value 120.646429 
iter  10 value 1.193110
iter  20 value 0.224979
iter  30 value 0.168419
iter  40 value 0.160797
iter  50 value 0.156729
iter  60 value 0.153777
iter  70 value 0.150874
iter  80 value 0.149621
iter  90 value 0.148691
iter 100 value 0.148334
final  value 0.148334 
stopped after 100 iterations
# weights:  63 (48 variable)
initial  value 126.484160 
iter  10 value 1.375234
iter  20 value 0.124856
iter  30 value 0.012044
iter  40 value 0.002572
final  value 0.000097 
converged
# weights:  63 (48 variable)
initial  value 126.484160 
iter  10 value 15.628076
iter  20 value 13.989692
final  value 13.989554 
converged
# weights:  63 (48 variable)
initial  value 126.484160 
iter  10 value 1.417908
iter  20 value 0.245160
iter  30 value 0.180883
iter  40 value 0.170537
iter  50 value 0.167035
iter  60 value 0.162098
iter  70 value 0.157875
iter  80 value 0.156208
iter  90 value 0.154991
iter 100 value 0.154037
final  value 0.154037 
stopped after 100 iterations
# weights:  63 (48 variable)
initial  value 122.592339 
iter  10 value 1.160417
iter  20 value 0.162686
iter  30 value 0.015871
iter  40 value 0.001935
iter  50 value 0.000669
final  value 0.000081 
converged
# weights:  63 (48 variable)
initial  value 122.592339 
iter  10 value 15.295508
iter  20 value 13.937812
final  value 13.936771 
converged
# weights:  63 (48 variable)
initial  value 122.592339 
iter  10 value 1.211200
iter  20 value 0.266794
iter  30 value 0.174726
iter  40 value 0.165736
iter  50 value 0.162175
iter  60 value 0.157912
iter  70 value 0.155364
iter  80 value 0.153778
iter  90 value 0.152625
iter 100 value 0.151735
final  value 0.151735 
stopped after 100 iterations
# weights:  63 (48 variable)
initial  value 120.646429 
iter  10 value 0.982411
iter  20 value 0.066584
iter  30 value 0.011904
iter  40 value 0.002347
iter  50 value 0.001356
final  value 0.000097 
converged
# weights:  63 (48 variable)
initial  value 120.646429 
iter  10 value 17.094756
iter  20 value 13.621311
final  value 13.620050 
converged
# weights:  63 (48 variable)
initial  value 120.646429 
iter  10 value 1.025922
iter  20 value 0.188570
iter  30 value 0.160388
iter  40 value 0.154288
iter  50 value 0.149946
iter  60 value 0.145432
iter  70 value 0.143887
iter  80 value 0.141985
iter  90 value 0.140837
iter 100 value 0.140255
final  value 0.140255 
stopped after 100 iterations
# weights:  63 (48 variable)
initial  value 120.646429 
iter  10 value 0.201740
iter  20 value 0.036329
iter  30 value 0.015300
iter  40 value 0.006737
iter  50 value 0.001509
iter  60 value 0.001034
iter  70 value 0.000403
iter  80 value 0.000390
final  value 0.000095 
converged
# weights:  63 (48 variable)
initial  value 120.646429 
iter  10 value 15.237850
iter  20 value 13.504443
final  value 13.503651 
converged
# weights:  63 (48 variable)
initial  value 120.646429 
iter  10 value 0.345888
iter  20 value 0.205508
iter  30 value 0.195911
iter  40 value 0.175069
iter  50 value 0.161029
iter  60 value 0.154607
iter  70 value 0.150725
iter  80 value 0.149049
iter  90 value 0.147205
iter 100 value 0.146646
final  value 0.146646 
stopped after 100 iterations
# weights:  63 (48 variable)
initial  value 124.538250 
iter  10 value 1.423335
iter  20 value 0.097869
iter  30 value 0.013049
iter  40 value 0.000310
final  value 0.000099 
converged
# weights:  63 (48 variable)
initial  value 124.538250 
iter  10 value 15.998770
iter  20 value 13.988523
final  value 13.987954 
converged
# weights:  63 (48 variable)
initial  value 124.538250 
iter  10 value 1.461579
iter  20 value 0.221927
iter  30 value 0.182446
iter  40 value 0.172022
iter  50 value 0.166376
iter  60 value 0.158815
iter  70 value 0.155713
iter  80 value 0.154033
iter  90 value 0.153355
iter 100 value 0.152889
final  value 0.152889 
stopped after 100 iterations
# weights:  63 (48 variable)
initial  value 126.484160 
iter  10 value 1.036502
iter  20 value 0.114252
iter  30 value 0.014528
iter  40 value 0.002648
iter  50 value 0.000355
final  value 0.000100 
converged
# weights:  63 (48 variable)
initial  value 126.484160 
iter  10 value 14.854834
iter  20 value 13.259516
final  value 13.259460 
converged
# weights:  63 (48 variable)
initial  value 126.484160 
iter  10 value 1.076774
iter  20 value 0.208832
iter  30 value 0.157131
iter  40 value 0.147462
iter  50 value 0.144709
iter  60 value 0.143059
iter  70 value 0.140412
iter  80 value 0.139310
iter  90 value 0.138768
iter 100 value 0.138344
final  value 0.138344 
stopped after 100 iterations
# weights:  63 (48 variable)
initial  value 124.538250 
iter  10 value 1.127422
iter  20 value 0.120905
iter  30 value 0.019095
iter  40 value 0.000191
final  value 0.000076 
converged
# weights:  63 (48 variable)
initial  value 124.538250 
iter  10 value 16.170644
iter  20 value 14.131864
final  value 14.130439 
converged
# weights:  63 (48 variable)
initial  value 124.538250 
iter  10 value 1.178679
iter  20 value 0.235910
iter  30 value 0.180086
iter  40 value 0.170725
iter  50 value 0.165276
iter  60 value 0.160358
iter  70 value 0.157981
iter  80 value 0.156756
iter  90 value 0.155457
iter 100 value 0.154352
final  value 0.154352 
stopped after 100 iterations</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,
: There were missing values in resampled performance measures.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># weights:  63 (48 variable)
initial  value 136.213710 
iter  10 value 18.641421
iter  20 value 14.337670
final  value 14.337620 
converged</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1268"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1268-1"><a href="#cb1268-1" aria-hidden="true" tabindex="-1"></a>log_reg_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Penalized Multinomial Regression 

70 samples
 7 predictor
 7 classes: 'A', 'B', 'C', 'D', 'E', 'F', 'G' 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 62, 61, 62, 65, 63, 62, ... 
Resampling results across tuning parameters:

  decay  logLoss    AUC        prAUC      Accuracy   Kappa      Mean_F1
  0e+00  0.5777232  0.9892857  0.2177480  0.9313889  0.9115174  NaN    
  1e-04  0.4544908  0.9930556  0.2457738  0.9513889  0.9387330  NaN    
  1e-01  0.1882385  0.9972222  0.2473611  0.9513889  0.9387330  NaN    
  Mean_Sensitivity  Mean_Specificity  Mean_Pos_Pred_Value  Mean_Neg_Pred_Value
  NaN               0.9882993         NaN                  NaN                
  NaN               0.9920918         NaN                  NaN                
  NaN               0.9920918         NaN                  NaN                
  Mean_Precision  Mean_Recall  Mean_Detection_Rate  Mean_Balanced_Accuracy
  NaN             NaN          0.1330556            NaN                   
  NaN             NaN          0.1359127            NaN                   
  NaN             NaN          0.1359127            NaN                   

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was decay = 0.1.</code></pre>
</div>
</div>
<p><strong>Logistic Regression</strong></p>
<ul>
<li>decay: 0.1</li>
<li>logLoss: 0.1882385</li>
<li>AUC: 0.9972222</li>
<li>prAUC: 0.2473611</li>
<li>Accuracy: 0.9513889</li>
<li>Kappa: 0.9387330</li>
<li>Mean_Specificity: 0.9920918</li>
<li>Mean_Detection_Rate: 0.1359127</li>
</ul>
<p><u><strong>Random Forest:</strong></u></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1270"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1270-1"><a href="#cb1270-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest</span></span>
<span id="cb1270-2"><a href="#cb1270-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1270-3"><a href="#cb1270-3" aria-hidden="true" tabindex="-1"></a>rf_grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">mtry =</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="fu">ncol</span>(train_data) <span class="sc">-</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">6</span>))</span>
<span id="cb1270-4"><a href="#cb1270-4" aria-hidden="true" tabindex="-1"></a>rf_model <span class="ot">&lt;-</span> <span class="fu">train</span>(oilType <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">"rf"</span>, <span class="at">trControl =</span> ctrl, <span class="at">tuneGrid =</span> rf_grid)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,
: There were missing values in resampled performance measures.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1272"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1272-1"><a href="#cb1272-1" aria-hidden="true" tabindex="-1"></a>rf_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest 

70 samples
 7 predictor
 7 classes: 'A', 'B', 'C', 'D', 'E', 'F', 'G' 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 62, 61, 62, 65, 63, 62, ... 
Resampling results across tuning parameters:

  mtry  logLoss    AUC  prAUC      Accuracy  Kappa      Mean_F1
  1.0   0.2490844  1    0.2522222  0.9625    0.9523009  NaN    
  2.2   0.1537911  1    0.2188889  0.9750    0.9679487  NaN    
  3.4   0.1361475  1    0.2147222  0.9750    0.9679487  NaN    
  4.6   0.1333570  1    0.1791667  0.9550    0.9405111  NaN    
  5.8   0.1378782  1    0.1583333  0.9550    0.9405111  NaN    
  7.0   0.1509535  1    0.1455556  0.9550    0.9405111  NaN    
  Mean_Sensitivity  Mean_Specificity  Mean_Pos_Pred_Value  Mean_Neg_Pred_Value
  NaN               0.9934524         NaN                  NaN                
  NaN               0.9959184         NaN                  NaN                
  NaN               0.9959184         NaN                  NaN                
  NaN               0.9933163         NaN                  NaN                
  NaN               0.9933163         NaN                  NaN                
  NaN               0.9933163         NaN                  NaN                
  Mean_Precision  Mean_Recall  Mean_Detection_Rate  Mean_Balanced_Accuracy
  NaN             NaN          0.1375000            NaN                   
  NaN             NaN          0.1392857            NaN                   
  NaN             NaN          0.1392857            NaN                   
  NaN             NaN          0.1364286            NaN                   
  NaN             NaN          0.1364286            NaN                   
  NaN             NaN          0.1364286            NaN                   

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was mtry = 2.2.</code></pre>
</div>
</div>
<p><strong>Random Forest:</strong></p>
<ul>
<li>mtry = 2.2</li>
<li>LogLoss: 0.1537911</li>
<li>AUC: 1</li>
<li>prAUC: 0.2188889</li>
<li>Accuracy: 0.9750</li>
<li>Kappa: 0.9679487</li>
<li>Mean_Specificity: 0.9959184</li>
<li>Mean_Detection_Rate: 0.1392857</li>
</ul>
<p><u><strong>Summary:</strong></u></p>
<table class="table">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Tuning Parameter</th>
<th>Accuracy</th>
<th>Kappa</th>
<th>AUC</th>
<th>prAUC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>k-NN</strong></td>
<td>k = 5</td>
<td>0.9375</td>
<td>0.9195499</td>
<td>0.9920</td>
<td>0.0139</td>
</tr>
<tr class="even">
<td><strong>Logistic Regression</strong></td>
<td>decay = 0.1</td>
<td>0.9514</td>
<td>0.9387330</td>
<td>0.9972</td>
<td>0.2474</td>
</tr>
<tr class="odd">
<td><strong>Random Forest</strong></td>
<td>mtry = 2.2</td>
<td>0.9750</td>
<td>0.9679487</td>
<td>1.0000</td>
<td>0.2189</td>
</tr>
</tbody>
</table>
<p><strong>Conclusion: Out of all the models the Random Forest performs the best with the highest accuracy, Kappa, and AUC score. Then followed by the Logistic Regression model, and the model that performed the worst is the k-NN model. Altogether these models performed well, but the Random Forest out performs the rest of the models.</strong></p>
<ol start="4" type="a">
<li>Of the models presented in this chapter, which performs best on these data? Which oil type does the model most accurately predict? Least accurately predict?</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb1274"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1274-1"><a href="#cb1274-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate predictions for each model</span></span>
<span id="cb1274-2"><a href="#cb1274-2" aria-hidden="true" tabindex="-1"></a>knn_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_model, test_data)</span>
<span id="cb1274-3"><a href="#cb1274-3" aria-hidden="true" tabindex="-1"></a>log_reg_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(log_reg_model, test_data)</span>
<span id="cb1274-4"><a href="#cb1274-4" aria-hidden="true" tabindex="-1"></a>rf_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_model, test_data)</span>
<span id="cb1274-5"><a href="#cb1274-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1274-6"><a href="#cb1274-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create confusion matrices</span></span>
<span id="cb1274-7"><a href="#cb1274-7" aria-hidden="true" tabindex="-1"></a>knn_cm <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(knn_pred, test_data<span class="sc">$</span>oilType)</span>
<span id="cb1274-8"><a href="#cb1274-8" aria-hidden="true" tabindex="-1"></a>log_reg_cm <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(log_reg_pred, test_data<span class="sc">$</span>oilType)</span>
<span id="cb1274-9"><a href="#cb1274-9" aria-hidden="true" tabindex="-1"></a>rf_cm <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(rf_pred, test_data<span class="sc">$</span>oilType)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1275"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1275-1"><a href="#cb1275-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print confusion matrices</span></span>
<span id="cb1275-2"><a href="#cb1275-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(knn_cm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  A  B  C  D  E  F  G
         A 10  0  0  0  0  0  0
         B  1  7  0  0  0  0  0
         C  0  0  0  0  0  0  0
         D  0  0  0  2  0  0  0
         E  0  0  0  0  3  0  0
         F  0  0  0  0  0  3  0
         G  0  0  0  0  0  0  0

Overall Statistics
                                         
               Accuracy : 0.9615         
                 95% CI : (0.8036, 0.999)
    No Information Rate : 0.4231         
    P-Value [Acc &gt; NIR] : 7.058e-09      
                                         
                  Kappa : 0.9467         
                                         
 Mcnemar's Test P-Value : NA             

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E Class: F
Sensitivity            0.9091   1.0000       NA  1.00000   1.0000   1.0000
Specificity            1.0000   0.9474        1  1.00000   1.0000   1.0000
Pos Pred Value         1.0000   0.8750       NA  1.00000   1.0000   1.0000
Neg Pred Value         0.9375   1.0000       NA  1.00000   1.0000   1.0000
Prevalence             0.4231   0.2692        0  0.07692   0.1154   0.1154
Detection Rate         0.3846   0.2692        0  0.07692   0.1154   0.1154
Detection Prevalence   0.3846   0.3077        0  0.07692   0.1154   0.1154
Balanced Accuracy      0.9545   0.9737       NA  1.00000   1.0000   1.0000
                     Class: G
Sensitivity                NA
Specificity                 1
Pos Pred Value             NA
Neg Pred Value             NA
Prevalence                  0
Detection Rate              0
Detection Prevalence        0
Balanced Accuracy          NA</code></pre>
</div>
</div>
<p><strong>kNN:</strong></p>
<ul>
<li>Accuracy: 0.9615</li>
<li>Kappa: 0.9467</li>
<li>Class A, B, D, E, and F are good.</li>
<li>Class C, and G have no predictions</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1277"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1277-1"><a href="#cb1277-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(log_reg_cm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  A  B  C  D  E  F  G
         A 10  0  0  0  0  0  0
         B  1  7  0  0  0  0  0
         C  0  0  0  0  0  0  0
         D  0  0  0  2  0  0  0
         E  0  0  0  0  3  0  0
         F  0  0  0  0  0  3  0
         G  0  0  0  0  0  0  0

Overall Statistics
                                         
               Accuracy : 0.9615         
                 95% CI : (0.8036, 0.999)
    No Information Rate : 0.4231         
    P-Value [Acc &gt; NIR] : 7.058e-09      
                                         
                  Kappa : 0.9467         
                                         
 Mcnemar's Test P-Value : NA             

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E Class: F
Sensitivity            0.9091   1.0000       NA  1.00000   1.0000   1.0000
Specificity            1.0000   0.9474        1  1.00000   1.0000   1.0000
Pos Pred Value         1.0000   0.8750       NA  1.00000   1.0000   1.0000
Neg Pred Value         0.9375   1.0000       NA  1.00000   1.0000   1.0000
Prevalence             0.4231   0.2692        0  0.07692   0.1154   0.1154
Detection Rate         0.3846   0.2692        0  0.07692   0.1154   0.1154
Detection Prevalence   0.3846   0.3077        0  0.07692   0.1154   0.1154
Balanced Accuracy      0.9545   0.9737       NA  1.00000   1.0000   1.0000
                     Class: G
Sensitivity                NA
Specificity                 1
Pos Pred Value             NA
Neg Pred Value             NA
Prevalence                  0
Detection Rate              0
Detection Prevalence        0
Balanced Accuracy          NA</code></pre>
</div>
</div>
<p><strong>Logistic Regression:</strong></p>
<ul>
<li>Accuracy: 0.9615</li>
<li>Kappa: 0.9467</li>
<li>Class A, B, D, E, and F are predicted well</li>
<li>Class C and G have the worst outcome.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1279"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1279-1"><a href="#cb1279-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rf_cm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  A  B  C  D  E  F  G
         A 11  0  0  0  0  0  0
         B  0  7  0  0  0  0  0
         C  0  0  0  0  0  0  0
         D  0  0  0  2  0  0  0
         E  0  0  0  0  3  0  0
         F  0  0  0  0  0  3  0
         G  0  0  0  0  0  0  0

Overall Statistics
                                     
               Accuracy : 1          
                 95% CI : (0.8677, 1)
    No Information Rate : 0.4231     
    P-Value [Acc &gt; NIR] : 1.936e-10  
                                     
                  Kappa : 1          
                                     
 Mcnemar's Test P-Value : NA         

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E Class: F
Sensitivity            1.0000   1.0000       NA  1.00000   1.0000   1.0000
Specificity            1.0000   1.0000        1  1.00000   1.0000   1.0000
Pos Pred Value         1.0000   1.0000       NA  1.00000   1.0000   1.0000
Neg Pred Value         1.0000   1.0000       NA  1.00000   1.0000   1.0000
Prevalence             0.4231   0.2692        0  0.07692   0.1154   0.1154
Detection Rate         0.4231   0.2692        0  0.07692   0.1154   0.1154
Detection Prevalence   0.4231   0.2692        0  0.07692   0.1154   0.1154
Balanced Accuracy      1.0000   1.0000       NA  1.00000   1.0000   1.0000
                     Class: G
Sensitivity                NA
Specificity                 1
Pos Pred Value             NA
Neg Pred Value             NA
Prevalence                  0
Detection Rate              0
Detection Prevalence        0
Balanced Accuracy          NA</code></pre>
</div>
</div>
<p><strong>Random Forest:</strong></p>
<ul>
<li>Accuracy: 1</li>
<li>Kappa: 1</li>
<li>Class A, B, D, E, and F are predicted well</li>
<li>Class C and G have no predictions.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1281"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1281-1"><a href="#cb1281-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute F1 Scores</span></span>
<span id="cb1281-2"><a href="#cb1281-2" aria-hidden="true" tabindex="-1"></a>f1_score <span class="ot">&lt;-</span> <span class="cf">function</span>(conf_matrix) {</span>
<span id="cb1281-3"><a href="#cb1281-3" aria-hidden="true" tabindex="-1"></a>  precision <span class="ot">&lt;-</span> conf_matrix<span class="sc">$</span>byClass[, <span class="st">"Precision"</span>]</span>
<span id="cb1281-4"><a href="#cb1281-4" aria-hidden="true" tabindex="-1"></a>  recall <span class="ot">&lt;-</span> conf_matrix<span class="sc">$</span>byClass[, <span class="st">"Recall"</span>]</span>
<span id="cb1281-5"><a href="#cb1281-5" aria-hidden="true" tabindex="-1"></a>  f1 <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (precision <span class="sc">*</span> recall) <span class="sc">/</span> (precision <span class="sc">+</span> recall)</span>
<span id="cb1281-6"><a href="#cb1281-6" aria-hidden="true" tabindex="-1"></a>  f1[<span class="fu">is.na</span>(f1)] <span class="ot">&lt;-</span> <span class="dv">0</span> <span class="co"># Handle cases where precision or recall is zero</span></span>
<span id="cb1281-7"><a href="#cb1281-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(f1)}</span>
<span id="cb1281-8"><a href="#cb1281-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1281-9"><a href="#cb1281-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate F1 Scores for each model</span></span>
<span id="cb1281-10"><a href="#cb1281-10" aria-hidden="true" tabindex="-1"></a>knn_f1 <span class="ot">&lt;-</span> <span class="fu">f1_score</span>(knn_cm)</span>
<span id="cb1281-11"><a href="#cb1281-11" aria-hidden="true" tabindex="-1"></a>log_reg_f1 <span class="ot">&lt;-</span> <span class="fu">f1_score</span>(log_reg_cm)</span>
<span id="cb1281-12"><a href="#cb1281-12" aria-hidden="true" tabindex="-1"></a>rf_f1 <span class="ot">&lt;-</span> <span class="fu">f1_score</span>(rf_cm)</span>
<span id="cb1281-13"><a href="#cb1281-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1281-14"><a href="#cb1281-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary Table</span></span>
<span id="cb1281-15"><a href="#cb1281-15" aria-hidden="true" tabindex="-1"></a>summary_table <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1281-16"><a href="#cb1281-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">Model =</span> <span class="fu">c</span>(<span class="st">"k-NN"</span>, <span class="st">"Logistic Regression"</span>, <span class="st">"Random Forest"</span>),</span>
<span id="cb1281-17"><a href="#cb1281-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">Accuracy =</span> <span class="fu">c</span>(knn_cm<span class="sc">$</span>overall[<span class="st">'Accuracy'</span>], log_reg_cm<span class="sc">$</span>overall[<span class="st">'Accuracy'</span>], rf_cm<span class="sc">$</span>overall[<span class="st">'Accuracy'</span>]),</span>
<span id="cb1281-18"><a href="#cb1281-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">Kappa =</span> <span class="fu">c</span>(knn_cm<span class="sc">$</span>overall[<span class="st">'Kappa'</span>], log_reg_cm<span class="sc">$</span>overall[<span class="st">'Kappa'</span>], rf_cm<span class="sc">$</span>overall[<span class="st">'Kappa'</span>]),</span>
<span id="cb1281-19"><a href="#cb1281-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">F1_Score =</span> <span class="fu">c</span>(<span class="fu">mean</span>(knn_f1), <span class="fu">mean</span>(log_reg_f1), <span class="fu">mean</span>(rf_f1)))</span>
<span id="cb1281-20"><a href="#cb1281-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1281-21"><a href="#cb1281-21" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(summary_table)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                Model  Accuracy     Kappa  F1_Score
1                k-NN 0.9615385 0.9467213 0.6979592
2 Logistic Regression 0.9615385 0.9467213 0.6979592
3       Random Forest 1.0000000 1.0000000 0.7142857</code></pre>
</div>
</div>
<p><strong>Best Predictive Model: Random Forest:</strong></p>
<ul>
<li>Accuracy: 1</li>
<li>Kappa: 1</li>
<li>F1 score: 0.7142857</li>
</ul>
<p><strong>Summary:</strong> Although the SVM and k-NN are identical in the confusion matrices, we would need further testing for these models. However, as previously stated the Random Forest proves to be the best performing almost perfectly. In terms of class, Class A (pumpkin) predicted the most accurate, wile the least accurate classes are Class C (peanut) and G (corn).</p>
<p>Use the fatty acid data from Problem 1 above.</p>
<ol type="a">
<li>Use the same data splitting approach (if any) and pre-processing steps that you did Problem 1. Using the same classification statistic as before, build models described in Chapter 13: Nonlinear Classification Models for these data. Which model has the best predictive ability? How does this optimal model’s performance compare to the best linear model’s performance?</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb1283"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1283-1"><a href="#cb1283-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up cross-validation control</span></span>
<span id="cb1283-2"><a href="#cb1283-2" aria-hidden="true" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, <span class="at">number =</span> <span class="dv">10</span>)</span>
<span id="cb1283-3"><a href="#cb1283-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1283-4"><a href="#cb1283-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a grid of hyperparameters</span></span>
<span id="cb1283-5"><a href="#cb1283-5" aria-hidden="true" tabindex="-1"></a>tune_grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">sigma =</span> <span class="fu">c</span>(<span class="fl">0.01</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.2</span>), </span>
<span id="cb1283-6"><a href="#cb1283-6" aria-hidden="true" tabindex="-1"></a>                         <span class="at">C =</span> <span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">128</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><u><strong>Support Vector Machines (SVM):</strong></u></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1284"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1284-1"><a href="#cb1284-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train SVM model</span></span>
<span id="cb1284-2"><a href="#cb1284-2" aria-hidden="true" tabindex="-1"></a>svm_model <span class="ot">&lt;-</span> <span class="fu">train</span>(oilType <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">"svmRadial"</span>,</span>
<span id="cb1284-3"><a href="#cb1284-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">trControl =</span> ctrl, <span class="at">tuneGrid =</span> tune_grid)</span>
<span id="cb1284-4"><a href="#cb1284-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1284-5"><a href="#cb1284-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate predictions for SVM model</span></span>
<span id="cb1284-6"><a href="#cb1284-6" aria-hidden="true" tabindex="-1"></a>svm_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(svm_model, test_data)</span>
<span id="cb1284-7"><a href="#cb1284-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1284-8"><a href="#cb1284-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create confusion matrix and calculate F1 Score</span></span>
<span id="cb1284-9"><a href="#cb1284-9" aria-hidden="true" tabindex="-1"></a>svm_cm <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(svm_pred, test_data<span class="sc">$</span>oilType)</span>
<span id="cb1284-10"><a href="#cb1284-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1284-11"><a href="#cb1284-11" aria-hidden="true" tabindex="-1"></a>svm_f1 <span class="ot">&lt;-</span> <span class="fu">f_meas</span>(svm_cm<span class="sc">$</span>table, <span class="at">truth =</span> <span class="st">"reference"</span>, <span class="at">estimate =</span> <span class="st">"prediction"</span>, <span class="at">event_level =</span> <span class="st">"second"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: While computing multiclass `precision()`, some levels had no predicted events
(i.e. `true_positive + false_positive = 0`).
Precision is undefined in this case, and those levels will be removed from the
averaged result.
Note that the following number of true events actually occurred for each
problematic event level:
'C': 0, 'G': 0</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: While computing multiclass `recall()`, some levels had no true events (i.e.
`true_positive + false_negative = 0`).
Recall is undefined in this case, and those levels will be removed from the
averaged result.
Note that the following number of predicted events actually occurred for each
problematic event level:
'C': 0, 'G': 0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1287"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1287-1"><a href="#cb1287-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print results</span></span>
<span id="cb1287-2"><a href="#cb1287-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(svm_cm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  A  B  C  D  E  F  G
         A 10  0  0  0  0  0  0
         B  1  7  0  0  0  0  0
         C  0  0  0  0  0  0  0
         D  0  0  0  2  0  0  0
         E  0  0  0  0  3  0  0
         F  0  0  0  0  0  3  0
         G  0  0  0  0  0  0  0

Overall Statistics
                                         
               Accuracy : 0.9615         
                 95% CI : (0.8036, 0.999)
    No Information Rate : 0.4231         
    P-Value [Acc &gt; NIR] : 7.058e-09      
                                         
                  Kappa : 0.9467         
                                         
 Mcnemar's Test P-Value : NA             

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E Class: F
Sensitivity            0.9091   1.0000       NA  1.00000   1.0000   1.0000
Specificity            1.0000   0.9474        1  1.00000   1.0000   1.0000
Pos Pred Value         1.0000   0.8750       NA  1.00000   1.0000   1.0000
Neg Pred Value         0.9375   1.0000       NA  1.00000   1.0000   1.0000
Prevalence             0.4231   0.2692        0  0.07692   0.1154   0.1154
Detection Rate         0.3846   0.2692        0  0.07692   0.1154   0.1154
Detection Prevalence   0.3846   0.3077        0  0.07692   0.1154   0.1154
Balanced Accuracy      0.9545   0.9737       NA  1.00000   1.0000   1.0000
                     Class: G
Sensitivity                NA
Specificity                 1
Pos Pred Value             NA
Neg Pred Value             NA
Prevalence                  0
Detection Rate              0
Detection Prevalence        0
Balanced Accuracy          NA</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1289"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1289-1"><a href="#cb1289-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(svm_f1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
  .metric .estimator .estimate
  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
1 f_meas  macro          0.977</code></pre>
</div>
</div>
<p><strong>svm:</strong></p>
<ul>
<li><p>Kappa: 0.9467</p></li>
<li><p>Accuracy: 0.9615</p></li>
<li><p>Classes E and F performed the best, followed by D then A and B.</p></li>
<li><p>Classes D and G continue to perform bad.</p></li>
<li><p>F1 score: 0.9771429</p></li>
</ul>
<p><u><strong>GBM Model:</strong></u></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1291"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1291-1"><a href="#cb1291-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train GBM model</span></span>
<span id="cb1291-2"><a href="#cb1291-2" aria-hidden="true" tabindex="-1"></a>gbm_model <span class="ot">&lt;-</span> <span class="fu">train</span>(oilType <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">"gbm"</span>,</span>
<span id="cb1291-3"><a href="#cb1291-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">trControl =</span> ctrl, <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span>
<span id="cb1291-4"><a href="#cb1291-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1291-5"><a href="#cb1291-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate predictions for GBM model</span></span>
<span id="cb1291-6"><a href="#cb1291-6" aria-hidden="true" tabindex="-1"></a>gbm_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(gbm_model, test_data)</span>
<span id="cb1291-7"><a href="#cb1291-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1291-8"><a href="#cb1291-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create confusion matrix and calculate F1 Score</span></span>
<span id="cb1291-9"><a href="#cb1291-9" aria-hidden="true" tabindex="-1"></a>gbm_cm <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(gbm_pred, test_data<span class="sc">$</span>oilType)</span>
<span id="cb1291-10"><a href="#cb1291-10" aria-hidden="true" tabindex="-1"></a>gbm_f1 <span class="ot">&lt;-</span> <span class="fu">f_meas</span>(gbm_cm<span class="sc">$</span>table, <span class="at">truth =</span> <span class="st">"reference"</span>, <span class="at">estimate =</span> <span class="st">"prediction"</span>, <span class="at">event_level =</span> <span class="st">"second"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: While computing multiclass `precision()`, some levels had no predicted events
(i.e. `true_positive + false_positive = 0`).
Precision is undefined in this case, and those levels will be removed from the
averaged result.
Note that the following number of true events actually occurred for each
problematic event level:
'C': 0, 'G': 0</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: While computing multiclass `recall()`, some levels had no true events (i.e.
`true_positive + false_negative = 0`).
Recall is undefined in this case, and those levels will be removed from the
averaged result.
Note that the following number of predicted events actually occurred for each
problematic event level:
'C': 0, 'G': 0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1294"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1294-1"><a href="#cb1294-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print results</span></span>
<span id="cb1294-2"><a href="#cb1294-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(gbm_cm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  A  B  C  D  E  F  G
         A 11  0  0  0  0  0  0
         B  0  7  0  0  0  0  0
         C  0  0  0  0  0  0  0
         D  0  0  0  2  0  0  0
         E  0  0  0  0  3  0  0
         F  0  0  0  0  0  3  0
         G  0  0  0  0  0  0  0

Overall Statistics
                                     
               Accuracy : 1          
                 95% CI : (0.8677, 1)
    No Information Rate : 0.4231     
    P-Value [Acc &gt; NIR] : 1.936e-10  
                                     
                  Kappa : 1          
                                     
 Mcnemar's Test P-Value : NA         

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E Class: F
Sensitivity            1.0000   1.0000       NA  1.00000   1.0000   1.0000
Specificity            1.0000   1.0000        1  1.00000   1.0000   1.0000
Pos Pred Value         1.0000   1.0000       NA  1.00000   1.0000   1.0000
Neg Pred Value         1.0000   1.0000       NA  1.00000   1.0000   1.0000
Prevalence             0.4231   0.2692        0  0.07692   0.1154   0.1154
Detection Rate         0.4231   0.2692        0  0.07692   0.1154   0.1154
Detection Prevalence   0.4231   0.2692        0  0.07692   0.1154   0.1154
Balanced Accuracy      1.0000   1.0000       NA  1.00000   1.0000   1.0000
                     Class: G
Sensitivity                NA
Specificity                 1
Pos Pred Value             NA
Neg Pred Value             NA
Prevalence                  0
Detection Rate              0
Detection Prevalence        0
Balanced Accuracy          NA</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1296"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1296-1"><a href="#cb1296-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(gbm_f1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
  .metric .estimator .estimate
  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
1 f_meas  macro              1</code></pre>
</div>
</div>
<p><strong>GBM</strong>:</p>
<ul>
<li><p>Kappa: 1</p></li>
<li><p>Accuracy: 1</p></li>
<li><p>Classes A, B, D, E and F in this order, predicted well.</p></li>
<li><p>Classes D and G continue to perform bad</p></li>
<li><p>F1 score: 1</p></li>
</ul>
<p><strong>Neural Network (NN):</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1298"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1298-1"><a href="#cb1298-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train Neural Network model</span></span>
<span id="cb1298-2"><a href="#cb1298-2" aria-hidden="true" tabindex="-1"></a>nn_model <span class="ot">&lt;-</span> <span class="fu">train</span>(oilType <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">"nnet"</span>,</span>
<span id="cb1298-3"><a href="#cb1298-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> ctrl, <span class="at">tuneLength =</span> <span class="dv">3</span>, <span class="at">linout =</span> <span class="cn">TRUE</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb1298-4"><a href="#cb1298-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1298-5"><a href="#cb1298-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate predictions for Neural Network model</span></span>
<span id="cb1298-6"><a href="#cb1298-6" aria-hidden="true" tabindex="-1"></a>nn_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(nn_model, test_data)</span>
<span id="cb1298-7"><a href="#cb1298-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1298-8"><a href="#cb1298-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create confusion matrix and calculate F1 Score</span></span>
<span id="cb1298-9"><a href="#cb1298-9" aria-hidden="true" tabindex="-1"></a>nn_cm <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(nn_pred, test_data<span class="sc">$</span>oilType)</span>
<span id="cb1298-10"><a href="#cb1298-10" aria-hidden="true" tabindex="-1"></a>nn_f1 <span class="ot">&lt;-</span> <span class="fu">f_meas</span>(nn_cm<span class="sc">$</span>table, <span class="at">truth =</span> <span class="st">"reference"</span>, <span class="at">estimate =</span> <span class="st">"prediction"</span>, <span class="at">event_level =</span> <span class="st">"second"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: While computing multiclass `precision()`, some levels had no predicted events
(i.e. `true_positive + false_positive = 0`).
Precision is undefined in this case, and those levels will be removed from the
averaged result.
Note that the following number of true events actually occurred for each
problematic event level:
'C': 0, 'G': 0</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: While computing multiclass `recall()`, some levels had no true events (i.e.
`true_positive + false_negative = 0`).
Recall is undefined in this case, and those levels will be removed from the
averaged result.
Note that the following number of predicted events actually occurred for each
problematic event level:
'C': 0, 'G': 0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1301"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1301-1"><a href="#cb1301-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print results</span></span>
<span id="cb1301-2"><a href="#cb1301-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(nn_cm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  A  B  C  D  E  F  G
         A 11  0  0  0  0  0  0
         B  0  7  0  0  0  0  0
         C  0  0  0  0  0  0  0
         D  0  0  0  2  0  0  0
         E  0  0  0  0  3  1  0
         F  0  0  0  0  0  2  0
         G  0  0  0  0  0  0  0

Overall Statistics
                                         
               Accuracy : 0.9615         
                 95% CI : (0.8036, 0.999)
    No Information Rate : 0.4231         
    P-Value [Acc &gt; NIR] : 7.058e-09      
                                         
                  Kappa : 0.9463         
                                         
 Mcnemar's Test P-Value : NA             

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E Class: F
Sensitivity            1.0000   1.0000       NA  1.00000   1.0000  0.66667
Specificity            1.0000   1.0000        1  1.00000   0.9565  1.00000
Pos Pred Value         1.0000   1.0000       NA  1.00000   0.7500  1.00000
Neg Pred Value         1.0000   1.0000       NA  1.00000   1.0000  0.95833
Prevalence             0.4231   0.2692        0  0.07692   0.1154  0.11538
Detection Rate         0.4231   0.2692        0  0.07692   0.1154  0.07692
Detection Prevalence   0.4231   0.2692        0  0.07692   0.1538  0.07692
Balanced Accuracy      1.0000   1.0000       NA  1.00000   0.9783  0.83333
                     Class: G
Sensitivity                NA
Specificity                 1
Pos Pred Value             NA
Neg Pred Value             NA
Prevalence                  0
Detection Rate              0
Detection Prevalence        0
Balanced Accuracy          NA</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1303"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1303-1"><a href="#cb1303-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(nn_f1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
  .metric .estimator .estimate
  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
1 f_meas  macro          0.931</code></pre>
</div>
</div>
<p><strong>Neural Network:</strong></p>
<ul>
<li><p>Accuracy : 0.9615</p></li>
<li><p>Kappa : 0.9453</p></li>
<li><p>F1 score: 0.9246377</p></li>
</ul>
<table class="table">
<thead>
<tr class="header">
<th>Matrices Models</th>
<th>Accuracy</th>
<th>Kappa</th>
<th>F1 Score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>SVM</strong></td>
<td>0.9615</td>
<td>0.9615</td>
<td>0.9771429</td>
</tr>
<tr class="even">
<td><strong>GBM</strong></td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td><strong>Neural Network</strong></td>
<td>0.9615</td>
<td>0.9453</td>
<td>0.9314286</td>
</tr>
</tbody>
</table>
<p><strong>Conclusion: The GBM performed the best here performing exceptionally well with perfect scores in accuracy, Kappa and F1 score. This model accurately predict all classes except for peanut and corn which had no predictions. Comparing the GBM and the linear model from question 1 (Random Forest), these two models accurately class A, B, D, E, F and also failed to predict Class C and G. However, in terms of metrics the GBM model offers a higher F1 score indicating it can better distinguish true positive and avoids false negative, making this model more reliable.</strong></p>
<ol start="2" type="a">
<li>Would you infer that the data have nonlinear separation boundaries based on this comparison?</li>
</ol>
<ul>
<li><strong>Given that the GBM, and Random Forest models, are both performing exceptionally well, indicates these models are best suited to handle non-linear data sets. Thus, confirming that the data does have nonlinear separation boundaries</strong></li>
</ul>
<ol start="3" type="a">
<li>Which oil type does the optimal model most accurately predict? Least accurately predict?</li>
</ol>
<ul>
<li><strong>The GBM model accurately predicted the Class (A, B, D, E, F) the best while not accurately predicting Class (C) the peanut and Class (G) corn oil type.</strong></li>
</ul>
<p>The “churn” data set was developed to predict telecom customer churn based on information about their account. The data files state that the data are “artificial based on claims similar to real world.” The data consist of 19 predictors related to the customer account, such as the number of customer service calls, the area code, and the number of minutes. The outcome is whether the customer churned:</p>
<ol type="a">
<li>Start R and use these commands to load the data</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb1305"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1305-1"><a href="#cb1305-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mlc_churn) </span>
<span id="cb1305-2"><a href="#cb1305-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(mlc_churn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tibble [5,000 × 20] (S3: tbl_df/tbl/data.frame)
 $ state                        : Factor w/ 51 levels "AK","AL","AR",..: 17 36 32 36 37 2 20 25 19 50 ...
 $ account_length               : int [1:5000] 128 107 137 84 75 118 121 147 117 141 ...
 $ area_code                    : Factor w/ 3 levels "area_code_408",..: 2 2 2 1 2 3 3 2 1 2 ...
 $ international_plan           : Factor w/ 2 levels "no","yes": 1 1 1 2 2 2 1 2 1 2 ...
 $ voice_mail_plan              : Factor w/ 2 levels "no","yes": 2 2 1 1 1 1 2 1 1 2 ...
 $ number_vmail_messages        : int [1:5000] 25 26 0 0 0 0 24 0 0 37 ...
 $ total_day_minutes            : num [1:5000] 265 162 243 299 167 ...
 $ total_day_calls              : int [1:5000] 110 123 114 71 113 98 88 79 97 84 ...
 $ total_day_charge             : num [1:5000] 45.1 27.5 41.4 50.9 28.3 ...
 $ total_eve_minutes            : num [1:5000] 197.4 195.5 121.2 61.9 148.3 ...
 $ total_eve_calls              : int [1:5000] 99 103 110 88 122 101 108 94 80 111 ...
 $ total_eve_charge             : num [1:5000] 16.78 16.62 10.3 5.26 12.61 ...
 $ total_night_minutes          : num [1:5000] 245 254 163 197 187 ...
 $ total_night_calls            : int [1:5000] 91 103 104 89 121 118 118 96 90 97 ...
 $ total_night_charge           : num [1:5000] 11.01 11.45 7.32 8.86 8.41 ...
 $ total_intl_minutes           : num [1:5000] 10 13.7 12.2 6.6 10.1 6.3 7.5 7.1 8.7 11.2 ...
 $ total_intl_calls             : int [1:5000] 3 3 5 7 3 6 7 6 4 5 ...
 $ total_intl_charge            : num [1:5000] 2.7 3.7 3.29 1.78 2.73 1.7 2.03 1.92 2.35 3.02 ...
 $ number_customer_service_calls: int [1:5000] 1 1 0 2 3 0 3 0 1 0 ...
 $ churn                        : Factor w/ 2 levels "yes","no": 2 2 2 2 2 2 2 2 2 2 ...</code></pre>
</div>
<div class="sourceCode cell-code" id="cb1307"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1307-1"><a href="#cb1307-1" aria-hidden="true" tabindex="-1"></a>?mlc_churn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1308"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1308-1"><a href="#cb1308-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(mlc_churn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] "state"                         "account_length"               
 [3] "area_code"                     "international_plan"           
 [5] "voice_mail_plan"               "number_vmail_messages"        
 [7] "total_day_minutes"             "total_day_calls"              
 [9] "total_day_charge"              "total_eve_minutes"            
[11] "total_eve_calls"               "total_eve_charge"             
[13] "total_night_minutes"           "total_night_calls"            
[15] "total_night_charge"            "total_intl_minutes"           
[17] "total_intl_calls"              "total_intl_charge"            
[19] "number_customer_service_calls" "churn"                        </code></pre>
</div>
</div>
<ol start="2" type="a">
<li>Explore the data by visualizing the relationship between the predictors and the outcome. Are there important features of the predictor data themselves, such as between-predictor correlations or degenerate distributions? Can functions of more than one predictor be used to model the data more effectively?</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb1310"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1310-1"><a href="#cb1310-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Density plot of account length</span></span>
<span id="cb1310-2"><a href="#cb1310-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mlc_churn, <span class="fu">aes</span>(<span class="at">x =</span> account_length, <span class="at">fill =</span> churn)) <span class="sc">+</span></span>
<span id="cb1310-3"><a href="#cb1310-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb1310-4"><a href="#cb1310-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Density: Account Length by Churn Status"</span>, <span class="at">x =</span> <span class="st">"Account Length"</span>, <span class="at">y =</span> <span class="st">"Density"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-124-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li><strong>Density Plot: Although there is some overlap between churn and nonchurn customers, their are some difference. It looks like the churned customer is skewed left, while the nonchurn customer are skewed right.</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1311"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1311-1"><a href="#cb1311-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Boxplot of total day minutes by churn</span></span>
<span id="cb1311-2"><a href="#cb1311-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mlc_churn, <span class="fu">aes</span>(<span class="at">x =</span> churn, <span class="at">y =</span> total_day_minutes, <span class="at">fill =</span> churn)) <span class="sc">+</span></span>
<span id="cb1311-3"><a href="#cb1311-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb1311-4"><a href="#cb1311-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Total Day Minutes by Churn Status"</span>, <span class="at">x =</span> <span class="st">"Churn"</span>, <span class="at">y =</span> <span class="st">"Total Day Minutes"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-125-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Boxplot: Churned customers have slightly higher total day minutes compared to nonchurned customers. Nonchurn customers show to have outliers, and at first glance both churn and nonchurn look to be normally distributed, but after carefully evaluating the nonchurn, we can determine its normal distributed, while churned is negatively distributed, only confirming the Density graph.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1312"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1312-1"><a href="#cb1312-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mlc_churn, <span class="fu">aes</span>(<span class="at">x =</span> total_day_minutes, <span class="at">y =</span> total_night_minutes, <span class="at">color =</span> churn)) <span class="sc">+</span></span>
<span id="cb1312-2"><a href="#cb1312-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb1312-3"><a href="#cb1312-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb1312-4"><a href="#cb1312-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Scatter Plot of Total Day vs. Total Night Minutes"</span>, <span class="at">x =</span> <span class="st">"Total Day Minutes"</span>, <span class="at">y =</span> <span class="st">"Total Night Minutes"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-126-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li><strong>Scatter Plot: There is a slight positive correlation and a linear relationship between day minutes and night minutes.</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1314"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1314-1"><a href="#cb1314-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the correlation matrix</span></span>
<span id="cb1314-2"><a href="#cb1314-2" aria-hidden="true" tabindex="-1"></a>numeric_vars <span class="ot">&lt;-</span> mlc_churn <span class="sc">%&gt;%</span> <span class="fu">select_if</span>(is.numeric)</span>
<span id="cb1314-3"><a href="#cb1314-3" aria-hidden="true" tabindex="-1"></a>cor_matrix <span class="ot">&lt;-</span> <span class="fu">cor</span>(numeric_vars, <span class="at">use =</span> <span class="st">"pairwise.complete.obs"</span>)</span>
<span id="cb1314-4"><a href="#cb1314-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1314-5"><a href="#cb1314-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert correlation matrix to long format</span></span>
<span id="cb1314-6"><a href="#cb1314-6" aria-hidden="true" tabindex="-1"></a>cor_long <span class="ot">&lt;-</span> cor_matrix <span class="sc">%&gt;%</span></span>
<span id="cb1314-7"><a href="#cb1314-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb1314-8"><a href="#cb1314-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rownames_to_column</span>(<span class="at">var =</span> <span class="st">"Var1"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1314-9"><a href="#cb1314-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="sc">-</span>Var1, <span class="at">names_to =</span> <span class="st">"Var2"</span>, <span class="at">values_to =</span> <span class="st">"value"</span>)</span>
<span id="cb1314-10"><a href="#cb1314-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1314-11"><a href="#cb1314-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the heatmap</span></span>
<span id="cb1314-12"><a href="#cb1314-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(cor_long, <span class="fu">aes</span>(Var1, Var2, <span class="at">fill =</span> value)) <span class="sc">+</span></span>
<span id="cb1314-13"><a href="#cb1314-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_tile</span>(<span class="at">color =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb1314-14"><a href="#cb1314-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_gradient2</span>(<span class="at">low =</span> <span class="st">"blue"</span>, <span class="at">high =</span> <span class="st">"red"</span>, <span class="at">mid =</span> <span class="st">"white"</span>, <span class="at">midpoint =</span> <span class="dv">0</span>, <span class="at">limit =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb1314-15"><a href="#cb1314-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Correlation Heatmap of Numeric Variables"</span>, <span class="at">x =</span> <span class="st">""</span>, <span class="at">y =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb1314-16"><a href="#cb1314-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb1314-17"><a href="#cb1314-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">hjust =</span> <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="predictive-modeling_files/figure-html/unnamed-chunk-127-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><strong>Correlation Heat Map:</strong></p>
<ul>
<li><strong>Positive correlation: day minutes and day charge</strong></li>
<li><strong>Positive correlation: eve minutes and eve charge</strong></li>
<li><strong>Positive correlation: night minutes and night charge</strong></li>
<li><strong>Positive correlation: intl minutes and intl charge</strong></li>
</ul>
<p>Conclusion: The visualizations suggest, that creating interaction based on relationships of predictors could create more effective models. For instance, aggregating totals across different times, or between account_length and total_day_minutes, would capture more patterns. Ultimately improving the predictive performance of the model.</p>
<ol start="3" type="a">
<li>Split the data into a training and a testing set, pre-process the data if appropriate.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb1315"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1315-1"><a href="#cb1315-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data</span></span>
<span id="cb1315-2"><a href="#cb1315-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1315-3"><a href="#cb1315-3" aria-hidden="true" tabindex="-1"></a>split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(mlc_churn, <span class="at">prop =</span> <span class="fl">0.7</span>)</span>
<span id="cb1315-4"><a href="#cb1315-4" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">training</span>(split)</span>
<span id="cb1315-5"><a href="#cb1315-5" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">testing</span>(split)</span>
<span id="cb1315-6"><a href="#cb1315-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1315-7"><a href="#cb1315-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Preprocess the data</span></span>
<span id="cb1315-8"><a href="#cb1315-8" aria-hidden="true" tabindex="-1"></a>recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(churn <span class="sc">~</span> ., <span class="at">data =</span> train_data) <span class="sc">%&gt;%</span></span>
<span id="cb1315-9"><a href="#cb1315-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb1315-10"><a href="#cb1315-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb1315-11"><a href="#cb1315-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prep</span>(<span class="at">training =</span> train_data, <span class="at">retain =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1315-12"><a href="#cb1315-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1315-13"><a href="#cb1315-13" aria-hidden="true" tabindex="-1"></a>train_prepped <span class="ot">&lt;-</span> <span class="fu">bake</span>(recipe, <span class="at">new_data =</span> train_data)</span>
<span id="cb1315-14"><a href="#cb1315-14" aria-hidden="true" tabindex="-1"></a>test_prepped <span class="ot">&lt;-</span> <span class="fu">bake</span>(recipe, <span class="at">new_data =</span> test_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="4" type="a">
<li>Try building other models discussed in this chapter. Do any have better predictive performance?</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb1316"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1316-1"><a href="#cb1316-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check column names in the preprocessed data</span></span>
<span id="cb1316-2"><a href="#cb1316-2" aria-hidden="true" tabindex="-1"></a><span class="co">#colnames(train_prepped)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1317"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1317-1"><a href="#cb1317-1" aria-hidden="true" tabindex="-1"></a><span class="co">#colnames(test_prepped)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1318"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1318-1"><a href="#cb1318-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Decision Tree Model</span></span>
<span id="cb1318-2"><a href="#cb1318-2" aria-hidden="true" tabindex="-1"></a>tree_model <span class="ot">&lt;-</span> <span class="fu">rpart</span>(churn <span class="sc">~</span> ., <span class="at">data =</span> train_prepped, <span class="at">method =</span> <span class="st">"class"</span>)</span>
<span id="cb1318-3"><a href="#cb1318-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1318-4"><a href="#cb1318-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on test data</span></span>
<span id="cb1318-5"><a href="#cb1318-5" aria-hidden="true" tabindex="-1"></a>tree_preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree_model, <span class="at">newdata =</span> test_prepped, <span class="at">type =</span> <span class="st">"class"</span>)</span>
<span id="cb1318-6"><a href="#cb1318-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1318-7"><a href="#cb1318-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate performance</span></span>
<span id="cb1318-8"><a href="#cb1318-8" aria-hidden="true" tabindex="-1"></a>test_churn <span class="ot">&lt;-</span> <span class="fu">factor</span>(test_data<span class="sc">$</span>churn, <span class="at">levels =</span> <span class="fu">levels</span>(tree_preds))</span>
<span id="cb1318-9"><a href="#cb1318-9" aria-hidden="true" tabindex="-1"></a>tree_metrics <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(tree_preds, test_churn)</span>
<span id="cb1318-10"><a href="#cb1318-10" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(tree_metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  yes   no
       yes  142   22
       no    64 1272
                                          
               Accuracy : 0.9427          
                 95% CI : (0.9297, 0.9539)
    No Information Rate : 0.8627          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.7353          
                                          
 Mcnemar's Test P-Value : 9.818e-06       
                                          
            Sensitivity : 0.68932         
            Specificity : 0.98300         
         Pos Pred Value : 0.86585         
         Neg Pred Value : 0.95210         
             Prevalence : 0.13733         
         Detection Rate : 0.09467         
   Detection Prevalence : 0.10933         
      Balanced Accuracy : 0.83616         
                                          
       'Positive' Class : yes             
                                          </code></pre>
</div>
</div>
<p><strong>Decision Tree Model:</strong></p>
<ul>
<li><p>Accuracy: 0.9427</p></li>
<li><p>Kappa : 0.7353</p></li>
<li><p>Mcnemar’s Test P-Value : 9.818e-06</p></li>
<li><p>Balanced Accuracy : 0.83616</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1320"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1320-1"><a href="#cb1320-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest Model</span></span>
<span id="cb1320-2"><a href="#cb1320-2" aria-hidden="true" tabindex="-1"></a>rf_model <span class="ot">&lt;-</span> <span class="fu">ranger</span>(churn <span class="sc">~</span> ., <span class="at">data =</span> train_prepped, <span class="at">classification =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1320-3"><a href="#cb1320-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1320-4"><a href="#cb1320-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on test data</span></span>
<span id="cb1320-5"><a href="#cb1320-5" aria-hidden="true" tabindex="-1"></a>rf_preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_model, <span class="at">data =</span> test_prepped)<span class="sc">$</span>predictions</span>
<span id="cb1320-6"><a href="#cb1320-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1320-7"><a href="#cb1320-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate performance</span></span>
<span id="cb1320-8"><a href="#cb1320-8" aria-hidden="true" tabindex="-1"></a>rf_metrics <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="fu">factor</span>(rf_preds, <span class="at">levels =</span> <span class="fu">levels</span>(test_data<span class="sc">$</span>churn)), test_churn)</span>
<span id="cb1320-9"><a href="#cb1320-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rf_metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  yes   no
       yes  153    4
       no    53 1290
                                         
               Accuracy : 0.962          
                 95% CI : (0.951, 0.9711)
    No Information Rate : 0.8627         
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
                                         
                  Kappa : 0.8218         
                                         
 Mcnemar's Test P-Value : 2.047e-10      
                                         
            Sensitivity : 0.7427         
            Specificity : 0.9969         
         Pos Pred Value : 0.9745         
         Neg Pred Value : 0.9605         
             Prevalence : 0.1373         
         Detection Rate : 0.1020         
   Detection Prevalence : 0.1047         
      Balanced Accuracy : 0.8698         
                                         
       'Positive' Class : yes            
                                         </code></pre>
</div>
</div>
<p>Random Forest Model:</p>
<ul>
<li>Accuracy : 0.962</li>
<li>Kappa : 0.8128</li>
<li>Mcnemar’s Test P-Value : &lt; 2.2e-16</li>
<li>Balanced Accuracy : 0.8698</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1322"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1322-1"><a href="#cb1322-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SVM Model</span></span>
<span id="cb1322-2"><a href="#cb1322-2" aria-hidden="true" tabindex="-1"></a>svm_model <span class="ot">&lt;-</span> <span class="fu">svm</span>(churn <span class="sc">~</span> ., <span class="at">data =</span> train_prepped, <span class="at">kernel =</span> <span class="st">"linear"</span>)</span>
<span id="cb1322-3"><a href="#cb1322-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1322-4"><a href="#cb1322-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on test data</span></span>
<span id="cb1322-5"><a href="#cb1322-5" aria-hidden="true" tabindex="-1"></a>svm_preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(svm_model, <span class="at">newdata =</span> test_prepped)</span>
<span id="cb1322-6"><a href="#cb1322-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1322-7"><a href="#cb1322-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate performance</span></span>
<span id="cb1322-8"><a href="#cb1322-8" aria-hidden="true" tabindex="-1"></a>svm_metrics <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="fu">factor</span>(svm_preds, <span class="at">levels =</span> <span class="fu">levels</span>(test_data<span class="sc">$</span>churn)), test_churn)</span>
<span id="cb1322-9"><a href="#cb1322-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(svm_metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  yes   no
       yes    0    0
       no   206 1294
                                          
               Accuracy : 0.8627          
                 95% CI : (0.8442, 0.8797)
    No Information Rate : 0.8627          
    P-Value [Acc &gt; NIR] : 0.5186          
                                          
                  Kappa : 0               
                                          
 Mcnemar's Test P-Value : &lt;2e-16          
                                          
            Sensitivity : 0.0000          
            Specificity : 1.0000          
         Pos Pred Value :    NaN          
         Neg Pred Value : 0.8627          
             Prevalence : 0.1373          
         Detection Rate : 0.0000          
   Detection Prevalence : 0.0000          
      Balanced Accuracy : 0.5000          
                                          
       'Positive' Class : yes             
                                          </code></pre>
</div>
</div>
<p>SVM Model:</p>
<ul>
<li><p>Accuracy: 0.8627</p></li>
<li><p>Kappa : 0</p></li>
<li><p>Mcnemar’s Test P-Value : &lt; 2e-16</p></li>
<li><p>Balanced Accuracy : 0.5000</p></li>
</ul>
<p><strong>Conclusion: The Random Forest performs the best with the highest accuracy and Kappa, and balance accuracy. Additionally, the Decision Tree performs well but not like the Random Forest model, and the svm model performed the worst failing to detect any churned customers.</strong></p>
<p>Use the fatty acid data from Homework 1 Problem 3 above.</p>
<ol type="a">
<li>Use the same data splitting approach (if any) and pre-processing steps that you did in Homework 1 Problem 3.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb1324"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1324-1"><a href="#cb1324-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-load the data if needed</span></span>
<span id="cb1324-2"><a href="#cb1324-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(oil)</span>
<span id="cb1324-3"><a href="#cb1324-3" aria-hidden="true" tabindex="-1"></a>oil_data <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(fattyAcids)</span>
<span id="cb1324-4"><a href="#cb1324-4" aria-hidden="true" tabindex="-1"></a>oil_data<span class="sc">$</span>oilType <span class="ot">&lt;-</span> oilType</span>
<span id="cb1324-5"><a href="#cb1324-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1324-6"><a href="#cb1324-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb1324-7"><a href="#cb1324-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1324-8"><a href="#cb1324-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1324-9"><a href="#cb1324-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data using stratified sampling</span></span>
<span id="cb1324-10"><a href="#cb1324-10" aria-hidden="true" tabindex="-1"></a>train_index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(oil_data<span class="sc">$</span>oilType, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb1324-11"><a href="#cb1324-11" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> oil_data[train_index, ]</span>
<span id="cb1324-12"><a href="#cb1324-12" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> oil_data[<span class="sc">-</span>train_index, ]</span>
<span id="cb1324-13"><a href="#cb1324-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1324-14"><a href="#cb1324-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Pre-process the data: Centering and Scaling</span></span>
<span id="cb1324-15"><a href="#cb1324-15" aria-hidden="true" tabindex="-1"></a>preProcValues <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(train_data[,<span class="sc">-</span><span class="fu">ncol</span>(train_data)], <span class="at">method =</span> <span class="fu">c</span>(<span class="st">"center"</span>, <span class="st">"scale"</span>))</span>
<span id="cb1324-16"><a href="#cb1324-16" aria-hidden="true" tabindex="-1"></a>train_data[,<span class="sc">-</span><span class="fu">ncol</span>(train_data)] <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcValues, train_data[,<span class="sc">-</span><span class="fu">ncol</span>(train_data)])</span>
<span id="cb1324-17"><a href="#cb1324-17" aria-hidden="true" tabindex="-1"></a>test_data[,<span class="sc">-</span><span class="fu">ncol</span>(test_data)] <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcValues, test_data[,<span class="sc">-</span><span class="fu">ncol</span>(test_data)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="2" type="a">
<li>Fit a few basic trees to the training set.</li>
</ol>
<p><u><strong>Decision tree model:</strong></u></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1325"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1325-1"><a href="#cb1325-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit tree model</span></span>
<span id="cb1325-2"><a href="#cb1325-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1325-3"><a href="#cb1325-3" aria-hidden="true" tabindex="-1"></a>tree_model <span class="ot">&lt;-</span> <span class="fu">train</span>(oilType <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">"rpart"</span>,</span>
<span id="cb1325-4"><a href="#cb1325-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, <span class="at">number =</span> <span class="dv">10</span>))</span>
<span id="cb1325-5"><a href="#cb1325-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1325-6"><a href="#cb1325-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on the test set</span></span>
<span id="cb1325-7"><a href="#cb1325-7" aria-hidden="true" tabindex="-1"></a>test_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree_model, <span class="at">newdata =</span> test_data)</span>
<span id="cb1325-8"><a href="#cb1325-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1325-9"><a href="#cb1325-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb1325-10"><a href="#cb1325-10" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(test_predictions, test_data<span class="sc">$</span>oilType)</span>
<span id="cb1325-11"><a href="#cb1325-11" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(conf_matrix)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  A  B  C  D  E  F  G
         A 10  0  0  0  0  0  0
         B  0  7  0  0  0  0  0
         C  0  0  0  0  0  0  0
         D  0  0  0  0  0  0  0
         E  1  0  0  2  3  3  0
         F  0  0  0  0  0  0  0
         G  0  0  0  0  0  0  0

Overall Statistics
                                          
               Accuracy : 0.7692          
                 95% CI : (0.5635, 0.9103)
    No Information Rate : 0.4231          
    P-Value [Acc &gt; NIR] : 0.000358        
                                          
                  Kappa : 0.6816          
                                          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E Class: F
Sensitivity            0.9091   1.0000       NA  0.00000   1.0000   0.0000
Specificity            1.0000   1.0000        1  1.00000   0.7391   1.0000
Pos Pred Value         1.0000   1.0000       NA      NaN   0.3333      NaN
Neg Pred Value         0.9375   1.0000       NA  0.92308   1.0000   0.8846
Prevalence             0.4231   0.2692        0  0.07692   0.1154   0.1154
Detection Rate         0.3846   0.2692        0  0.00000   0.1154   0.0000
Detection Prevalence   0.3846   0.2692        0  0.00000   0.3462   0.0000
Balanced Accuracy      0.9545   1.0000       NA  0.50000   0.8696   0.5000
                     Class: G
Sensitivity                NA
Specificity                 1
Pos Pred Value             NA
Neg Pred Value             NA
Prevalence                  0
Detection Rate              0
Detection Prevalence        0
Balanced Accuracy          NA</code></pre>
</div>
</div>
<p><strong>decision tree model:</strong></p>
<ul>
<li><p>Accuracy : 0.7692</p></li>
<li><p>Kappa : 0.6816</p></li>
<li><p>P-Value: 0.000358</p></li>
</ul>
<ol start="3" type="a">
<li>Does bagging improve the performance of the trees? What about boosting?</li>
</ol>
<p><strong>Bagging:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1327"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1327-1"><a href="#cb1327-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a bagged decision tree model</span></span>
<span id="cb1327-2"><a href="#cb1327-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1327-3"><a href="#cb1327-3" aria-hidden="true" tabindex="-1"></a>bagged_tree_model <span class="ot">&lt;-</span> <span class="fu">train</span>(oilType <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">"treebag"</span>,</span>
<span id="cb1327-4"><a href="#cb1327-4" aria-hidden="true" tabindex="-1"></a>                           <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, <span class="at">number =</span> <span class="dv">10</span>))</span>
<span id="cb1327-5"><a href="#cb1327-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1327-6"><a href="#cb1327-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on the test set</span></span>
<span id="cb1327-7"><a href="#cb1327-7" aria-hidden="true" tabindex="-1"></a>bagged_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(bagged_tree_model, <span class="at">newdata =</span> test_data)</span>
<span id="cb1327-8"><a href="#cb1327-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1327-9"><a href="#cb1327-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb1327-10"><a href="#cb1327-10" aria-hidden="true" tabindex="-1"></a>bagged_conf_matrix <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(bagged_predictions, test_data<span class="sc">$</span>oilType)</span>
<span id="cb1327-11"><a href="#cb1327-11" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(bagged_conf_matrix)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  A  B  C  D  E  F  G
         A 10  0  0  0  0  0  0
         B  0  7  0  0  0  0  0
         C  0  0  0  0  0  0  0
         D  0  0  0  2  0  0  0
         E  1  0  0  0  3  0  0
         F  0  0  0  0  0  3  0
         G  0  0  0  0  0  0  0

Overall Statistics
                                         
               Accuracy : 0.9615         
                 95% CI : (0.8036, 0.999)
    No Information Rate : 0.4231         
    P-Value [Acc &gt; NIR] : 7.058e-09      
                                         
                  Kappa : 0.9472         
                                         
 Mcnemar's Test P-Value : NA             

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E Class: F
Sensitivity            0.9091   1.0000       NA  1.00000   1.0000   1.0000
Specificity            1.0000   1.0000        1  1.00000   0.9565   1.0000
Pos Pred Value         1.0000   1.0000       NA  1.00000   0.7500   1.0000
Neg Pred Value         0.9375   1.0000       NA  1.00000   1.0000   1.0000
Prevalence             0.4231   0.2692        0  0.07692   0.1154   0.1154
Detection Rate         0.3846   0.2692        0  0.07692   0.1154   0.1154
Detection Prevalence   0.3846   0.2692        0  0.07692   0.1538   0.1154
Balanced Accuracy      0.9545   1.0000       NA  1.00000   0.9783   1.0000
                     Class: G
Sensitivity                NA
Specificity                 1
Pos Pred Value             NA
Neg Pred Value             NA
Prevalence                  0
Detection Rate              0
Detection Prevalence        0
Balanced Accuracy          NA</code></pre>
</div>
</div>
<p><strong>Bagging (decision tree mode):</strong></p>
<ul>
<li><p>Accuracy : 0.9615</p></li>
<li><p>Kappa : 0.9472</p></li>
<li><p>P-Value: 7.058e-09</p></li>
</ul>
<p><strong>Boosting</strong>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1329"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1329-1"><a href="#cb1329-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a boosted decision tree model</span></span>
<span id="cb1329-2"><a href="#cb1329-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1329-3"><a href="#cb1329-3" aria-hidden="true" tabindex="-1"></a>boosted_tree_model <span class="ot">&lt;-</span> <span class="fu">train</span>(oilType <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">"gbm"</span>,</span>
<span id="cb1329-4"><a href="#cb1329-4" aria-hidden="true" tabindex="-1"></a>                            <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb1329-5"><a href="#cb1329-5" aria-hidden="true" tabindex="-1"></a>                            <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span>
<span id="cb1329-6"><a href="#cb1329-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1329-7"><a href="#cb1329-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on the test set</span></span>
<span id="cb1329-8"><a href="#cb1329-8" aria-hidden="true" tabindex="-1"></a>boosted_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(boosted_tree_model, <span class="at">newdata =</span> test_data)</span>
<span id="cb1329-9"><a href="#cb1329-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1329-10"><a href="#cb1329-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb1329-11"><a href="#cb1329-11" aria-hidden="true" tabindex="-1"></a>boosted_conf_matrix <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(boosted_predictions, test_data<span class="sc">$</span>oilType)</span>
<span id="cb1329-12"><a href="#cb1329-12" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(boosted_conf_matrix)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  A  B  C  D  E  F  G
         A 11  0  0  0  0  0  0
         B  0  7  0  0  0  0  0
         C  0  0  0  0  0  0  0
         D  0  0  0  2  0  0  0
         E  0  0  0  0  3  0  0
         F  0  0  0  0  0  3  0
         G  0  0  0  0  0  0  0

Overall Statistics
                                     
               Accuracy : 1          
                 95% CI : (0.8677, 1)
    No Information Rate : 0.4231     
    P-Value [Acc &gt; NIR] : 1.936e-10  
                                     
                  Kappa : 1          
                                     
 Mcnemar's Test P-Value : NA         

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E Class: F
Sensitivity            1.0000   1.0000       NA  1.00000   1.0000   1.0000
Specificity            1.0000   1.0000        1  1.00000   1.0000   1.0000
Pos Pred Value         1.0000   1.0000       NA  1.00000   1.0000   1.0000
Neg Pred Value         1.0000   1.0000       NA  1.00000   1.0000   1.0000
Prevalence             0.4231   0.2692        0  0.07692   0.1154   0.1154
Detection Rate         0.4231   0.2692        0  0.07692   0.1154   0.1154
Detection Prevalence   0.4231   0.2692        0  0.07692   0.1154   0.1154
Balanced Accuracy      1.0000   1.0000       NA  1.00000   1.0000   1.0000
                     Class: G
Sensitivity                NA
Specificity                 1
Pos Pred Value             NA
Neg Pred Value             NA
Prevalence                  0
Detection Rate              0
Detection Prevalence        0
Balanced Accuracy          NA</code></pre>
</div>
</div>
<p><strong>Boosting (decision tree mode):</strong></p>
<ul>
<li><p>Accuracy : 1</p></li>
<li><p>Kappa : 1</p></li>
<li><p>P-Value: 1.936e-10</p></li>
</ul>
<p><strong>In conclusion, both bagging and boosting, enchance the decision tree from the basic tree model, you can observe that the predicting class levels have drastically improve. The accuracy and Kappa have also improved from the basic decision tree to bagging and then to boosting which resulted in accuracy of 100% and Kappa of 100%. The specific classes accuracy have also increase with Class A being the best and Class C and G being the worst..</strong></p>
<p>Side note: All classes (A,B,D,E,F) had an accuracy of 100%.</p>
<ol start="4" type="a">
<li>Which model has better performance, and what are the corresponding tuning parameters?</li>
</ol>
<ul>
<li><strong>The Boosted decision tree performs the best resulting in perfect accuracy and Kappa.</strong></li>
</ul>
<table class="table">
<colgroup>
<col style="width: 35%">
<col style="width: 12%">
<col style="width: 10%">
<col style="width: 27%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Accuracy</th>
<th>Kappa</th>
<th>No Information Rate</th>
<th>P-Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Decision Tree</strong></td>
<td>0.7692</td>
<td>0.6816</td>
<td>0.4231</td>
<td>0.000358</td>
</tr>
<tr class="even">
<td><strong>Bagged Decision Tree</strong></td>
<td>0.9615</td>
<td>0.9472</td>
<td>0.4231</td>
<td>7.058e-09</td>
</tr>
<tr class="odd">
<td><strong>Boosted Decision Tree</strong></td>
<td>1.0000</td>
<td>1.0000</td>
<td>0.4231</td>
<td>1.936e-10</td>
</tr>
</tbody>
</table>
<ul>
<li></li>
<li><strong>Now for the corresponding tuning parameter, they are as follows</strong>:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1331"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1331-1"><a href="#cb1331-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the best tuning parameters</span></span>
<span id="cb1331-2"><a href="#cb1331-2" aria-hidden="true" tabindex="-1"></a>boosted_tree_model<span class="sc">$</span>bestTune</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  n.trees interaction.depth shrinkage n.minobsinnode
1      50                 1       0.1             10</code></pre>
</div>
</div>
<table class="table">
<thead>
<tr class="header">
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>n.trees</strong></td>
<td>50</td>
</tr>
<tr class="even">
<td><strong>interaction.depth</strong></td>
<td>1</td>
</tr>
<tr class="odd">
<td><strong>shrinkage</strong></td>
<td>0.1</td>
</tr>
<tr class="even">
<td><strong>n.minobsinnode</strong></td>
<td>10</td>
</tr>
</tbody>
</table>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>